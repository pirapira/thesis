\chapter{Introduction}

\subsection{Our Contributions in the Historical Perspective}

Implication is an important concept.
Different treatments of implication has taken place in the realm of
mathematical logic.
One treatment of implications called the material implication~\fix{cite russel}
reduces an implication to negations and conjunctions by letting
$\phi\supset \psi$ be equivalent to $\neg (\phi \land \neg \psi)$.
However, there is another treatment of implication: the
Brouwer--Heyting--Kolmogorov interpretation reads: ``a proof of the
implication $\varphi\supset\psi$ is a construction which permits us to
 transform any proof of $\varphi$ into a proof of $\psi$''~\fix{cite}.
The BHK
interpretation does not specify what is a proof or what kind of
transformation witnesses implication.
Notwithstanding, there is a
traditional realization of proofs as lambda terms where the
introduction rule of implication is realized as the lambda abstraction
and the elimination rule of implication is realized as the application
of lambda terms.
This encoding has a formidable property:
the reductions in the lambda calculus corresponds to the reductions of
proofs that
removes detours.
For example, suppose a natural deduction proof introduces an implication and then
immidiately eliminate the
implication.  This proof can be encoded as a lambda term whose outermost
structure is a $\beta$-redex: $(\lambda x. M)N$.
 The result of the $\beta$-reduction $M[N/x]$ encodes a proof tree using
 the same assumptions as the original and concluding the same formula as
 the original, yet without the aforementioned detour.
 a proof of implication allows transformation of proofs
by means of
substitution.  The encoding of proofs as lambda terms is traditionally
called the Curry--Howard isomorphism.
% The situation is similar to axiomatized geometry where lines and points
% could be tables and chairs \fix{(cite)}.
The former explanation of implications is justified in classical propositional logic.
The latter view is most naturally materialized in the situation of
intuitionistic propositional logic.  The last century saw their
generalization called intermediate logics~\citep{umezawa} (or superintuitionistic
logics), of which a typical example is called G\"odel--Dummett logic.
In this thesis we investigate the Curry--Howard isomorphism for
G\"odel--Dummett logic.  The G\"odel--Dummett logic validates formulas
of the form $(\phi\imp\psi)\lor(\psi\imp\phi)$, which is known as
Dummett's axiom.  We add a construct to the simply typed lambda calculus
that witnesses Dummett's axiom.
After the intermediate logics, the generalization went further to
substructural
logics~\fix{cite ono et al}, which contains all the intermedaite logics as
well as the
(intuitionistic) multiplicative
additive fragment of linear logic.
In the later chapter, we make a typing system that lacks contraction and
weakening, which falls outside of intermediate logics but within
substructural logics albeit it has quantification over propositional variables.

The material implication can be traced back at least to
Frege's \textit{Begriffsschrift}.  There, in the section called
``conditionality,''
he begins by establishing four cases~\citep[p.~13]{van1967frege}:
\begin{enumerate}
 \item $A$ is affirmed and $B$ is affirmed\,;
 \item $A$ is affirmed and $B$ is denied\,;
 \item $A$ is denied and $B$ is affirmed\,;
 \item $A$ is denied and $B$ is denied.
\end{enumerate}
Then he defines a notation involving $A$ and $B$, which ``stands for the
judgment that \textit{the third of these possibilities does not take
place, but one of the three other does\footnote{The emphasis is by
the English translation~\citep[p.~14]{van1967frege}}.''}
It was Russell who called this implication the material implication,
according to~\citet{sep-conditionals}.

The Curry--Howard isomorphism~\citep{curryhoward} was first made
precise~\citep[p.97]{curryhoward} by \citet[\textbf{9}E and \textbf{9}F]{curry1974combinatory}
The double discovery is considered (e.g.~by \citet{wadler2012propositions})
to affirm the importance of the typed lambda calculi.
In this thesis we witness a replay of the double discovery with
different casts: G\"odel--Dummett logic and the waitfreedom.
Both of these were born in the early eras of their respective academic
disciplines:
mathematical logic bore G\"odel Dummett logic in
1950's~\citep{dummett59}
and the
computer science bore waitfree computation in
1970's~\citep{lamport1979make}.
This thesis is about the unknown connection between these two.

We list our contributions from the most important:
\begin{enumerate}
 \item identifying the computational ability of the
G\"odel--Dummett logic with waitfreedom
 \item developing a lambda calculus using
       a hypoersequent calculus
 \item developing a parametricity argument for
       concurrent processes performing waitfree communication.
 \item finding a method for implementing hypersequent-based lambda calculi in a
       functional programming language Haskell on the Glasgow Haskell
       Compiler
 \item finding a terminating tableau system for the sequential
       consistency logic.
\end{enumerate}

Our first contribution relies on our second contribution, which
develops a lambda calculus based on \citet{avron91}'s hypersequent
calculus for G\"odel--Dummett logic.  This justifies our title ``a
computational interpretation of G\"odel--Dummett logic.''
We found a way to interpret proofs in G\"odel--Dummett logic as
concurrently executable programs for waitfree computation.
Although \citet{avron91} noticed his hypersequent calculus has something
to do with concurrency (as the title of~\citep{avron91} contains the phrase
``intermediate logics for concurrency''), it was unknown that
the computational interpretation of G\"odel--Dummett logic has
the degree of synchronization called waitfreedom.  This discovery
constitutes our first contribution.

The lambda calculus relies on \citet{avron91}' hypersequents.
The hypersequent calculus is a
variant of the deduction system called sequent calculus.  In sequent
calculus, each step of a proof tree concludes a sequent $\G\vdash\phi$ that
consists of a finite sequence of logical formulae~$\G$ and a logical
formula~$\phi$.  After proving soundness of a sequent calculus, we know
that whenever a proof tree concludes $\G\vdash\phi$, any state of any model
satisfying all logical formulae in $\G$ must also satisfy the
formula~$\phi$.  In other words, the sequent $\G\vdash\phi$ is
interpreted as an implication.  In hypersequent calculus, each step of a
proof tree concludes a hypersequent instead of a sequent.  A
hypersequent is a sequence of sequents: $\G\vdash\phi\hmid \D\vdash\psi
\hmid \cdots$.  Also here, each component is interpreted as an
implication, and then the whole hypersequent is interpreted as the
disjunction of all those implications.
When we interpret proofs as programs, we take the components as
concurrent processeses.  Following the original disjunctive
interpretation of components, we regard the proof tree as the guarantee of
success of at least one process.

Our third contribution is about the parametricity in the second-order
setting.  When we allow logical formulas to have quantifiers on
propositional variables (e.g. $\forall X(X\imp X)$), the logic gets much
more expressive.
Moreover, these second-order types can give more detailed specification
of programs than just specifying the types of outputs given types of
inputs.
For example, in \fix{specify logic}, a term of type $\forall X(X\imp X)$
must be the identity function.
Using this technique, we find the common behaviour of terms of type
$\forall X \forall Y ((X\limp Y)\lor (Y\limp X))$, thus finding the
computational semantics of Dummett's axiom.
Our technical development here is very similar to that of
\citet{danos-krivine}.  The crucial difference is that the processes do
not communicate in the case of \citet{danos-krivine} but they perform
waitfree communication in our case.

Our fourth contribution is a confirmation of our second contribution.
We implemented the lambda calculus on top of
Glasgow Haskell Compiler.

Our fifth contribution is about proof searching, which is another
kind of computation arising from propositional logic.
The lambda calculi is about removing detours from proofs while the proof
searching is about finding a proof or a counterexample for a given
conclusion.  \fix{read synch schemes paper and make regorous}
We are now able to connect our work with the tradition of
synchronization schemes.

\fix{where to put it}
Proofs as objects de Bruijin.

\section{General Description of this Thesis}

% \section{An Introduction for Computer Scientists}

% \section{An Introduction for Proof Theorists}

% \section{An Introduction for Functional Programmers}

% \section{An Introduction for Philosophers}

At the core of computer science lies the interplay of static formalism
and dynamic behaviour.  We can find examples in typed lambda calculi,
where static formalism of type derivations interacts with dynamic
behaviour of lambda terms.
Type derivations of static objects associtating lambda terms to types.
The reduction on terms gives dynamics, defining which term reduce
to which.  Static type derivations can guarantee dynamic properties of
programs such as strong normalization \fix{cite},
deadlock freedom \fix{cite}
and so on.

Dynamic behaviour involves time.
One simple notion of time is that of totally-ordered events where
one event happens before the other or the other before one \fix{cite something}.
This sentence is syntactically similar to Dummett's axiom that states
one proposition implies the other or the other implies one.
We investigate whether this syntactic similarity is reflected
in the dynamic semantics of logics: namely, the lambda calculi.

\fix{describe lambda}

Our investigation is guided by the Curry--Howard isomorphism.
We look at proofs as programs and propositions as types.
The Curry--Howard isomorphism is used to give computational content
to mathematical proofs, and on the other hand to give mathematical
guarantees to computer programs.


There have been several attempts of finding computational meaning of
Dummett's axiom.  \fix{name examples}
The best thing we can hope is that the computational
interpretation coincides with something we know already.
That is the case indeed.

We extended the Curry--Howard correspondence to G\"odel--Dummett logic.
The Curry--Howard correspondence is \fix{add}

G\"odel--Dummett logic is an intermediate logic~\citep{umezawa} between
classical logic and intuitionistic logic.  Every theorem in
intuitionistic logic is a theorem in G\"odel--Dummet logic and every
theorem in G\"odel--Dummett logic is a theorem in classical logic.
These inclusions are strict.  The law of excluded middle
$\varphi\vee(\varphi\supset \bot)$ is not a theorem in G\"odel--Dummett
logic and $(\varphi\supset\psi)\vee(\psi\supset\varphi)$ is not a
theorem in intuitionistic logic.

In terms of Kripke semantics, the axiom is sound and complete for
requiring that the models are linearly ordered.
In terms of algebraic semantics, the axiom is sound and complete for
requiring that the truth values are linearly ordered.  \fix{ is this
usage of ``truth values'' correct? }
In terms of computation, what is it?

\section{Curry--Howard Correspondence for Different Logics}

Gentzen

Prawitz

Pfenning

Davies--Pfenning S4 A Modal Analysis of Staged Computation

Curien

Murphey 7

Hypersequent

Game

\section{Location Aware Languages}

X10


Hypersequents were born to solve proof theoretical difficulties, but we
apply hypersequents to solve distributed computational difficulties.

\section{Properties}


\section{Preliminaries}

We use set-theoretic concepts such as sets, relations and functions.
The largest cardinality in this thesis is that of the
powerset of the powerset of the set of natural numbers.