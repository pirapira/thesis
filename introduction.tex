\chapter{Introduction}

\subsection{Our Contributions}

The Curry--Howard isomorphism~\citep{curryhoward} was first made
precise~\citep[p.97]{curryhoward} by \citet[\textbf{9}E and
\textbf{9}F]{curry1974combinatory}.
The intuitionistic propositional logic and the typed lambda calculus
had been independently invented but Curry discovered them to be the same thing.
The double discovery is considered (e.g.~by \citet{wadler2012propositions})
to affirm the importance of the typed lambda calculi.
In this thesis we witness a replay of the double discovery with
different casts: G\"odel--Dummett logic and the waitfreedom.
Both of these were born in the early eras of their respective academic
disciplines:
mathematical logic bore G\"odel Dummett logic in
1950's~\citep{dummett59}
and the
computer science bore waitfree computation in
1970's~\citep{lamport1979make}.
This thesis is about the unknown connection between these two.

We list our contributions from the most important:
\begin{enumerate}
 \item identifying the computational ability of the
G\"odel--Dummett logic with waitfreedom (Chapter~\ref{ch:lambda}),
 \item developing a lambda calculus using
       a hypoersequent calculus (Chapter~\ref{ch:lambda}),
 \item identifying the communication performed by the prelinearity axiom
       of monoidal t-norm logic (Chapter~\ref{ch:pole}),
 \item developing a parametricity argument for
       concurrent processes performing waitfree communication (Chapter~\ref{ch:pole}),
 % \item identifying the communication performed by a seemingly unknown axiom
 %       $(p\limp q)\otimes(q\limp p)$ on top of multiplicative linear
 %       logic (Chapter~\ref{ch:exchange}),
 \item finding a method for implementing hypersequent-based lambda calculi in a
       functional programming language Haskell on the Glasgow Haskell
       Compiler (Chapter~\ref{ch:haskell}).
\end{enumerate}

Our first contribution relies on our second contribution, which
develops a lambda calculus based on \citet{avron91}'s hypersequent
calculus for G\"odel--Dummett logic.  This justifies our title ``a
computational interpretation of G\"odel--Dummett logic.''
We found a way to interpret proofs in G\"odel--Dummett logic as
concurrently executable programs for waitfree computation.
Although \citet{avron91} noticed his hypersequent calculus has something
to do with concurrency (as the title of~\citep{avron91} contains the phrase
``intermediate logics for concurrency''), it was unknown that
the computational interpretation of G\"odel--Dummett logic has
the degree of synchronization called waitfreedom.  This discovery
constitutes our first contribution.

The lambda calculus relies on \citet{avron91}'s hypersequents.
The hypersequent calculus is a
variant of the deduction system called sequent calculus.  In sequent
calculus, each step of a proof tree concludes a sequent $\G\vdash\phi$ that
consists of a finite sequence of logical formulae~$\G$ and a logical
formula~$\phi$.  After proving soundness of a sequent calculus, we know
that whenever a proof tree concludes $\G\vdash\phi$, any state of any model
satisfying all logical formulae in $\G$ must also satisfy the
formula~$\phi$.  In other words, the sequent $\G\vdash\phi$ is
interpreted as an implication.  In hypersequent calculus, each step of a
proof tree concludes a hypersequent instead of a sequent.  A
hypersequent is a sequence of sequents: $\G\vdash\phi\hmid \D\vdash\psi
\hmid \cdots$.  Also here, each component is interpreted as an
implication, and then the whole hypersequent is interpreted as the
disjunction of all those implications.
When we interpret proofs as programs, we take the components as
concurrent processeses.  Following the original disjunctive
interpretation of components, we regard the proof tree as the guarantee of
success of at least one process.

Our third contribution treats the prelinearity axiom
$(\phi\limp\psi)\oplus(\psi\limp\phi)$, which is the linear version of
Dummett's axiom.

Our fourth contribution is about the parametricity in the second-order
setting.  When we allow logical formulas to have quantifiers on
propositional variables (e.g. $\forall X(X\imp X)$), the logic gets much
more expressive.
Moreover, these second-order types can give more detailed specification
of programs than just specifying the types of outputs given types of
inputs.
For example, in \fix{specify logic}, a term of type $\forall X(X\imp X)$
must be the identity function.
Intuitively, since the term has to work on any type~$X$, the term cannot
look inside the argument of type~$X$.
Using this technique, we find the common behaviour of terms of type
$\forall X \forall Y ((X\limp Y)\lor (Y\limp X))$, thus finding the
computational semantics of Dummett's axiom.
Our technical development here is very similar to that of
\citet{danos-krivine}.  The crucial difference is that the processes do
not communicate in the case of \citet{danos-krivine} but they perform
waitfree communication in our case.


\fix{add nth and nth}

Our \fix{nth} contribution is a confirmation of our second contribution.
We implemented the lambda calculus on top of
Glasgow Haskell Compiler.

Our \fix{nth} contribution is about proof searching, which is another
kind of computation arising from propositional logic.
The lambda calculi is about removing detours from proofs while the proof
searching is about finding a proof or a counterexample for a given
conclusion.  \fix{read synch schemes paper and make regorous}
We are now able to connect our work with the tradition of
synchronization schemes.

\fix{where to put it}
Proofs as objects de Bruijin.

% \section{An Introduction for Computer Scientists}

% \section{An Introduction for Proof Theorists}

% \section{An Introduction for Functional Programmers}

% \section{An Introduction for Philosophers}

