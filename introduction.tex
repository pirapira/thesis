\chapter{Introduction}

\subsection{Our Contributions in the Historical Perspective}

The Curry--Howard isomorphism~\citep{curryhoward} is \fix{what... see Sorenzen}.
The double discovery is considered (e.g.~\citep{wadler2012propositions})
to affirm the importance of the typed lambda calculi.
In this thesis we witness a replay of the double discovery with
different casts: G\"odel--Dummett logic and the waitfreedom.
Both of these were born in the early eras of their respective academic
disciplines:
mathematical logic bore G\"odel Dummett logic in
1950's~\citep{dummett59}
and the
computer science bore waitfree computation in
1970's~\citep{lamport1979make}.
This thesis is about the connection between these two,
which has been unknown.

We list our contributions from the most important:
\begin{enumerate}
 \item identifying the computational ability of the
G\"odel--Dummett logic with waitfreedom
 \item developing a lambda calculus using
       a hypoersequent calculus
 \item developing a parametricity argument for
       concurrent processes performing waitfree communication.
 \item finding a method for implementing hypersequent-based lambda calculi in a
       functional programming language Haskell on the Glasgow Haskell
       Compiler
 \item finding a terminating tableau system for the sequential
       consistency logic.
\end{enumerate}

Our first contribution relies on our second contribution, which
develops a lambda calculus based on \citet{avron91}'s hypersequent
calculus for G\"odel--Dummett logic.  This justifies our title ``a
computational interpretation of G\"odel--Dummett logic.''
We found a way to interpret proofs in G\"odel--Dummett logic as
concurrently executable programs for waitfree computation.
Although \citet{avron91} noticed his hypersequent calculus has something
to do with concurrency (as the title of~\citep{avron91} contains the phrase
``intermediate logics for concurrency''), it was unknown that
the computational interpretation of G\"odel--Dummett logic has
the degree of synchronization called waitfreedom.  This discovery
constitutes our first contribution.

The lambda calculus relies on \citet{avron91}' hypersequents.
The hypersequent calculus is a
variant of the deduction system called sequent calculus.  In sequent
calculus, each step of a proof tree concludes a sequent $\G\vdash\phi$ that
consists of a finite sequence of logical formulae~$\G$ and a logical
formula~$\phi$.  After proving soundness of a sequent calculus, we know
that whenever a proof tree concludes $\G\vdash\phi$, any state of any model
satisfying all logical formulae in $\G$ must also satisfy the
formula~$\phi$.  In other words, the sequent $\G\vdash\phi$ is
interpreted as an implication.  In hypersequent calculus, each step of a
proof tree concludes a hypersequent instead of a sequent.  A
hypersequent is a sequence of sequents: $\G\vdash\phi\hmid \D\vdash\psi
\hmid \cdots$.  Also here, each component is interpreted as an
implication, and then the whole hypersequent is interpreted as the
disjunction of all those implications.
When we interpret proofs as programs, we take the components as
concurrent processeses.  Following the original disjunctive
interpretation of components, we regard the proof tree as the guarantee of
success of at least one process.

Our third contribution is about the parametricity in the second-order
setting.  When we allow logical formulas to have quantifiers on
propositional variables (e.g. $\forall X(X\imp X)$), the logic gets much
more expressive.
Moreover, these second-order types can give more detailed specification
of programs than just specifying the types of outputs given types of
inputs.
For example, in \fix{specify logic}, a term of type $\forall X(X\imp X)$
must be the identity function.
Using this technique, we find the common behaviour of terms of type
$\forall X \forall Y ((X\limp Y)\lor (Y\limp X))$, thus finding the
computational semantics of Dummett's axiom.
Our technical development here is very similar to that of
\citet{danos-krivine}.  The crucial difference is that the processes do
not communicate in the case of \citet{danos-krivine} but they perform
waitfree communication in our case.

Our fourth contribution is a confirmation of our second contribution.
We implemented the lambda calculus on top of
Glasgow Haskell Compiler.

Our fifth contribution is about proof searching, which is another
kind of computation arising from propositional logic.
The lambda calculi is about removing detours from proofs while the proof
searching is about finding a proof or a counterexample for a given
conclusion.  \fix{read synch schemes paper and make regorous}
We are now able to connect our work with the tradition of
synchronization schemes.

\section{General Description of this Thesis}

% \section{An Introduction for Computer Scientists}

% \section{An Introduction for Proof Theorists}

% \section{An Introduction for Functional Programmers}

% \section{An Introduction for Philosophers}

At the core of computer science lies the interplay of static formalism
and dynamic behaviour.  We can find examples in typed lambda calculi,
where static formalism of type derivations interacts with dynamic
behaviour of lambda terms.
Type derivations of static objects associtating lambda terms to types.
The reduction on terms gives dynamics, defining which term reduce
to which.  Static type derivations can guarantee dynamic properties of
programs such as strong normalization \fix{cite},
deadlock freedom \fix{cite}
and so on.

Dynamic behaviour involves time.
One simple notion of time is that of totally-ordered events where
one event happens before the other or the other before one \fix{cite something}.
This sentence is syntactically similar to Dummett's axiom that states
one proposition implies the other or the other implies one.
We investigate whether this syntactic similarity is reflected
in the dynamic semantics of logics: namely, the lambda calculi.

\fix{describe lambda}

Our investigation is guided by the Curry--Howard isomorphism.
We look at proofs as programs and propositions as types.
The Curry--Howard isomorphism is used to give computational content
to mathematical proofs, and on the other hand to give mathematical
guarantees to computer programs.


There have been several attempts of finding computational meaning of
Dummett's axiom.  \fix{name examples}
The best thing we can hope is that the computational
interpretation coincides with something we know already.
That is the case indeed.

We extended the Curry--Howard correspondence to G\"odel--Dummett logic.
The Curry--Howard correspondence is \fix{add}

G\"odel--Dummett logic is an intermediate logic~\citep{umezawa} between
classical logic and intuitionistic logic.  Every theorem in
intuitionistic logic is a theorem in G\"odel--Dummet logic and every
theorem in G\"odel--Dummett logic is a theorem in classical logic.
These inclusions are strict.  The law of excluded middle
$\varphi\vee(\varphi\supset \bot)$ is not a theorem in G\"odel--Dummett
logic and $(\varphi\supset\psi)\vee(\psi\supset\varphi)$ is not a
theorem in intuitionistic logic.

In terms of Kripke semantics, the axiom is sound and complete for
requiring that the models are linearly ordered.
In terms of algebraic semantics, the axiom is sound and complete for
requiring that the truth values are linearly ordered.  \fix{ is this
usage of ``truth values'' correct? }
In terms of computation, what is it?

\section{Curry--Howard Correspondence for Different Logics}

Prawitz

Pfenning

Davies--Pfenning S4 A Modal Analysis of Staged Computation

Curien

Murphey 7

Hypersequent

Game

\section{Location Aware Languages}

X10


Hypersequents were born to solve proof theoretical difficulties, but we
apply hypersequents to solve distributed computational difficulties.

\section{Properties}


\section{Preliminaries}

We use set-theoretic concepts such as sets, relations and functions.
The largest cardinality in this thesis is that of the
powerset of the powerset of the set of natural numbers.