\renewcommand{\comodL}{\comod cd}
\renewcommand{\comodR}{\comod dc}

\chapter{An Asynchronous Hyper-Lambda Calculus}
\label{ch:lambda}

\subsection{Summary}

We define a typed lambda calculus based on Avron's hypersequent
calculus~\citep{avron91} for G\"odel--Dummett logic.
We show that this calculus models
waitfree computation~\citep{Herlihy88,Saks:1993vq}.
Besides strong normalization and non-abortfullness,
we give soundness and completeness of
the calculus against the typed version of waitfree protocols.
The calculus is not only proof theoretically interesting,
but also valuable as a basis for distributed programming languages.
In other words, we extend
Curry--Howard isomorphism~\cite{curryhoward} to G\"odel--Dummett logic and
waitfreedom.
The content of this chapter appeared in a conference paper by
\citet{hiraiflops2012} although substantial modification has been
applied since.

On one hand, G\"odel--Dummett logic~\cite{dummett59}
is one of the intermediate logics
between classical and intuitionistic logics.
Waitfreedom~\cite{Herlihy88,Saks:1993vq} is a class of distributed
computation without synchronization among processes.

We connect G\"odel--Dummett logic and waitfreedom using
Avron's hypersequent calculus~\cite{avron91}.
In doing that, we respond to his suggestion:
\begin{quote}
it seems to us extremely important to determine the exact
       computational content of them~[intermediate logics] ---
       and {to develop corresponding `$\lambda$-calculi'}
       ---Avron~\cite{avron91}.
\end{quote}
Differently from intuitionistic logic, G\"odel--Dummett logic validates
all formulae of the form
 $(\varphi\supset\psi)\vee(\psi\supset\varphi)$.
We aim at building a typed lambda calculus
with some terms witnessing those formulae.
Such a term
$\tj{M}{(\varphi\supset\psi)\vee(\psi\supset\varphi)}$ must choose
$M\reduction \linl\cdots$ or $M\reduction \linr\cdots$.
We devise a nondeterministic lambda calculus in Section~\ref{lgd}.
In this lambda calculus, terms can contain operators that read from and
write to the store, or memory.
In essence, the nondeterminism arises from the scheduling of concurrent
processes: which process writes to the store before which process
reads from the store.

On the other hand, waitfreedom is a class of distributed computation
where processes cannot wait for other processes.  When two processes try
to exchange information, the faster process can pass information to the
slower one, but not always vice versa because the slower process might
start after the faster one finishes.
So, the computation is nondeterministic.
% see introduction for history of waitfreedom

The contribution of this chapter lies in capturing
the nondeterminism of waitfreedom using the nondeterministic
$\lambda$-calculus for G\"odel--Dummett logic.
In Section~\ref{lgd},
we define a lambda calculus and prove some of its properties.
In Section~\ref{waitfreedom}, we define typed waitfreedom.
Finally in Section~\ref{comparison},
we prove that the lambda calculus characterizes typed waitfreedom.
In other words, we show that the
$\lambda$-terms in the lambda calculus can solve a typed input-output
problem if and only if it is waitfreely solvable.

\section{\lgd}
\label{lgd}

In this section, we define a typed lambda calculus \lgd\, based on
hypersequents.
This constitutes the second contribution of this thesis.
Moreover, the lambda calculus is one side of the Curry--Howard
isomorphism that will be matched against the waitfree computation.

We first present a proof system for G\"odel--Dummett logic.
Then we turn the proof system into typing rules for $\lambda$-terms
of~\lgd, give a set of reductions and prove strong-normalization and
non-abortfullness.
We show that the proof system using the hypersequent
style~\citep{avron91}.
In the usual sequent calculi, each reasoning step concludes a sequent
$\G\vdash\phi$ where $\G$ is a possibly empty sequence of formulae.
By contrast,
in the hypersequent calculi, each reasoning step concludes a
hypersequent, which is a finite, non-empty sequence of sequents.
Of the hypersequent
$\G_0\vdash\phi_0\hmid\G_1\vdash\phi_1\hmid\cdots\hmid\G_n\vdash\phi_n$,
each sequent $\G_i\vdash\phi_i$ is called a
\textit{component}\index{component}.
Each component $\G_i\vdash\phi_i$ is interpreted as an implication: the
conjunction of $\G_i$ implies $\phi_i$.
The whole hypersequent is interpreted as disjunction of implications:
$\tr$ is interpreted as implication and $\hmid$ as
disjunction.
In other words, $\G_i$ implies $\phi_i$ for at least one $i\in
\{0,1,\ldots,n\}$.
When we give computational interpretation to proofs, we still interpret
the components
disjunctively: namely, a derivation tree concluding a hypersequent
represents a sequence of concurrent processes at least one of which is
guaranteed to succeed.

\subsection{Logic}

\newcommand{\m}[1]{{#1}^+}

Let us assume a countably infinite set~$\pvar$ of \textit{propositional
variables}\index{propositional
variable|see{variable}}\index{variable!propositional}.  We define \textit{local
formulae}\index{formula!local}\index{local formula|see{formula}}
$\varphi, \psi$ (also called \textit{local types}\index{type!local}\index{local
type|see{type}}) by the following BNF, where $I$ is a propositional
variable\footnote{We include $\bot$ in the definition of local formulae
because G\"odel--Dummett logic has
$\bot$ although $\bot$ is not necessary to encode waitfree computation.}%
:
\[
 \varphi,\psi ::= \bot \mid I \mid (\varphi\supset\psi) \mid (\varphi\wedge\psi) \mid
 (\varphi\vee\psi)\enspace.
\]
We omit parentheses when no ambiguity occurs.
We assume countably infinitely many \textit{processes}\index{process}.
A \textit{global formula}\index{formula!global}\index{global
formula|see{formula}}
(also called a \textit{global type}\index{type!global}\index{global type|see{type}})
is a non-empty partial map from processes to local
formulae.
We use $\m\phi$ and $\m\psi$ for global formulae.  For a process~$i$,
as a notation, $[i]\phi$ is a global formula that maps $i$ to $\phi$ but
does not map any other processes to local formulae.
% I considered removing this notation,
% but that would make the contexts awkward, so
% I chose not changing it for now.
% \fix{this sentence is awkward}
We name such global formulae that map only one process as singleton
global formulae.
The unary operators $[0], [1],\ldots$ are called \textit{modalities}%
\index{modality}.
%\fix{example, with $\sqcup$}
Informally, the local formulae describe datatypes used by each process.
The global formulae describe inputs or outputs of possibly multiple
processes.

A \textit{context}\index{context} (denoted by $\Gamma$ and $\Delta$ possibly
subscripted) is a potentially empty
finite sequence of singleton global formulae.
A \textit{sequent}\index{sequent}~$\Gamma\vdash\m\varphi$ is a pair of a
context and a
global formula.
A \textit{hypersequent}\index{hypersequent} is a finite sequence of sequents.

The underlying logic has the derivation rules in Figure~\ref{fig:logic}.
If we omit all the modalities, these rules characterize
G\"odel--Dummett logic.
 \begin{theorem}[Characterization of G\"odel--Dummett logic]
For any local formula~$\phi$, $\phi$ is a theorem in G\"odel--Dummett
logic iff $[0]\phi$ is provable.
 \end{theorem}
 \begin{proof}
  We consider a translation of a global formula $\m\phi$ to a local
  formula.
  Let $I$ be the domain of $\m\phi$.
  The translation is $\wwedge_{i\in I}\m\phi(i)$.
  After translating all rules in Figure~\ref{fig:logic},
  both directions of the statement can be shown by induction on derivations.
 \end{proof}
Indeed,
$[0]((\varphi\supset\psi)\vee(\psi\supset\varphi))$ is provable (Figure~\ref{fig:dummett-modal}).
\begin{figure}
 \footnotesize
 \centering
\AxiomC{}
\LL{[0]Ax}
\UnaryInfC{$[0]P\vdash [0]P$}
\AxiomC{}
\LL{[0]Ax}
\UnaryInfC{$[0]Q\vdash[0]Q$}
\LL{00-com}
\BinaryInfC{$[0]P\vdash[0]Q\hmid [0]Q\vdash[0]P$}
\LL{$[0]\supset\intro$}
\UnaryInfC{$\vdash[0](P\supset Q)\hmid [0]Q\vdash[0]P$}
\LL{$[0]\supset\intro$}
\UnaryInfC{$\vdash[0](P\supset Q)\hmid \vdash[0](Q\supset P)$}
\LL{$[0]\vee\intro$}
\UnaryInfC{$\vdash[0]((P\supset Q)\lor(Q\supset P))\hmid \vdash[0](Q\supset P)$}
\LL{$[0]\vee\intro$}
\UnaryInfC{$\vdash[0]((P\supset Q)\lor(Q\supset P))\hmid
 \vdash[0](P\supset Q) \lor (Q\supset P)$}
\LL{EC}
\UnaryInfC{$
\vdash
 [0]((P\supset Q)\lor (Q\supset P)) $}
 \DisplayProof

 \caption{A derivation of Dummett's axiom under modality~$[0]$ in \lgd.}
 \label{fig:dummett-modal}
\end{figure}

% \section{About the modality}

% \fix{compare with the intuitionistic epistemic logic}

% \fix{consider the Kripke model.}

% \fix{translation back and forth.}

\begin{figure}
 \small
\centering
  \textbf{External Rules}
   \vskip 2mm
%%communication
   \BinaryRule
   {$\hyper_0\hmid\G\vdash[i]\phi$}
   {$\hyper_1\hmid\D\vdash[j]\psi$}
   {$ij$-com}
   {$\hyper_0\hmid\hyper_1\hmid\Gamma\vdash[i]\psi\hmid\Delta\vdash[j]\varphi$}
  \hfill
%% external structural
 \UnaryRule
 {$\hyper^+$}
 {EW}
 {$\hyper^+\hmid\Gamma\vdash \m\varphi$}
 \ruleskip
 %
 \UnaryRule
 {$\hyper\hmid\Gamma\vdash \m\phi\hmid\Gamma\vdash \m\phi$}
 {EC}
 {$\hyper\hmid\Gamma\vdash \m\phi$}
 \hfill
 %
 \UnaryRule
 {$\hyper\hmid\Gamma\vdash \m\varphi\hmid\Delta\vdash \m\psi\hmid \hyper'$}
 {EE}
 {$\hyper\hmid\Delta\vdash \m\psi   \hmid\Gamma\vdash \m\varphi\hmid
   \hyper'$}
 \ruleskip
\textbf{Inner Global Rules}
\ruleskip
%% structural
   \UnaryRule
   {$\hyper\hmid\Gamma,[i]\phi,[j]\psi,\Delta\tr\m\theta$}
   {IE}
   {$\hyper\hmid\Gamma,[j]\psi,[i]\phi,\Delta\tr\m\theta$}
   \hfill
   \UnaryRule{$\hyper\hmid\Gamma\vdash\m\varphi$}
   {IW}
   {$\hyper\hmid[i]\psi,\Gamma\vdash\m\varphi$}
   \hfill
   \UnaryRule
   {$\hyper\hmid[i]\psi,[i]\psi,\G\vdash\m\varphi$}
   {IC}
   {$\hyper\hmid[i]\psi,        \G\vdash\m\varphi$}
   \ruleskip
%% global conj intro
 \BinaryRule
 {$\hyper_0\hmid\G,\D_0\tr(\phi_i)_{i\in I}$}
 {$\hyper_1\hmid\G,\D_1\tr(\psi_j)_{j\in J}$}
 {$\wedge\intro$}
 {$\hyper_0\hmid\hyper_1\hmid\G,\D_0,\D_1\tr(\phi_k\land\psi_k)_{k\in I\cap J}\sqcup
 (\phi_i)_{i\in I\setminus J}\sqcup (\psi_j)_{j\in J\setminus I}$}
 \ruleskip
%% global conj elim
 \UnaryRule
 {$\hyper\hmid \G\tr(\phi_i)_{i\in I}$}
 {$\wedge\elim$}
 {$\hyper\hmid \G\tr(\phi_i)_{i\in J}$}
 where $J$ is a subset of $I$.
\ruleskip
\textbf{Inner Local Rules}
\ruleskip
%% axiom
  \UnaryRule{}{$[i]$Ax}
   {$[i]\phi,\Gamma\vdash [i]\phi$}
   \hfill
%% bot elim
 \UnaryRule{$\hyper\hmid\Gamma\vdash[i]\bot$}
   {$[i]\bot\elim$}
   {$\hyper\hmid\Gamma\vdash[i]\phi$}
   \ruleskip
%% local imp intro
  \UnaryRule{$\hyper\hmid[i]\varphi,\G\vdash [i]\psi$}
  {$[i]\supset\intro$}
  {$\hyper\hmid\G\vdash [i](\varphi\supset \psi)$}
  \hfill
%% local imp elim
  \BinaryRule
  {$\hyper_0\hmid\G,\D_0\vdash [i](\phi\imp\psi)$}
  {$\hyper_1\hmid\G,\D_1\vdash [i]\phi$}
  {$[i]\supset\elim$}
  {$\hyper_0\hmid\hyper_1\hmid\G,\D_0,\D_1\vdash [i]\psi$}
   \ruleskip
%% local conj elim
  \UnaryRule{$\hyper\hmid\Gamma\vdash [i](\varphi\wedge\psi)$}
   {$[i]\wedge\elim_0$}
   {$\hyper\hmid\Gamma\vdash[i]\varphi$}
   \hfill
  \UnaryRule{$\hyper\hmid\Gamma\vdash[i](\varphi\wedge\psi)$}
   {$[i]\wedge\elim_1$}
   {$\hyper\hmid\Gamma\vdash[i]\psi$}
\ruleskip
%% local disj intro
  \UnaryRule
   {$\hyper\hmid\Gamma\vdash[i]\varphi$}
   {$[i]\vee\intro_0$}
   {$\hyper\hmid\Gamma\vdash[i](\varphi\vee\psi)$}
   \hfill
  \UnaryRule{$\hyper\hmid\Gamma\vdash[i]\psi$}
   {$[i]\vee\intro_1$}
   {$\hyper\hmid\Gamma\vdash[i](\varphi\vee\psi)$}
\ruleskip
%% local disj elim
   \TrinaryRule
   {$\hyper_0\hmid\G,\D_0\vdash[i](\phi\vee\psi)$}
   {$\hyper_1\hmid[i]\varphi, \G,\D_1\vdash[i]\theta$}
   {$\hyper_2\hmid[i]\psi,    \G,\D_2\vdash[i]\theta$}
   {$[i]\vee\elim$}
   {$\hyper_0\hmid\hyper_1\hmid\hyper_2\hmid
 \G,\D_0,\D_1,\D_2\vdash[i]\theta$}
\ruleskip
\caption[The underlying logic of \lgd.]
 {The underlying logic.
 Metavariables $\m\phi$ and $\m\psi$ stand for global formulae.
 Metavariables~$i$ and $j$ stand for processes.  For the use of
 $\sqcup$, see Section~\ref{sec:prelim}.
 $\hyper$ stands for a possibly empty hypersequent.
 $\hyper^+$ stands for a nonempty hypersequent.
 $\Gamma$ and $\Delta$ stand for possibly empty contexts.
 In the names of rules, $\intro$ at the end stands for introduction and $\elim$ for
 elimination.  For structural rules, E stands for exchange, W for
 weakening and C for contraction.  The I's in front stand for internal and E
 for external.
 A rule $[i]\wedge\intro$ is omitted because the inner global rule
 $\wedge\intro$ is more general.
  There is no disjunction elimination in the inner global rules lest it
 is difficult (if possible) to translate the rule into
 waitfree computation.
 }
\label{fig:logic}
\end{figure}

\subsection{Term Assignment}
\label{term}

We assume distinct, countably infinite sets of
\textit{variables}\index{variable} and
\textit{locations}\index{location}.
Locations are denoted by~$c,d,\ldots$; process~$i,j, \ldots$ and variables~$x,
y, \ldots$.
Later, locations will be used to specify a location in a store.
A location in a store can hold a term or be empty.
Like in the $\lambda$-calculus, some terms reduce to other
terms, but in this calculus, terms may interact with stores (like
a program written in Haskell or OCaml does with i-vars).
This behavior will be shown later in the definition of reductions.

We define \textit{local terms}\index{term!local}~$\term$ by BNF:
\begin{align*}
\term ::=&\,
 x\mid (\comod c c) \term \mid \reader c
 \mid
 \cotuple{\term,\term} \mid \abort \mid
  \lpil \term \mid \lpir \term \mid
 \lpair {\term,\term}\mid \\&
  \linl \term \mid  \linr \term \mid
 \lambda x.\term\mid (\term \term)
\mid \mat \term x\term y \term
\end{align*}
where $x$ is a variable and $c$ is a location.
All variable occurrences except the first clause are binding.
The set of free variables of a local term $\FV(M)$ is defined inductively
on $M$:
\begin{align*}
 \FV(x)&= \{x\}\\
 \FV(\comod c c) M&= \FV(M)\\
 \FV(\reader c) &= \emptyset\\
 \FV(\cotuple{M,N})&= \FV(M)\cup \FV(N)\\
 \FV(\abort)&= \emptyset\\
 \FV(\lpil{M})&= \FV(M)\\
 \FV(\lpir{N})&= \FV(N)\\
 \FV(\lpair{M,N})&= \FV(M)\cup \FV(N)\\
 \FV(\inl{M})&= \FV(M)\\
 \FV(\inr{M})&= \FV(M)\\
 \FV(\lambda x.M)&= \FV(M) \setminus \{x\}\\
 \FV((M N))&= \FV(M)\cup \FV(N)\\
 \FV(\mat M x N y O)&= \FV(M)\cup (\FV(N)\setminus \{x\}) \cup
 (\FV(O)\setminus\{y\})\enspace.
\end{align*}
A \textit{closed local term}\index{term!closed local} is a local term
that has no free variables.

A \textit{global term}\index{term!global} is a partial map from
processes to local
terms.  For example, a global term $\{0\mapsto \lambda x.x, 1\mapsto
y\}$ maps process~$0$ to local term $\lambda x.x$ and process~$1$ to
local term $y$.
We can substitute a local term for a variable in a global term.
The substitution is defined elementwise: i.e.,
the result of the substitution $\m{M}[N/x]$ maps a process~$i$ to $(\m{M}(i))[N/x]$.
A \textit{closed global term}\index{term!closed global} is a global term
whose image only contains closed local terms.
Informally, the local terms represent parts of
programs executed by the processes.
Especially, $(\comod c c)t$ and $\reader c$ cause processes to communicate.

Using these terms, we annotate the hypersequent system in Figure~\ref{fig:logic}.
We extend a sequent
to $\G\tr \tj {\m M}{\m \varphi}$\kern -3pt, where $\G$ is
a sequence like $\tj{x}{[i]\psi}\kern -1pt, \tj{y}{[j]\theta}$ and $\m M$
is a global term.
In a sequent $\Gamma\tr\tj{M}{\m\varphi}$\kern -3pt, we require the
variables in $\G$ to be distinct from each other.
We do not allow a context to contain both $\tj{x}{[0]I}$ and
$\tj{x}{[1]I}$, or even $\tj{x}{[0]I}$ twice.
An (extended) \textit{hypersequent}\index{hypersequent} is a finite sequence of
sequents (each called
a \textit{component}\index{component})
where the same
variable has the same type even if it appears in different components.
The typing rules for the terms are given in Figure~\ref{termassign}.
For example, the proof in Figure~\ref{fig:dummett-modal} can be
annotated as in Figure~\ref{fig:typed}.
Each derivation has a unique hypersequent at the bottom, which is called the
\textit{endhypersequent}\index{endhypersequent} of the derivation.
A hypersequent is \textit{derivable}\index{derivable} when there is a
derivation whose endsequent is identical to the hypersequent.
\begin{sidewaysfigure}
 \centering
\AxiomC{}
\LL{[0]Ax}
\UnaryInfC{$\tj{x}{[0]P}\tr \tj{x}{[0]P}$}

\AxiomC{}
\LL{[0]Ax}
\UnaryInfC{$\tj{y}{[0]Q}\tr\tj{y}{[0]Q}$}
\LL{$00$-com}
\BinaryInfC{$\tj{x}{[0]P}\tr\tj{(\comodL)x}{[0]Q}\hmid
 \tj{y}{[0]Q}\tr\tj{(\comodR)y}{[0]P}$}
\LL{$[0]\supset\intro$}
\UnaryInfC{$\tr\tj{\lambda x. (\comodL)x}{[0](P\supset Q)}
 \hmid \tj{y}{[0]Q}\tr\tj{(\comodR)y}{[0]P}$}
\LL{$[0]\supset\intro$}
\UnaryInfC{$\tr\tj{\lambda x. (\comodL)x}{[0](P\supset Q)}\hmid \tr
 \tj{\lambda y.(\comodR)y}{[0](Q\supset P)}$}
\LL{$[0]\vee\intro$}
\UnaryInfC{$\tr\tj{\inl{\lambda x. (\comodL)x}}{[0]((P\supset Q)\lor
 (Q\supset P))}\hmid \tr
 \tj{\lambda y.(\comodR)y}{[0](Q\supset P)}$}
\LL{$[0]\vee\intro$}
\UnaryInfC{$\tr\tj{\inl{\lambda x. (\comodL)x}}{[0]((P\supset Q)\lor
 (Q\supset P))}\hmid \tr
 \tj{\inr{\lambda y.(\comodR)y}}{[0]((P\supset Q)\lor(Q\supset P))}$}
\LL{EC}
\UnaryInfC{$
\tr \tj{\left[{\inl{\lambda x. (\comodL)x}} ,\quad {\inr{\lambda
 y.(\comodR)y}} \right]}
 {[0]((P\supset Q)\lor (Q\supset P))} $}
\DisplayProof
 \caption{An example of a typed term in \lgd\, that corresponds the
 derivation in Figure~\ref{fig:dummett-modal}.}
 \label{fig:typed}
\end{sidewaysfigure}

\begin{figure}[p]
 \small
\centering
% \textbf{External Rules}
% \ruleskip
%% communication
\BinaryRule
   {$\hypert_0\hmid\G\tr\tj{\imapsto{M}}{[i]\phi}$}
   {$\hypert_1\hmid\D\tr\tj{\jmapsto{N}}{[j]\psi}$}
   {com}
   {$\hypert_0\hmid\hypert_1\hmid\Gamma\tr\tj{\imapsto{(\comodL)M}}{[i]\psi}\hmid
   \Delta\tr\tj{\jmapsto{(\comodR)N}}{[j]\phi}$}
 \\ where locations $c$ and $d$ are fresh and no location is contained
 in both of the two branches.
\ruleskip
%% external structural
 \AxiomC{$\hypert\hmid \G\tr\tj{(M_i)_{i\in I}}{(\phi_i)_{i\in I}}\hmid
 \G\tr\tj{(N_i)_{i\in I}}{(\phi_i)_{i\in I}}$}
 \LL{EC}
 \UnaryInfC{$\hypert\hmid
 \G\tr\tj{(\cotuple{M_i,N_i})_{i\in I}}{(\phi_i)_{i\in I}}$}
 \DisplayProof
\ruleskip
 \UnaryRule
 {$\hypert^+$}
 {EW}
 {$\hypert^+\hmid\Gamma\tr \tj {\{\}} {\m\phi}$}
\hfill
 \UnaryRule
 {$\hypert\hmid\Gamma\tr \m M\colon\m\varphi\hmid\Delta\tr \m N\colon \m\psi\hmid \hypert'$}
 {EE}
 {$\hypert\hmid\Delta\tr \m N\colon\m\psi   \hmid\Gamma\tr \m M\colon \m\varphi\hmid \hypert'$}
 \ruleskip
% \textbf{Inner Global Rules}
%    \ruleskip
 % internal contraction
   \UnaryRule
   {$\hypert\hmid \Gamma\tr\tj {\m M} {\m\varphi}$}
   {IW}
   {$\hypert\hmid \tj x {[i]\psi}, \Gamma\tr \tj{\m M}{\m\varphi}$}
   \hfill
   \UnaryRule
   {$\hypert\hmid \tj{x}{[i]\phi}, \tj{y}{[i]\phi}, \Gamma\tr \tj
 {\m M}{\m\psi}$}
   {IC}
   {$\hypert \hmid \tj{x}{[i]\phi}, \Gamma\tr \tj{\m{M}[x/y]}{\m\psi}$}
\ruleskip
\UnaryRule
   {$\hypert\hmid\Gamma,\tj x{[i]\phi},\tj y{[j]\psi},\Delta\tr
   \tj {\m M}{\m\theta}$}
 {IE}
   {$\hypert\hmid\Gamma,\tj y{[j]\psi},\tj x{[i]\phi},\Delta\tr \tj
 {\m M}{\m\theta}$} %IE
\ruleskip
%% conj intro
 {
 \AxiomC
 {$\hypert_0\hmid\G,\D_0\tr\tj{(M_i)_{i\in I}}{(\phi_i)_{i\in I}}$}
 \AxiomC
 {$\hypert_1\hmid\G,\D_1\tr\tj{(N_j)_{j\in J}}{(\psi_j)_{j\in J}}$}
 \LL
 {$\wedge\intro$}
 \BinaryInfC
 {{
 $\hypert_0\hmid\hypert_1\hmid \G,\D_0,\D_1\tr$\phantom{some text
 necessary here, enough to make a line long}
 }}
 \noLine
 \UnaryInfC{
 $
 \tj
 {(\lpair{M_k,N_k})_{k\in I\cap J}\sqcup (M_i)_{i\in I\setminus J}\sqcup
 (N_j)_{j\in J\setminus I}}
 {(\phi_k\land\psi_k)_{k\in I\cap J}\sqcup
 (\phi_i)_{i\in I\setminus J}\sqcup (\psi_j)_{j\in J\setminus I}}
 $
 }
 \DisplayProof
 }
   \ruleskip
%% conj elim
\UnaryRule
 {$\hypert\hmid\G\tr\tj{(M_i)_{i\in I}}{(\phi_i)_{i\in I}}$}
 {$\wedge\elim$}
 {$\hypert\hmid\G\tr\tj{(M_j)_{j\in J}}{(\phi_j)_{j\in J}}$}
 where $J$ is a subset of $I$.
\ruleskip
% \textbf{Inner Local Rules}
% \ruleskip
%% axiom
  \UnaryRule{}{$[i]$Ax}{$\tj {x}{[i]\varphi}, \Gamma\tr \tj
 {\imapsto x}{[i]\varphi}$}
                       \hfill
%% bot elim
 \UnaryRule
   {$\hypert\hmid\Gamma\tr \tj {\imapsto M}{[i]\bot}$} {$[i]\bot\elim$}
   {$\hypert\hmid\Gamma\tr \tj{\imapsto{\abort}}{[i]\varphi}$}
   \ruleskip
%% local imp intro
  \UnaryRule
   {$\hypert\hmid\tj x{[i]\varphi},\Gamma\tr \tj {\imapsto{M}}{[i]\psi}$}
   {$[i]\imp\intro$}
   {$\hypert\hmid\Gamma\tr \tj{\imapsto{\lambda x.M}}{[i](\varphi\supset\psi)}$}
                       \ruleskip
%% local imp elim
 \BinaryRule
 {$\hypert_0\hmid\G,\D_0 \tr \tj {\imapsto{M}}{[i](\varphi\supset \psi)}$}
 {$\hypert_1\hmid\G,\D_1 \tr \tj {\imapsto{N}}{[i]\varphi}$}
 {$[i]\imp\elim$}
 {$\hypert_0\hmid\hypert_1\hmid\G,\D_0,\D_1\tr \tj{\imapsto{MN}}{[i]\psi}$}
   \ruleskip
%% local conj elim
  \UnaryRule
   {$\hypert\hmid\Gamma\tr \tj{\imapsto{M}}{[i](\phi\land\psi)}$}
   {$[i]\wedge\elim_0$}
   {$\hypert\hmid\Gamma\tr \tj{\imapsto{\lpil{M}}}{[i]\phi}$}
   \hfill
  \UnaryRule
   {$\hypert\hmid\Gamma\tr \tj{\imapsto{M}}{[i](\varphi\wedge\psi)}$}
   {$[i]\wedge\elim_1$}
   {$\hypert\hmid\Gamma\tr \tj{\imapsto{\lpir M}}{[i]\psi}$}
\ruleskip
%% local disj intro
 {\footnotesize
  \UnaryRule
   {$\hypert\hmid\Gamma\tr \tj{\imapsto{M}}{[i]\varphi}$}
   {$[i]\vee\intro_0$}
   {$\hypert\hmid\Gamma\tr \tj{\imapsto{\linl{M}}}{[i](\varphi\vee\psi)}$}
   \hfill
  \UnaryRule
   {$\hypert\hmid\Gamma\tr \tj{\imapsto{M}}{[i]\psi}$}
   {$[i]\vee\intro_1$}
   {$\hypert\hmid\Gamma\tr
 \tj{\imapsto{\linr{M}}}{[i](\varphi\vee\psi)}$}
}
 \ruleskip
%% local disj elim
\AxiomC
   {$\hypert_0\hmid\G,\D_0\tr \tj{\imapsto{M}}{[i](\phi\lor\psi)}$}
 \noLine
 \UnaryInfC{$\hypert_1\hmid\tj x{[i]\phi},\G,\D_1\tr
 \tj{\imapsto{N_0}}{[i]\theta}$}
 \noLine
 \UnaryInfC{$\hypert_2\hmid\tj y{[i]\psi},\G,\D_2\tr \tj{\imapsto{N_1}}{[i]\theta}$}
 \LL{$[i]\vee\elim$}
 \UnaryInfC{$\hypert_0\hmid\hypert_1\hmid\hypert_2\hmid\G,\D_0,\D_1,\D_2 \tr
 \tj{\imapsto{\mat M x {N_0} y {N_1}}}{[i]\theta}$}
 \DisplayProof
\ruleskip
 \caption[The typing rules of \lgd.]
 {Term assignment on the \lgd\,type system.
 Metavariable $\m M$ stands for global terms.
 When we remove variables and terms, we obtain the derivation rules for
 the underlying logic (Figure~\ref{fig:logic}).
 $\hypert$ stands for
 a possibly empty hypersequent (with possible subscripts).
 $\hypert^+$ stands for a non-empty hypersequent.
 }
 \label{termassign}
\end{figure}

 \begin{example}[A typing of a global term.]
The global term
  \[
\{0\mapsto
\cotuple{\lpair{(\comodL)x, x}, x}
,1\mapsto
\cotuple{\lpair{(\comodR)y, y}, y}
\}  \]
 can be typed (Figure~\ref{fig:typed2}).
 \end{example}

 \begin{sidewaysfigure}
  \centering
   \begin{flushleft}
    \textsf{Part A}
   \end{flushleft}
  \AxiomC{}
  \LL{Ax}
  \UnaryInfC{$\tj{x}{[0]X}\tr\tj{x}{[0]X}$}
  \AxiomC{$\vdots$}
  \LL{$\wedge\intro$}
  \BinaryInfC{$
  \tj{x}{[0]X}\tr\tj{\{0\mapsto \lpair{(\comodL)x,x}\}}{[0](Y\land X)}\hmid
  \tj{y}{[1]Y}\tr\tj{\{1\mapsto (\comodR)y\}}{[1]X}
  $}
  \AxiomC{}
  \LL{Ax}
  \UnaryInfC{$\tj{y}{[1]Y}\tr\tj{y}{[1]Y}$}
  \LL{$\wedge\intro$}
  \BinaryInfC{$
  \tj{x}{[0]X}\tr\tj{\{0\mapsto \lpair{(\comodL)x,x}\}}{[0](Y\land X)}\hmid
  \tj{y}{[1]Y}\tr\tj{\{1\mapsto \lpair{(\comodR)y,y}\}}{[1](X\land Y)}
  $}
  \LL{$[0]\vee\intro$}
  \UnaryInfC{$
  \tj{x}{[0]X}\tr\tj{\{0\mapsto
  \linl{\lpair{(\comodL)x,x}}\}}{[0](Y\land X)\lor X}\hmid
  \tj{y}{[1]Y}\tr\tj{\{1\mapsto \lpair{(\comodR)y,y}\}}{[1](X\land Y)}
  $}
  \LL{$[1]\vee\intro$}
  \UnaryInfC{$
  \tj{x}{[0]X}\tr\tj{\{0\mapsto
  \linl{\lpair{(\comodL)x,x}}\}}{[0](Y\land X)\lor X}\hmid
  \tj{y}{[1]Y}\tr\tj{\{1\mapsto \inr{\lpair{(\comodR)y,y}}\}}{[1](X\land
  Y)\lor Y}
  $}
  \DisplayProof
  \begin{flushleft}
   \textsf{Part B}
  \end{flushleft}
  \AxiomC{}
  \LL{Ax}
  \UnaryInfC{$\tj{y}{[1]Y}\tr\tj{y}{[1]Y}$}
  \LL{$[1]\vee\intro$}
  \UnaryInfC{$\tj{y}{[1]Y}\tr\tj{\inr{y}}{[1]((X\land Y)\lor Y)}$}
  \AxiomC{$\vdots$}
  \LL{$\wedge\intro$}
  \BinaryInfC{$
  \tj{x}{[0]X}\tr\tj{\{0\mapsto
  \linl{\lpair{(\comodL)x,x}},
  1\mapsto\inr{y}
  \}}{\{0\mapsto (Y\land X)\lor X, 1\mapsto (X\land Y)\lor Y\}}\hmid
  $}
  \noLine
  \UnaryInfC{$
  \tj{y}{[1]Y}\tr\tj{\{1\mapsto \inr{\lpair{(\comodR)y,y}}\}}{[1](X\land
  Y)\lor Y}
  $}
  \AxiomC{}
  \LL{Ax}
  \UnaryInfC{$\tj{x}{[0]X}\tr\tj{x}{[0]X}$}
  \LL{$[0]\vee\intro$}
  \UnaryInfC{$\tj{\inr{x}}{[0]X}\tr\tj{x}{[0]((Y\land X)\lor X)}$}
  \LL{$\wedge\intro$}
  \BinaryInfC{$
  \tj{x}{[0]X}, \tj{y}{[1]Y}\tr
  \tj{\{
  0\mapsto \inl{\lpair{(\comodL)x,x}}, 1\mapsto \inr{y}
  \}}
  {\{0\mapsto (Y\land X)\lor X, 1\mapsto (X\land Y)\lor Y\}}
  \hmid
  $}
  \noLine
  \UnaryInfC{
  $
  \tj{x}{[0]X}, \tj{y}{[1]Y}\tr
  \tj
  {\{
  0\mapsto \inr{x},
  1\mapsto \inl{\lpair{(\comodR)y, y}}
  \}}
  {\{0\mapsto
  (Y\land X)\lor X
  , 1\mapsto
  (X\land Y)\lor Y
  \}}
  \phantom{\hmid}$
  }
  \DisplayProof
  \begin{flushleft}
    \textsf{Whole Derivation}
  \end{flushleft}
  \AxiomC{}
  \LL{Ax}
 \UnaryInfC{$\tj{x}{[0]X}\tr\tj{\{0\mapsto x\}}{[0]X}$}
  \AxiomC{}
  \LL{Ax}
 \UnaryInfC{$\tj{y}{[1]Y}\tr \tj{\{1\mapsto y\}}{[1]Y}$}
 \LL{01-com}
 \BinaryInfC{
 $
  \tj{x}{[0]X}\tr\tj{\{0\mapsto (\comodL)x\}}{[0]Y} \hmid
  \tj{y}{[1]Y}\tr\tj{\{1\mapsto (\comodR)y\}}{[1]X}$
 }
  \LL{\textsf{Part A}}
 \doubleLine
  \UnaryInfC{$
  \tj{x}{[0]X}\tr\tj{\{0\mapsto\inl{\lpair{(\comodL)x,x}}\}}{[0]((Y\land
  X)\lor X)}
  \hmid
  \tj{y}{[1]Y}\tr\tj{\{1\mapsto\inl{\lpair{(\comodR)y,y}}\}}{[1]((X\land
  Y)\lor Y)}
  $}
  \LL{\textsf{Part B}}
  \doubleLine
 \UnaryInfC{
 $
 \tj{x}{[0]X}, \tj{y}{[1]Y}\tr
 \tj{\{
  0\mapsto \inl{\lpair{(\comodL)x,x}}, 1\mapsto \inr{y}
  \}}
  {\{0\mapsto (Y\land X)\lor X, 1\mapsto (X\land Y)\lor Y\}}
  \hmid
 $
 }
  \noLine
  \UnaryInfC{
  $
  \tj{x}{[0]X}, \tj{y}{[1]Y}\tr
  \tj
  {\{
  0\mapsto \inr{x},
  1\mapsto \inl{\lpair{(\comodR)y, y}}
  \}}
  {\{0\mapsto
  (Y\land X)\lor X
  , 1\mapsto
  (X\land Y)\lor Y
  \}}
  \phantom{\hmid}$
  }
  \LL{EC}
  \UnaryInfC{$
  \tj{x}{[0]X}, \tj{y}{[1]Y}\tr\tj
  {\{
  0\mapsto \cotuple{\inl{\lpair{(\comodL)x,x}},\inr{x}},
  1\mapsto \cotuple{\inl{\lpair{(\comodR)y,y}},\inr{y}}
  \}}
  {\{
  0\mapsto ((Y\land X)\lor X),
  1\mapsto ((X\land Y)\lor Y)
  \}
  }
  $
  }
 \DisplayProof
  \ruleskip
  \caption{An example of a typing derivation.}
  \label{fig:typed2}
 \end{sidewaysfigure}

\subsection{Reduction}

A \textit{hyperterm}\index{hyperterm}~$\hypert$ is a nonempty sequence
of global terms.
From a hypersequent $\G_0\tr\tj{\m{M_0}}{\m{\phi_0}}\hmid \cdots \hmid
\G_n\tr\tj{\m{M_n}}{\m{\phi_n}}$,
we can construct a hyperterm $(\m{M_i})_{0\le i \le n}$.
The hyperterm $(\m{M_i})_{0\le i \le n}$ is typeable when the
aforementioned hypersequent is derivable for some $\G_i$'s and $\m{\phi_i}$'s.

A \textit{store}\index{store} maps a location to a pure, closed term or $\epsilon$,
where a \textit{pure term}\index{pure term|see{term}}\index{term!pure} is a term
without $\comod c c$ or $\reader c$.
For a store~$S$, the \textit{updated store}\index{update} $S[c\mapsto x]$ maps $c$ to
$x$ and $d$ to $S(d)$ if $d$ is different from~$c$.
A \textit{configuration}\index{configuration} is a pair $\conf{}\hypert$ of a
store~$\lstore$ and a hyperterm~$\hypert$.
A \textit{typed configuration}\index{typed configuration} is a
configuration $(\epsilon, \mathcal O)$ where $\epsilon$ is the empty
store and $\mathcal O$ is a typeable hypersequent.

To complete the definition of \lgd,
 we define the \textit{reductions} $\reduce_\spadesuit$ of
 configurations for $\spadesuit\in\{\mathrm B, \mathrm W, \mathrm R, \mathrm A,
 \mathrm P\}$, where B stands for basic, W for write, R for read, A for
 abort and P for permutative reductions.
 We consider terms up to $\alpha$-equivalence and implicitly
 require all instances
 of $\rightsquigarrow_\spadesuit$ to avoid free variable captures.

We require all reductions to be congruences.
A binary relation~$R$ on configurations is a \textit{congruence}\index{congruence}
when
\begin{itemize}
 \item $\concreteconf{S_0}{\hypert_0} R \concreteconf{S_1}{\hypert_1}$ implies\\
       $\concreteconf{S_0}{\hypert_0\hmid \hypert} R
       \concreteconf{S_1}{\hypert_1\hmid \hypert}$,
 \item $\concreteconf{S_0}{\hypert_0\hmid \m{M_0}} R
       \concreteconf{S_1}{\hypert_1 \hmid \m{M_1}}$ implies\\
       $\concreteconf{S_0}{\hypert_0\hmid \m{M_0}\sqcup \m{N}} R
       \concreteconf{S_1}{\hypert_1\hmid \m{M_1}}$
 \item $\concreteconf{S_0}{\hypert_0\hmid \{i\mapsto M_0\}\sqcup
       \m{M_0}} R \concreteconf{S_1}{\hypert_1\hmid \imapsto{M_1}\sqcup
       \m{M_1}}$ implies\\
       $\concreteconf{S_0}{\imapsto{C[M_0]}\sqcup \m{M_0}} R
       \concreteconf{S_1}{\imapsto{C[M_1]}\sqcup \m{M_1}}$ for any
       context~$C$
 \item $\concreteconf{S}{\hypert_0\hmid \m{M}\hmid \m{N} \hmid \hypert_1}
       R \concreteconf{S'}{\hypert'}$
       implies\\
       $\concreteconf{S}{\hypert_0\hmid \m{N}\hmid \m{M} \hmid \hypert_1}
       R \concreteconf{S'}{\hypert'}$ and
 \item $\concreteconf{S}{\hypert} R \concreteconf{S'}{\hypert_0\hmid
       \m{M}\hmid \m{N}\hmid \hypert_1}$
       implies\\
       $\concreteconf{S}{\hypert} R \concreteconf{S'}{\hypert_0\hmid
       \m{N}\hmid \m{M}\hmid \hypert_1}$.
\end{itemize}

The first kind of reductions, basic reductions, are what one would
expect from typed lambda calculi based on intuitionistic propositional
logic with implication, conjunction and disjunction.
\begin{definition}[Basic reduction]
 The basic reduction $\breduce$ is the smallest congruence containing
 the followings:
 \begin{itemize}
  \item  $\conf{}{\imapsto{(\lambda x.M)N}}\breduce
	 \conf{}{\imapsto{M[N/x]}}$
  \item $\conf{}{\imapsto{\lpil{\lpair{M,N}}}} \breduce
	 \conf{}{           \imapsto{M}   }$
  \item $\conf{}{\imapsto{\lpir{\lpair{M,N}}}} \breduce
	 \conf{}{             \imapsto{N} }$
  \item $\conf{}{\imapsto{\mat{(\linl M)}x N y O}} \breduce
	 \conf{}{              \imapsto{N[M/x]}}$
  \item $\conf{}{\imapsto{\mat{(\linr M)}x N y O}} \breduce
	 \conf{}{                  \imapsto{O[M/y]}}$
 \end{itemize}
\end{definition}

There are two sorts of reductions that interact with the store.
In summary, $\comodL$ tries to write to $d$ and read from
$c$ in the store of the configuration.
If a term writes to an empty location, the location is filled with the
local term written by the term.
 If a term writes to a full location of
a store, it does not abort but the store is not updated.  In fact, the
contents of locations are never updated after being written.
This property will be used in the proof of \thref{first:sn} (Strong normalization).
The formal definition of the reductions follows.
\begin{definition}[Write reduction]
 The write reduction $\wreduce$ is the smallest congruence
 containing the followings:
 \begin{itemize}
  \item $\conf{[c\mapsto \epsilon]}{\imapsto{(\comodR)M}} \wreduce
	\conf{[c\mapsto M]}{\imapsto{\reader d}}
	$ where $M$ is a pure, closed term
  \item $\conf{[c\mapsto N]}{\imapsto{(\comodR) M}} \wreduce
	\conf{[c\mapsto	N]}{\imapsto{\reader d}}$ where $M$ is a pure,
	closed term.
 \end{itemize}
\end{definition}
In the first clause of this definition of write reductions, we require
$M$ to be a pure, closed
term because a store can only contain pure, closed terms.
This restriction on store contents comes from our aim of modeling
asynchronous communication.
If we allow stores to contain terms with free variables,
the term $(\lambda x. (\comodL x)) M$ can store $x$ in the store and
another process can read $x$ from the store.
After that, if $(\lambda x.\cdots)M$ reduces,
then, $x$ becomes $M$ suddenly in the other process.
We want to avoid this phenomenon because it is synchronous communication.

We require the same condition in the second clause as well although
the store contents are not changed in the second clause.
Otherwise, whether a configuration admits a write reduction or not
would depend on the contents of the store, which would make the
implementation more complicated.  More technically, the definition of
normal forms would depend on the store contents, which we avoided.

After the communicating term $(\comodL)$ writes to the memory,
the term changes into a reader~$\reader c$.  When the reader~$\reader c$
tries to
read when $c$ is full, the reader is replaced with the content of the
location~$c$.
If a reader tries to read from an empty location of a store,
the reader changes into $\abort$.
\begin{definition}[Read reduction]
 \label{read}
 The read reduction $\rreduce$ is the smallest congruence
 containing the
 followings:
\begin{itemize}
   \item $\conf{[c\mapsto M]}{\imapsto{\reader c}}\rreduce
      \conf{[c\mapsto M]}{\imapsto{M}}$
   \item $\conf{[c\mapsto \epsilon]}{\imapsto{\reader c}}
       \rreduce \conf{[c\mapsto \epsilon]}{\imapsto{\abort}}$
\end{itemize}
\end{definition}

The special term $\abort$ means failure, so, a term containing $\abort$,
except $\cotuple{M,N}$, also reduces to $\abort$.  The \textit{concurrent
construction}\index{concurrent
construction}\index{construction!concurrent} $\cotuple{M,N}$ runs $M$
and $N$ concurrently and throws
away those subterms that reduce to $\abort$.
To be specific, the term $\cotuple{M,N}$ reduces to ${M}$
or ${N}$.
The reduction rules are not symmetric with regard to the left component
and the right component of the concurrent construct $[M,N]$ because
when both components succeed, the whole construct reduces to
the left component.
\begin{definition}[Abort propagation reduction]
 The abort propagation reduction $\areduce$ is the smallest
 congruence containing the
 followings:
\begin{itemize}
 \item  $\conf{}{\imapsto{\cotuple{\abort, M}}}\areduce
 \conf{}{\imapsto{M}}$;
 \item
   $\conf{}{\imapsto{\cotuple{M,\abort}}}\areduce
 \conf{}{\imapsto{M}}$;
 \item $\conf{}{\imapsto{\cotuple{M,N}}}\areduce \conf{}{\imapsto{M}}$ where
       $M$ and $N$ do not contain $\abort$, $\comodL$ or $\reader c$
       for any locations $c,d$;
 \item  $\conf{}{\imapsto{C[\abort]}}\areduce
 \conf{}{\imapsto{\abort}}$  where $C[\bullet]$ is defined by BNF:
\begin{align*}
  C[\bullet] ::= &\bullet \mid
C[\bullet] N \mid
{M C[\bullet]}\mid
(\comod c c)C[\bullet]\mid
\linl{C[\bullet]}\mid
\linr{C[\bullet]}\mid
\lpair {C[\bullet], N}\mid \\&
\lpair {M, C[\bullet]}\mid
\pi^\square_i{C[\bullet]}\mid
\mat M x N y {C[\bullet]}\mid\\ &
\mat  {C[\bullet]} x N y O\mid
\mat  M x {C[\bullet]} y O
\end{align*}
\end{itemize}
\end{definition}
For example, the configuration $(S, \cotuple{\abort,\abort})$ reduces to $(S,
\abort)$.

In order to avoid the situation where computation is blocked by
a syntactic barricade,
we add yet another kind of reduction rules called permutative
 reductions.
\begin{definition}[Permutative reduction]
 The permutative reduction~$\preduce$ is the smallest congruence
 containing the followings:
\begin{itemize}
 \small
 \item $\conf{}{\imapsto{ \left(\mat  M x N y O\right) P }}\preduce$ \\
       $\conf{}{\imapsto{ \mat M x {N P} y {O P} }}$
 \item $\conf{}{\imapsto{ \pi_d \left(\mat M x N y
       O\right)}}\preduce$\\
       $\conf{}{\imapsto{ \mat M x
       {\pi_d N} y {\pi_d O} }}$
 \item {
       $\conf{}{\imapsto{ \mat
                          {\left(\mat  M x N y O\right)}
                          u P v Q
                     } }\preduce$ \\
       $(\lstore,
       \{i\mapsto
        \mathsf{match}\,{M}\,\mathsf{of}\, \linl{x}. {
                          {\left(\mat N u P v Q\right)}
       } /$ \\ \phantom{mmmmmmmmmmm}$
       \linr{y}. {\left(\mat  O u P v Q\right)}
                      \})
       $}
 \item $\conf{}{ \imapsto{\cotuple{M, N} P} }\preduce
        \conf{}{ \imapsto{\cotuple{MP, NP} }}$
 \item $\conf{}{ \imapsto{\pi_d\cotuple{M,N} }}\preduce
        \conf{}{ \imapsto{\cotuple{\pi_d M, \pi_d N}} }$
 \item $\conf{}{ \imapsto{\mat {\cotuple{M,N}} x P y Q }}\preduce$\\
       $\conf{}{ \imapsto{\cotuple{
                          \mat  M x P y Q,
                          \mat N x P y Q
                        }} }$
\end{itemize}
\end{definition}

We define $\reduce$ to be the union of $\breduce$, $\wreduce$, $\rreduce$,
$\areduce$ and $\preduce$.
The reflexive transitive closure of $\reduce$ is
written as~$\reduction$.
A \textit{redex}\index{redex} is a subterm that can be rewritten by a reduction.
A configuration~$\mathcal{C}$ is \textit{normal}\index{normal} when
there is no configuration
$\mathcal{D}$ with $\mathcal{C}\reduce \mathcal{D}$.
A term~$M$ is \textit{normal}\index{normal} when the configuration $\conf{}{M}$ is
a normal configuration (the choice of $\lstore$ is irrelevant).

\begin{example}[Reductions of \lgd]
 We take the term shown in
 Figure~\ref{fig:typed2} and replace $x$ and $y$ with pure, closed terms
 $v$ and $w$.
 Below, an underlined subterm is a redex:
 \begin{align*}
  &\left(\{\}, \{
  0\mapsto\cotuple{\lpair{\underline{(\comodL)v},v},v},
  1\mapsto\cotuple{\lpair{           (\comodR)w ,w},w}
  \right)
  \\   \wreduce &
  \left( \{d\mapsto v\},
  \{
  0\mapsto \cotuple{{\lpair{\underline{\reader c},  v}}, v},
  1\mapsto \cotuple{           \lpair{(\comodR)w,w},w}
  \}
  \right)
  \\ \rreduce &
  \left( \{d\mapsto v\},
  \{
  0\mapsto \cotuple{\underline{\lpair{\abort,  v}}, v},
  1\mapsto \cotuple{           \lpair{(\comodR)w,w},w}
  \}
  \right)
  \\
  \areduce &
  \left(
  \{d\mapsto v\},
  \{
  0\mapsto\underline{\cotuple{\abort,v}},
  1\mapsto{\cotuple{\lpair{(\comodL)w,w},w}}
  \}
  \right)
  \\
  \areduce &
  \left(\{d\mapsto v\},
  \{
  0\mapsto{v},
  1\mapsto\cotuple{\lpair{\underline{(\comodR)w},w},w}
  \}
  \right)
  \\
  \wreduce &
  \left(
  \{c\mapsto w, d\mapsto v\}
  ,
  \{
  0\mapsto {v},
  1\mapsto \cotuple{\lpair{\underline{\reader d}, w}, w}
  \}
  \right)
  \\
  \rreduce &
  \left(
  \{c\mapsto w, d\mapsto v\}
  ,
  \{
  0\mapsto {v},
  1\mapsto \underline{\cotuple{\lpair{v,w},w}}
  \}
  \right)
  \\
  \areduce &
  \left(
  \{c\mapsto w, d\mapsto v\}
  ,
  \{
  0\mapsto {v},
  1\mapsto {\lpair{v,w}}
  \}
  \right)\quad.
 \end{align*}
 The overall effect is the transfer of term~$v$ from process~0 to
 process~1.  In the beginning, $v$ only appears in process~0's
 local term but not in process~1's local term.  In the end, the
 term~$v$ appears in both processes' local terms.
 From the first line to the second line,
 process~0's communication term succeeds in writing term~$v$ to
 location~$d$.
 From the second line to the third line, process~0 fails to read from
 location~$c$ so that a reader construct is turned into an $\abort$.
 This failure occurs because process~0 tries to read before process~1
 writes.  In a different scheduling (or, evaluation strategy) such a
 failure can be avoided.  This kind of nondeterminism is essential to
 characterize waitfreedom later.
 From the third line to the fourth line,
 the $\abort$ in process~0's subterm is propagated so that the whole pair
 containing $\abort$ is turned into $\abort$.
 From the fourth line to the fifth line,
 the aborted subterm in process~0 is thrown away: this is
 the main functionality of the concurrent construction $\cotuple{M,N}$.
 From the fifth line to the sixth line,
 process~1 writes to location~$c$.
 From the sixth line to the seventh line,
 process~1 reads what process~0 wrote.
 In this case, the reader in process~1 does not
 yield $\abort$ but outputs a previous content of the store.
 From the seventh line to the last line,
 the right side component~$w$ of $\cotuple{\lpair{v,w},w}$ is thrown away:
 we chose to throw away the right hand side component when both sides
 of $\cotuple{M,N}$ contain no $\abort$.  When we view the concurrent construction
 $\cotuple{M,N}$ as a representation of external contraction rule,
 this asymmetry is strange, but the asymmetry plays a significant
 role in encoding waitfree computation in our calculus.
\end{example}


\subsection{Properties}

An important property of
\lgd\, is strong normalization:
every typed hyperterm has a finite, maximum number of ensuing reductions.
Another property is {non-abortfullness}: although some reductions yield
$\abort$ terms, a typed hyperterm never reduces to a hyperterm that only
contains $\abort$'s.  We show the second property first because its
proof is simpler.

\begin{theorem}[Non-abortfullness of \lgd]
 \label{nab}
 All normal forms of a typed configuration contain at least one term
 that is not $\abort$.
\end{theorem}
\begin{proof}
 When a reduction sequence is fixed, for any locations~$c$ and $d$, depending on
 whether $c$ or $d$ is filled first,
 either:
 (i)  no ${\reader d} \reduce {\abort}$ occurs, or
 (ii) no ${\reader c} \reduce {\abort}$ occurs.

In case~(i), we can rewrite
a communication rule occurrence
\begin{center}
 \BinaryRule
 {$\hypert_0\hmid \G,\D\tr \tj{\imapsto{M}}{[i]\psi}$}
 {$\hypert_1\hmid \G,\D\tr \tj{\jmapsto{N}}{[j]\tau}$}
 {}
 {$\hypert_0\hmid\hypert_1\hmid
 \Gamma\tr \tj
   {\imapsto{(\comodL)M}}{[i]\tau}\hmid
   \Delta\tr \tj{\jmapsto{(\comodR)N}}{[j]\psi}$}
\end{center}
into a weakening occurrence (using Proposition~\ref{process-change} proved below)
\begin{center}
 \AxiomC
 {$\hypert_0\hmid  \Gamma^j, \Delta^j\tr \tj {\jmapsto{M}}{[j]\psi}$}
 \UnaryInfC
 {$\hypert_0\hmid \tr \tj {\imapsto\abort}
 {[i]\tau}\hmid
   \Gamma^j,\Delta^j\tr \tj{\jmapsto{M}}{[j]\psi}$}
 \DisplayProof
\end{center}
 where $\G^j$ denotes the context obtained by replacing every modality
 in $\G$ with $j$.
 In case~(ii), we can do the symmetric.

After these rewritings for all appearing locations,
we obtain a derivation not containing any locations.
Moreover, the endhypersequent of the rewritten derivation has a component
not containing $\abort$.
The reductions of the original hyperterm can be simulated by the
rewritten hyperterm.  And, even after reductions, the resulting
hyperterm has a component not containing $\abort$.
\end{proof}

In order to justify the renaming operation appearing in the proof of
\thref{nab}, we first define the renaming operation on global types.
Of a global type $\m\phi = (\phi_i)_{i \in I}$,
the $j$-replacement~$\phi^{+j}$ is
$\{j \mapsto \bigwedge_{i\in I} (\phi_i)\}$.  For example, the
1-replacement of $[0]\bot$ is $[0]\bot^1 = [1]\bot$.

For a context $\G = \tj{x_0}{[i_0]\phi_0}, \tj{x_1}{[i_1]\phi_1},
\tj{x_2}{[i_2]\phi_2}, \ldots,\tj{x_n}{[i_n]\phi_n}$,
the $j$-replacement $\G^j$ is
$\tj{x_0}{[j]\phi_0}, \tj{x_1}{[j]\phi_1},
\tj{x_2}{[j]\phi_2}, \ldots,\tj{x_n}{[j]\phi_n}$.

  \begin{proposition}
   \label{process-change}
  When $\mathcal O \hmid \G_0,\D_0\tr\tj{\m{M}}{\m\phi}$ is derivable,
  \[
   \mathcal O\hmid \G_0^m, \D_0^m\tr\tj{\mmapsto{M'}}{\phi^{+m}}
  \] is also
  derivable for some local term~$M'$.
  \end{proposition}
  \begin{proof}
   By induction on the height of derivation.
   All rules except com and EC are trivial because
   they do not interact
   with the modalities.  For EC rule, we have to apply the induction
   hypothesis twice to change modalities in two components.
   For com rule, let us assume the derivation ends in com rule as:
   \[
   \BinaryRule
   {$\hypert_0\hmid\G\tr\tj{M}{[i]\varphi}$}
   {$\hypert_1\hmid\D\tr\tj{N}{[j]\psi}$}
   {}
   {$\cotuple{\hypert_0,\hypert_1}\hmid\Gamma\tr\tj{(\comodL)M}{[i]\psi}\hmid
   \Delta\tr\tj{(\comodR)N}{[j]\varphi}$}\enspace.
   \]
   We have to consider three cases:  first, when
   $\G_0,\D_0\tr\tj{\m M}{\m \phi}$ in the statement is in $[\mathcal O_0, \mathcal O_1]$;
   second, when $\G_0,\D_0\tr\tj{\m{M}}{\m{\phi}}$ in the statement is identical to
   $\G\tr\tj{(\comodL)M}{[i]\psi} $; and third,
   when $\G_0,\D_0\tr\tj{\m{M}}{\m{\phi}}$ in the statement is identical to
   $\D\tr\tj{(\comodR)N}{[j]\varphi}$.
   The second and third cases are symmetric.  In the first case, $\m{M}$ is
   actually a concurrent construct $([P_i,Q_i])_{i\in I}$. We can apply the
   induction hypothesis to $P$ and $Q$ and combine them
   again~$\mmapsto{\cotuple{P', Q'}}$.
   In the second case, we can use the induction hypothesis on the left branch%
   \footnote{One crucial thing is our choice of the form of the com rule.
   If we use the com' rule by Avron~\cite{avron91}, the proof does not
   proceed because the contexts $\G$ and $\D$ are duplicated as
   \[
   \BinaryRule
   {$\hypert_0\hmid\G,\D\tr\tj{M}{[i]\varphi}$}
   {$\hypert_1\hmid\G,\D\tr\tj{N}{[j]\psi}$}
   {}
   {$\hypert_0\hmid\hypert_1\hmid\G\tr\tj{(\comodL)M}{[i]\psi}\hmid
   \D\tr\tj{(\comodR)N}{[j]\varphi}$}\enspace.
   \]
   There, if we want to change the modalities in the rightmost component
   naively, we also have to change the modalities in the second
   rightmost component.
   }.
  \end{proof}

\subsubsection{Strong Normalization}
\newcommand{\sreduce}{\leadsto}

For proving strong normalization, we use an auxiliary relation, which is
similar to the reduction $\reduce$.  We denote
the relation by $\leadsto$.  The $\leadsto$ relation (symmetric
reduction) is also a
congruence.  All reductions are symmetric reductions.
In addition to reductions, symmetric reductions contain pairs like
$\cotuple{M, N}\sreduce N$ when $N$ does not contain any~$\abort$,
$\comodL$ or $\reader c$.
Ordinary reductions are not symmetric because it allows
$\conf{}{\imapsto{\cotuple{M,N}}}\areduce \conf{}{\imapsto{M}}$
but not
$\conf{}{\imapsto{\cotuple{M,N}}}\areduce \conf{}{\imapsto{N}}$%
.  This asymmetricity allows us to encode waitfree
computation in our calculus.  However, it is easier to prove strong
normalization for the symmetric reductions.  When strong normalization
for the symmetric reductions holds, the same property holds for the
reductions because there are less pairs in reductions than in symmetric
reductions.

\begin{theorem}[Strong normalization of \lgd]
 \label{first:sn}
 \lgd\, is strongly normalizing.
\end{theorem}
\begin{proof}
For proving this, we consider the \textit{pure fragment}\index{pure fragment}
 that does not contain
$(\comodL)M$, $(\comodR)N$.
We first reduce the strong
normalization of the \lgd\, to that of the pure fragment, and
ultimately to that of de Groote's
natural deduction with permutation-conversion~\cite{Philippe2002js}%
\footnote{
To the
same effect, we might be able to use other strong normalization
 results for lambda calculi with commutative conversions, like Balat,
 Di~Cosmo
 and Fiore~\cite{bdf}.
}%
.

We assume an infinitely long sequence of reductions, namely,
$
\conf{_0}{\hypert_0}
\reduce
\conf{_1}{\hypert_1}
\reduce
\conf{_2}{\hypert_2}
\reduce\cdots
$.
From this, we are going to construct an infinitely long sequence of
symmetric reductions in the pure fragment.

For that, we first
build an infinite reduction sequence with constant stores.
Using the original infinite sequence, we define a pair of stores called the
\textit{store prophecy}\index{store!--- prophecy} $\lstore_\infty$ where
$ \lstore_\infty(c)$ is defined to be $\epsilon$ if
 $\lstore_k(c)=\epsilon$ holds for all
 $k\in\omega$ and
$ \lstore_\infty(c) $ is defined to be $M $ if $\lstore_k(c)=M$ holds for some $k\in\omega$.
Since store contents are never overwritten,
$\lstore_\infty$ is well defined.
Moreover,
$\lstore_i(c)$ and $\lstore_\infty(c)$ coincide unless
$\lstore_i(c)=\epsilon$.

We build another reduction sequence
$
\conf{_\infty}{\hypert_0}
\reduce^\ast
\conf{_\infty}{\hypert'_1}
\reduce^\ast
\conf{_\infty}{\hypert'_2}
\reduce^\ast\cdots
$
with the following invariant:
$\mathcal O'_i$ can be obtained by replacing some $\abort$ occurrences
in $\mathcal O_i$ with some terms.
More specifically, we translate each reduction as follows, keeping the
invariant inductively on the number of steps
(the base case is satisfied by $\mathcal O'_0 = \mathcal O_0$ immediately):
\begin{itemize}
 \item a read reduction $\conf{_k}{\hypc{}{\reader c}}
       \rreduce
       \conf{_{k+1}}{\hypc{}{O}}$ is translated into
       $\conf{_\infty}{\hypc'{\reader c}} \rreduce
       \conf{_{k+1}}{\hypc'{O'}}$.
       If $\lstore_i(c)$ is a term,
       $\lstore_\infty(c)$ and $O'$ are also identical to the term.
       Otherwise, $O'$ must be $\abort$.
       Thus, the invariant
       holds for $k+1$.
 \item a write reduction $\conf{[c\mapsto \epsilon]}{\hypc{}{(\comodR)M}} \wreduce
	\conf{[c\mapsto M]}{\hypc{}{\reader d}}
	$ is translated into
       $\conf{_\infty}{\hypc'{(\comodR)M}} \wreduce
	\conf{_\infty}{\hypc'{\reader d}}
	$;
 \item an $\abort$ reduction of the form
       $\conf{_k}{\hypc{}{C[\abort]}} \areduce
       \conf{_{k+1}}{\hypc{}{\abort}}$ can be translated
       either to a similar reduction or no reduction if the $\abort$ in
       the redex is replaced by another term in the ${\hypert'}_k$.
       Note that even in that case, the result ${\hypert'}_{k+1}$ can
       be obtained by replacing some $\abort$ occurrences in
       $\hypert_{k+1}$ with other terms;
 \item any other reduction $\conf{_k}{\hypc{}{M}} \bpreduce
       \conf{_{k+1}}{\hypc{}{N}}$
       is translated into one similar reduction
       $\conf{_\infty}{\hypc{'}{M'}}\bpreduce
        \conf{_\infty}{\hypc{'}{N'}}$.
\end{itemize}
Here, we have to show that the translated sequence of symmetric
reductions is infinite.
For that, we can use the facts that there are only finite
number of mentioned locations and that each location allows only one
 write, and that an $\abort$ propagation always
strictly shortens the term under operation.

 After that, we can replace
 every ${\reader c}$ with
 $\lstore_\infty(c)$.
 Since $\reader c$ either reduces to $\lstore_\infty(c)$ or $\abort$,
 replacing it with $\lstore_\infty(c)$ will only ``shorten'' the reduction
 sequence for at most one read step.
 Replacing all readers
 makes an infinite reduction sequence in the pure fragment.
 Moreover,
 the result of the translation is also well typed\footnote{Because each
 channel~$c$ is uniquely associated with a type~$\phi$ in the original
 derivation and $\lstore_\infty(c)$ is a closed term of type~$\phi$.}.
 A typing derivation of the resulting hyperterm can be obtained by
 replacing com rules with EW rules and changing the process number in
 global types of some variables (c.f. the proof of \thref{nab}).

 We are aiming at reducing the problem to the strong normalization result
 by de Groote~\cite{Philippe2002js}.
 Since we have eliminated $(\comodL)M$ and $(\comodR)N$ occurrences,
 the remaining difference from \citet{Philippe2002js}'s lambda calculus
 is small: some abort propagation reductions
 and some permutative reductions involving $\cotuple{M,N}$.
 We just have to make sure that there are no infinite reduction sequences
 that consist of these two kinds of reductions only.
 We can deal with the permutative reductions following de
 Groote~\cite{Philippe2002js}'s strategy for introducing~$\bot$.
 There are no infinite sequence of abort propagation reductions keeping the
 number of $[M,N]$ constructions; and an abort propagation reduction cannot increase
 the number of $[M,N]$ constructions in a configuration.  Combined,
 there are no infinite sequence of abort propagation reductions.
\end{proof}

Strong normalization and non-abortfullness hold even for reductions
where $\comodL$ operators are copied or discarded.  This is different
from the situation in Chapter~\ref{ch:exchange} where
discarding term~$c$ causes the peer $\co c$ to
deadlock.  This is the reason why we can use intuitionistic
propositional logic rather than linear (or affine) logics in this chapter.

% \fix{subformula property around here state in 6min}

% \fix{prove subfmla in 90min}

\section{Typed Waitfreedom}
\label{waitfreedom}

Waitfree protocols~\cite{Herlihy88,Saks:1993vq} are a class of protocols
that can solve
some of the input-output problems~\cite{Moran:1987ep,Biran:1988hh}.
If a waitfree protocol solves an input-output problem, then the protocol
belongs to the waitfreedom.
We define the typed version of waitfreedom.
Since these definitions are involved, we supplied many examples.

\subsection{Typed Input-Output Problem}

Saks and Zaharoglou~\cite{Saks:1993vq} formulated waitfreedom as a class
of input-output
problems.
Given inputs for all processes and outputs of all
processes, an input-output problem decides whether the processes have
succeeded or not.
We change the standard definition and have typed terms as inputs and
outputs.
This change is necessary because according to the original definition of
waitfreedom,
a single process waitfree protocol can solve any undecidable problem
because a waitfree protocol can contain arbitrary functions.

\newcommand{\true}{\texttt{t\kern -1.2pt t}}
\newcommand{\false}{\texttt{f\kern -1.7pt f}}
In order to define the set of inputs and outputs, we let
$\lterm(\varphi)$ denote the set of closed, pure terms of
type~$\varphi$,
and $\lval(\varphi)$ denote the set of normal terms in $\lterm(\varphi)$.
For a finite set of processes~$\processes$,
a \textit{typed input-output problem}\index{typed input-output problem} consists
of each process's input type
$(\iota_i)_{i\in \processes}$, each process's output type $(o_i)_{i\in
\processes}$, and a
task $R\subseteq \prod_{i\in \processes}\left(\lterm(\iota_i)\right)\times
 \prod_{i\in \processes}\left(\lval(o_i)\right)$.
 In words, a task~$R$ decides whether a pair of inputs and outputs is
 good or not.

 \begin{example}[The addition problem]
  \label{ex:xor}
  Let the set~$\processes$ be $\{0,1\}$,
  the types $\iota_0$, $\iota_1$, $o_0$ and $o_1$ be
  natural numbers\footnote{Actually, the type of natural numbers is not
  definable in our language.
  However, since we can define a three-valued type, we can make the same
  argument below using $\mathbb{Z}/3$ instead of natural numbers.
  }.
  Now we can define a task requiring at least one of the processes outputs
  the addition of the inputs.  Specifically,
  \begin{align*}
   R_{+} =&
   \{\tuple{\{0\mapsto x, 1\mapsto y\},\{0\mapsto (x + y), 1\mapsto z\}}\mid
   x,y,z\in\mathbb{N}\}
   \\ & \cup \{\tuple{\{0\mapsto x, 1\mapsto y\},\{0\mapsto z, 1\mapsto
   (x + y)\}}\mid
   x,y,z\in\mathbb{N}\}\enspace.
  \end{align*}
  The equation above says the task~$R_{+}$ allows two different kinds of
  behavior.  The first clause says if process~0 receives $x$ and
  process~1 receives $y$ as their inputs, and process~0 outputs $x +
  y$; then whatever process~1 outputs, the two processes are considered
  to have solved the task.  The second clause poses a symmetric
  condition where the two processes are swapped.
  In order to solve the task~$R_{+}$,
  it is enough for one of the two processes to give the correct answer.
 \end{example}
 \begin{example}[The exchange problem]
  \label{ex:exchange}
  There is another problem that requires
  two processes to exchange their inputs.  Namely,
 \begin{align*}
  R_{\mathtt{exch}} =&
  \{\tuple{\{0\mapsto x, 1\mapsto y\},\{0\mapsto y, 1\mapsto x\}}\mid
  x,y\in\{\true,\false\}\}\enspace.
 \end{align*}
 \end{example}

\subsection{Typed Protocols}

We assume a finite set~$\processes$
of processes and a countably infinite
set of \textit{program variables}\index{program
variable}\index{variable!program}
$\ProV =\{\p x, \p y, \p z, \ldots\}$.
Program variables are typed in the typewriter font.
We assume an injection from variables to program variables $x\mapsto
\p{x}_x$, whose image leaves infinitely many unused program variables.

A \textit{program}\index{program} is defined by BNF:
\[
 p ::= \epsilon\mid
 \p x\leftarrow E; p \mid
 c \leftarrow E; p
\]
where $c$ is a location and an \textit{expression}\index{expression}~$E$ is
\begin{align*}
 E
 ::=\,\,
 &x\mid \p x \mid c \mid (EE)\mid \lambda
 x.E\mid \tuple{E,E}\mid \linl{E}\mid \linr{E}\mid \\
 &\lpil{E}\mid\lpir{E}\mid  \mat E x {E} y {E}\mid \epsilon\enspace.
\end{align*}
Here, the expression~$\epsilon$ is used as the initial placeholder of the shared
memory.

\newcommand{\Wg}{W_{\mathrm g}}
\newcommand{\Wd}{W_{\mathrm d}}
A program is \textit{well formed}\index{well formed
program}\index{program!well formed} when
any program variable~$\p x$ (resp. location~$c$) first appears in a $\p x\leftarrow E$
(resp. $c\leftarrow E$)
sentence where $E$ does not contain $\p x$ (resp. $c$), and
after that, only appears in expressions.
In other words, a well-formed program is in the single assignment form.

A \textit{contexed type}\index{contexted type}
 $\Gamma\tr\m\varphi$ is a sequent without a term but with variables in
 $\Gamma$.
For a contexted type $(\Gamma\tr\m\varphi)$,
we write $\tj{M}{(\Gamma\tr\m\varphi)}$ for
$\Gamma\tr\tj{M}{\m\varphi}$.
For input types $(\iota_i)_{i\in\processes}$
and output types $(o_i)_{i\in\processes}$,
a \textit{typed protocol}\index{typed protocol}\footnote{We formulated this definition
 as close as we can to the definition of waitfree protocols in \citet[\textbf{2.3.}]{saks2000wait}.} has:
\begin{itemize}
 \item two program variables
      $\p i_i$ and $\p o_i$ for each process~$i$;
 \item a finite set of locations~$C$;
 \item two functions $w\colon C\rightarrow \processes$
       and $r\colon C\rightarrow
       \processes$ (specifying the writer and the reader of
       each location);
 \item $W$: maps a location in $C$ to a contexted type;
 \item $V$: a finite set of program variables that contains $\p i_i$'s
       and $\p o_i$'s;
 \item a function~$t_i$ for each $i\in \processes$;
       that maps a program variable in $V$ to a contexted type
       $(\tj{x_k}{[i]\phi_k})_k \tr[i]\varphi$ with a special condition
       $t_i(\p i_i)= \iota_i$;
 \item a typed program~$p_i$ for each $i\in \processes$, where
       a \textit{typed program}\index{typed program} is a well-formed
       program where all
       sentences are typed according to the rules below.
       A sentence $\p x \leftarrow E$ is typed  iff $\tr E\colon [i]t_i(\p
       x)$ is derivable with assumptions of the form $\tr\tj{\p y}{[i]t_i(\p
       y)}$ and $\tr\tj{c}{W(c)}$.
       A sentence $c\leftarrow E$ is typed iff
       $\tr\tj{E}{[i]W(c)}$ is derivable with
       assumptions of the form $\tr\tj{\p y}{[i]t(\p y)}$ and
       $\tr\tj{c}{[i]W(c)}$.
\end{itemize}
 \begin{example}[The addition protocol]
  \label{ex:xor-protocol}
  We give a concrete typed protocol that solves the addition task
  (Example~\ref{ex:xor}).
  The set of locations~$C$ contains two elements $c$ and $d$.
  The locations $c$ and $d$ will be used as follows:
  process~0 writes to $d$ and reads from $c$, and process~1
  writes to $c$ and reads from $d$.
  Formally, $w(c) = 1$, $w(d) = 0$, $r(c) = 0$ and $r(d) = 1$.
  Both locations will contain natural numbers.
  Formally, $W(c) = W(d) = \mathbb{N}$.
  The set of program variables~$V$ is just $\{\p i_0, \p i_1, \p o_0, \p
  o_1\}$.
  The typed programs are
  \begin{align*}
   p_0 &= d\leftarrow \p i_0; \p o_0\leftarrow add(c, \p i_0); \p o_0
   \leftarrow \p i_0 \text{ and }\\
   p_1 &= c\leftarrow \p i_1; \p o_1\leftarrow add(d, \p i_1); \p o_1
   \leftarrow \p i_1
  \end{align*}
  where $add(M,N)$ is a specially introduced\footnote{If we choose
  $\mathbb{Z}/3$, we do not need to introduce a special term, but we can
  define addition using nested \textsf{match} constructs.}
  term that reduce to the sum.
  We omit the type assignments $t_0, t_1$ and typing derivations.
 \end{example}

\subsection{Typed Waitfree Computation}

We define when a typed protocol solves a typed
input-output problem.
This definition is obtained by modifying \citet{Saks:1993vq}'s
definition of input-output problems.

A closed local term~$M$ is \textit{of} type~$\varphi$ iff there is
a derivation of $\tr \tj{\{0\mapsto M\}}{[0]\varphi}$.
Let $\processes$ be $\{0,\ldots, n-1\}$ and fix a typed protocol.
We are going to define a virtual machine for executing the typed
protocol.
In order to do that, we first define snapshots of the virtual machine.
After this, we will define the transition from snapshots to snapshots.
 \begin{definition}
A \textit{program variable content}\index{program variable content} for
$i\in\processes$ is a
partial function that maps a program variable to a closed local term of
$t_i(\p x)$.
A global term~$\m M$ \textit{is of} a contexted type $\Gamma\tr\m\varphi$ when
$\Gamma\tr\tj {\m{M}}{\m\phi}$ is derivable.
A \textit{process snapshot}\index{process snapshot} of $i\in\processes$ is a tuple
$\tuple{p,m}$ where $p$ is either a program or $\abort$ and $m$ is a
program variable content for $i$.
We let $S_i$ denote the set of process snapshots for~$i$.
A \textit{system snapshot}\index{system snapshot}
is a pair $\tuple{\vec s, \vec v}$ of process snapshots and a shared
memory snapshot, where $\vec s = \tuple{s_0,
{s_1,{\ldots,s_{n-1}}}} \in
\prod_{i\in \processes}\left(S_i\right)
$
and
$\vec v =
\left(v_c\right)_{c\in C} \in \prod_{c\in C}(\val(W(c))\cup\{\epsilon\})
$.
 \end{definition}

  \begin{definition}
For a nonempty subset~$J$ of $\processes$, we define an operator $\update J$ that
takes a system snapshot and produces a system snapshot.
This operator depicts a computational step where the processes in~$J$
are fired.

We define $
(\vec s, \vec v) \update J = (\vec u, \vec m)$
by defining $u_i$ and $m_c$ for $i\in\processes$ and $c \in C$.
Let $s_i$ be $\tuple{p,x}$:
when $i$ is not in $J$, $u_i$ is identical to $s_i$; otherwise, when $i$
is in $J$:
\begin{align*}
 u_i & =
   \begin{cases}
    \tuple{p',x}  & (\text{if } p = c
    \leftarrow E; p' \text{ and }\semo{E}_{x,\vec v} = \epsilon)
    \\
    \tuple{p', x[\p x \mapsto \semo{E}_{x, \vec v}]}&
    (\text{if } p = \p x \leftarrow E; p', \quad
    x(\p x) = \epsilon  \text{ and } \semo{E}_{x, \vec v} \neq \epsilon)
    \\
    \tuple{p', x} & (\text{if } p = \p x \leftarrow E; p' \text{
    but } x(\p x)\neq \epsilon \text{ or }\semo{E}_{x,\vec v} = \epsilon
    ) \\
    \tuple{\epsilon, x} & (\text{if } p = \epsilon)
   \end{cases}\\
 m_c & =
   \begin{cases}
   \semo{E}_{x, \vec v} & (\text{if } p = c \leftarrow E; p',\quad w(c)= i
    \text{
   and } v_c = \epsilon) \\
   v_c &(\text{otherwise})
   \end{cases}\\
\end{align*}
with the following notations.
The term
$\semo{E}_{x, \vec v}$ is defined as the unique normal form
%{show, show, show}
of the local term~$E[x(\vec{\p y}) / \vec{\p y}][\vec{v_c}/\vec c]$, where
every program variable~$\p y$ is replaced by $x(\p y)$
and every location~$c$ is replaced by $v_c$.
If any of the substitutes is $\epsilon$,
$\semo{E}_{x, \vec v}$ is defined to be $\epsilon$.
  \end{definition}

   \begin{definition}
A \textit{schedule}\index{schedule} is an infinite sequence of nonempty subsets
of~$\processes$,
which looks like $\sigma = \sigma_0\sigma_1\sigma_2\cdots$.
Each $\sigma_k$ is called a \textit{block}\index{block}.
We say $i$ is \textit{non-faulty}\index{non-faulty} (resp.~faulty\index{faulty}) in
$\sigma$ if it appears infinitely (resp. only finitely many) often.
When every process is non-faulty, the schedule is \textit{fair}\index{fair}.
   \end{definition}
 \begin{example}[An example of schedules]
  \label{ex:schedules}
  When $\processes$ is a singleton $\{0\}$, there is only one schedule
  $(\{0\},\{0\},\{0\},\ldots)$ where ``$\ldots$'' contains only $\{0\}$'s.
  Since 0 is the only process and 0 is non-faulty, this schedule is fair.

  Assume $\processes = \{0,1\}$.
  There is a schedule which is not fair: $(\{0\}, \{0\}, \{0\}, \ldots)$
  where ``$\ldots$'' contains only $\{0\}$'s.
  Even when we add a finite prefix to an unfair schedule, the schedule
  is still not fair because no process can appear infinitely often in that
  finite prefix.

  Obviously, when a schedule contains infinitely many
  $\{0,1\}$'s, then the schedule is fair.  Not only that, but when a
  schedule contains infinitely many $\{0\}$'s and infinitely many $\{1\}$'s,
  then the schedule is fair.  On the other direction, a fair schedule
  must satisfy one of these conditions.
 \end{example}

  \begin{definition}
A \textit{run}\index{run} is a triple $\tuple{\Pi, \vec x, \sigma}$,
where $\Pi$ is a typed protocol,
$\vec x \in \prod_{i\in \processes} \lterm(\iota_i)$ is the input,
and $\sigma$ is a schedule.
The \textit{execution}\index{execution} associated to the run
is defined as the infinite sequence of system snapshots
$C_0C_1C_2\cdots$, where $C_0 = \tuple{\vec{s^0}, \vec{v^0}}$ is
defined by $\vec{s^0_i} = \tuple{p_i, [\p i_i\mapsto x_i]}$ and
$v_c = \epsilon$, and $C_{k+1}$ is defined to be $C_{k}\update\sigma_{k}$.
Since all programs are finite, the system snapshot will stay constant
after initial finite steps.  We call that constant system snapshot the
\textit{final system snapshot}\index{final system snapshot}\index{system
snapshot!final}\index{snapshot!final system} of an execution.
  \end{definition}

 \begin{example}[An example of a run and an execution]
  Let $\processes$ be $\{0,1\}$ and $\Pi$ be the typed protocol given in
  Example~\ref{ex:xor-protocol}.
  let us take $x_0 = 3$ and $x_1 = 4$.
  Also we choose a schedule $\sigma$ as
  $\{0\}, \{0\}, \{0,1\}, \{1\}, \{1\}$, followed by an infinite
  sequence of $\{0,1\}$'s.
  The triple $\tuple{\Pi,\vec x,\sigma}$ constitutes a run.

  We can associate an execution with this run.
  The initial system snapshot $C_0=\tuple{\vec{s^0},\vec{v^0}}$ contains
  process snapshots
  \begin{align*}
   s_0^0 = \tuple{p_0,\{\p i_0\mapsto 3\}}\text{ and }
   s_1^0 = \tuple{p_1,\{\p i_1\mapsto 4\}}
  \end{align*}
  where $p_0$ and $p_1$ are defined in Example~\ref{ex:xor-protocol}.
  In the system snapshot, $\vec{v^0}$ maps both locations $c$ and $d$ to
  $\epsilon$.
  The next system snapshot $C_1$ is defined to be $C_0\update\sigma_0$.
  Since $\sigma_0 = \{0\}$, it does not contain 1.
  So, $s_1^1$ is the same as $s_1^0$.
  On the other hand, since $p_0$ is $d\leftarrow \p i_0; \p o_0\leftarrow
  add(c, \p i_0); \p o_0
   \leftarrow \p i_0$, $s_0^1$ is defined to be
  $\tuple{\p o_0\leftarrow
  add(c, \p i_0); \p o_0
   \leftarrow \p i_0, \{\p i_0\mapsto 3\}}$ and
  $v_d^1$ is defined to be $3$.
  However, $v_c^1$ is the same as $v_c^0$ and thus remains to be
  $\epsilon$.
  We conclude that $C_1=\tuple{\{0\mapsto s_0^1,1\mapsto s_1^1\},
  \{c\mapsto \epsilon, d\mapsto 3\}}$.
  Again, the next snapshot $C_2$ is defined to be $C_1\update \sigma_1$.
  Since $\sigma_1 = \{0\}$, process~1's state is not changed so that
  $s_0^2 = s_0^1 = \tuple{p_1,\{\p i_1\mapsto 4\}}$.
  On the other hand, since $s_0^1 = \tuple{\p o_0\leftarrow
  add(c, \p i_0); \p o_0
   \leftarrow \p i_0, \{\p i_0\mapsto 3\}}$ and 0 is in $\sigma_1$,
  process~0's state is updated to
  $s_0^2 = \tuple{\p o_0
   \leftarrow \p i_0, \{\p i_0\mapsto 3\}}$
  where the process failed to read from the location~$c$ because $v_c^1$
  is $\epsilon$.  As a result, the program variable~$\p o_i$ obtained
  no assignments.
  The store contents are not updated either so that $v_c^2 = v_c^1 =
  \epsilon$ and $v_d^2 = v_d^1 = 3$.
  After four more rounds (including $i = 6$ to confirm $C_5 = C_6$), we
  obtain an execution shown in Table~\ref{table:exec}.
  Since $C_i = C_5$ for $i > 5$, the system snapshot~$C_5$ is the final
  system snapshot of this execution.
 \end{example}
  \begin{sidewaystable}
   \centering
   \caption{An example of execution of a typed protocol defined in
   Example~\ref{ex:xor-protocol}.
   }
   \label{table:exec}
   \begin{tabular}{cllcc|l}
    $i$    & $s_0^i$&$s_1^i$ &$v_c^i$ &$v_d^i$ & $\sigma_i$ \\ \hline
    0      & $\tuple{d\leftarrow \p i_0; \p o_0\leftarrow add(c, \p i_0); \p o_0
   \leftarrow \p i_0, \{\p i_0\mapsto 3\}}$
	& $\tuple{c\leftarrow \p i_1; \p o_1\leftarrow add(d, \p i_1); \p o_1
   \leftarrow \p i_1, \{\p i_1\mapsto 4\}}$
	    & $\epsilon$
		& $\epsilon$
		    & $\{0\}$ \\ \hline
    1      & $\tuple{\p o_0\leftarrow
        add(c, \p i_0); \p o_0
        \leftarrow \p i_0, \{\p i_0\mapsto 3\}}$
	& $\tuple{c\leftarrow \p i_1; \p o_1\leftarrow add(d, \p i_1); \p o_1
   \leftarrow \p i_1, \{\p i_1\mapsto 4\}}$
	    & $\epsilon$
		& $3$
		    & $\{0\}$ \\ \hline
    2      & $\tuple{\p o_0
        \leftarrow \p i_0, \{\p i_0\mapsto 3\}}$
        & $\tuple{c\leftarrow \p i_1; \p o_1\leftarrow add(d, \p i_1); \p o_1
            \leftarrow \p i_1, \{\p i_1\mapsto 4\}}$
	    & $\epsilon$
		& $3$
		    & \{0,1\} \\ \hline
    3      & $\tuple{\epsilon, \{\p i_0\mapsto 3, \p o_0 \mapsto 3\}}$
        & $\tuple{\p o_1\leftarrow add(d, \p i_1); \p o_1
   \leftarrow \p i_1, \{\p i_1\mapsto 4\}}$
	    & $4$
		& $3$
		    & $\{1\}$ \\ \hline
    4      & $\tuple{\epsilon, \{\p i_0\mapsto 3, \p o_0 \mapsto 3\}}$
	& $\tuple{\p o_1
   \leftarrow \p i_1, \{\p i_1\mapsto 4, \p o_1\mapsto 7\}}$
	    & $4$
		& $3$
		    & $\{1\}$\\ \hline
    $\ge 5$& $\tuple{\epsilon, \{\p i_0\mapsto 3, \p o_0 \mapsto 3\}}$
	& $\tuple{\epsilon, \{\p i_1\mapsto 4, \p o_1\mapsto 7\}}$
	    & $4$
		& $3$
		    & $\{0,1\}$ \\ \hline
   \end{tabular}
  \end{sidewaystable}

   \begin{definition}
Process~$i$'s \textit{output}\index{output}~$\hat{o_k}$ at step~$k$ is
$M$ if the $i$-th process snapshot of $C_k$ is
$(p, x)$ and the $x[\p{o}_i] = M$, which might be $\epsilon$.
The \textit{decision value}\index{decision value}\index{value!decision}
of $i$ on the run $\tuple{\Pi,\vec x,\sigma}$,
denoted~$d_i \in \lval(o_i)\cup\{\epsilon\}$
 is the first non-$\epsilon$ output in the sequence
 $\left(\hat{o_k}\right)_{k\in\omega}$,
 or
$\epsilon$ if such an output does not exist.
The \textit{decision vector}\index{vector!decision} of the run is
the $n$-tuple~$\vec d$ consists of decision value $d_i$'s.
   \end{definition}

A vector $\vec b\in \prod_{i\in \processes}(\lval(o_i))$
is \textit{compatible with}\index{compatible with} $\vec d \in \prod_{i\in
\processes}\left(\lval(o_i)\cup\{\epsilon\}\right)$ iff
$d_i = b_i$ or $d_i = \epsilon$ holds for any process~$i$.
For a task~$R$,
an input~$\vec x\in \prod_{i\in \processes}\lterm(\iota_i)$
is \linebreak[2] $R$-\textit{permissible}\index{permissible} iff there
is at least one
vector $\vec b\in \prod_{i\in \processes}(\lval(o_i))$ with $(\vec x,
\vec b)\in R$.
 \begin{definition}
A typed protocol~$\Pi$ \textit{solves}\index{solve!typed protocol --- typed
input-output problem} the typed input-output problem
  $\tuple{(\iota_i)_{i\in \processes}, (o_i)_{i\in \processes}, R}$ on
schedule~$\sigma$ iff for all $R$-permissible inputs~$\vec x$ and a
schedule~$\sigma$,
 the decision value of every non-faulty process~$i$ is a term
       $M$ not $\epsilon$, and
 there is a vector $\vec b\in \prod_{i\in \processes}(\lval (o_i))$
 with $\tuple{\vec x, \vec b} \in R$ which is compatible with the
 decision vector~$\vec d$ of the run $\tuple{\Pi,\vec x,\sigma}$.
 A typed protocol is \textit{waitfree}\index{waitfree} iff it solves
 the problem on every schedule~$\sigma$.
 In that case, the typed input-output problem is
 \textit{waitfreely solvable}\index{waitfreely solvable}.
 \end{definition}

 \begin{example}[Permissible inputs and outputs]
  The compatible inputs for the addition problem in
  Example~\ref{ex:xor} are pairs of natural numbers.
  For the input $(3,4)$, the addition of the inputs is
  $7$,
  but the addition problem requires at least one process to output
  the sum.
  Moreover, when process~0 is faulty, process~0 is allowed to output
  $\epsilon$.
  In that case, whatever natural number process~1 outputs,
  the addition problem is solved because any $(\epsilon,n) (n\in
  \mathbb{N})$ is
  compatible with some vector $\vec b$ in $R_{+}$.
  In short, in the addition problem, if one process outputs
  $\epsilon$, the other process is allowed to output whatever.
 \end{example}

 \begin{example}[An example of a typed protocol solving the addition task]
  \label{ex:solv}
  In the execution in Table~\ref{table:exec}, we can replace $3$ and $4$
  with any natural numbers and $7$ with the sum.
  This shows that the typed protocol in Example~\ref{ex:xor-protocol}
  solves the addition problem in Example~\ref{ex:xor} on the
  schedule
  \[
  \sigma = (\{0\}, \{0\}, \{0,1\}, \{1\}, \{1\}, \{0,1\}, \{0,1\},\ldots)
  \] where
  the last ``$\ldots$'' represents an infinite sequence consisting of
  $\{0,1\}$'s.
  On schedule~$\sigma$, both processes 0 and 1 are non-faulty.
  In Table~\ref{table:exec}, the decision value of process~0 is $d_0 =
  3$ and the decision value of process~1 is $d_1=7$.
  The tuple $\tuple{(x_0,x_1),(d_0,d_1)}$ is in $R_{+}$.
  The same argument goes for different $(x_0,x_1)$'s.
  Thus, the typed protocol solves the addition problem on schedule~$\sigma$.
  Actually, the typed protocol solves the problem for all schedules.
  To see why, we can do case analysis on an arbitrarily taken schedule:
  one case where all processes produce non-$\epsilon$ outputs and the other case where
  one of the prcesses produces a non-$\epsilon$ output.  There is no possibility where no
  processes produce non-$\epsilon$ outputs because there are infinitely many blocks in a
  schedule and each block contains at least one process (by definition
  of a block).
  In the first case, when the first block
  contains 0, the execution proceeds like in Table~\ref{table:exec}.
  Otherwise, the first block must contain 1 so that the execution
  proceeds like Table~\ref{table:exec} with 0 and 1 swapped.
  In either case, the typed protocol solves the task.
  In the second case, the output producing process can
  produce whatever output to meet the task because the other process
  produces~$\epsilon$.
 \end{example}
  \begin{example}[An example of waitfreely unsolvable typed input-output
   problem]
   On the other hand, there is no typed protocol that solves
   the exchange problem (Example~\ref{ex:exchange}).
   To see the reason, take any typed protocol.
   There exist natural numbers $m$ and $n$ so that
   the typed protocol contains $m$ commands
   for process~0 and $n$ commands for process~1.
   Consider a schedule that consists of the first~$m$ blocks $\{0\}$ and
   the following~$n$ blocks $\{1\}$ and the rest $\{0,1\}$.
   Thus process~0 finishes before process~1 starts so that process~0
   cannot learn process~1's input.
   Because of the infinitely many $\{0,1\}$'s at the tail,
   under the schedule, both processes are non-faulty so that they must
   produce the correct outputs.
   However, since process~0 finishes before process~1 starts, there is
   no way process~0 can output process~1's input, not by chance.
   Even when process~0 produces the correct output by chance, when we
   change process~1's input, then, process~0's output is wrong with
   regard to process~1's new input.
  \end{example}


\section{Characterization of Waitfreedom by \lgd}
\label{comparison}

In this section,
we show that the ability of the waitfree protocols and \lgd\, are the same.
\begin{definition}
 \label{def:solvable}
 A typed input-output problem
 $\tuple{(\iota_i)_{i\in \processes}, (o_i)_{i\in \processes}, R}$ is
 solvable by a global term
 $\m M$ of contexted type
 $\left(\tj{x_i}{[i]\iota_i}\right)_{i\in\processes}
 \tr\left(o_i\right)_{i\in \processes}$ iff
 for any closed $(N_i)_{i\in \processes}$ of $\iota_i$,
 all normal forms of $\m{M}[\vec{N_i}/\vec{x_i}]$
 are in the form $(V_i)_{i\in\processes}$
 where $\tuple{(N_i)_{i\in \processes}, (V_i)_{i\in \processes}}\in R$.
 % looks like we assume subformula property
\end{definition}

 \begin{example}[A global term solving the addition problem]
  For the exclusive-or problem (defined in Example~\ref{ex:xor}), there is
  a global term $\{0\mapsto \cotuple{add((\comodL)x_0,x_0),x_0},
  1\mapsto\cotuple{add((\comodR)x_1,x_1),x_1}\}$ that solves the
  problem.
  The global term can be typed as in Figure~\ref{fig:solving}.
 \end{example}


 \begin{sidewaysfigure}  %fig:solving
  \centering
   \begin{flushleft}
    \textsf{Part A}
   \end{flushleft}
  \AxiomC{}
  \LL{Ax}
  \UnaryInfC{$\tj{x}{[0]\mathbb{N}}\tr\tj{x}{[0]\nat}$}
  \AxiomC{$\vdots$}
  \LL{$add$}
  \BinaryInfC{$
  \tj{x}{[0]\nat}\tr\tj{\{0\mapsto add((\comodL)x,x)\}}{[0]\nat}\hmid
  \tj{y}{[1]\nat}\tr\tj{\{1\mapsto (\comodR)y\}}{[1]\nat}
  $}
  \AxiomC{}
  \LL{Ax}
  \UnaryInfC{$\tj{y}{[1]\nat}\tr\tj{y}{[1]\nat}$}
  \LL{$add$}
  \BinaryInfC{$
  \tj{x}{[0]\nat}\tr\tj{\{0\mapsto add((\comodL)x,x)\}}{[0]\nat}\hmid
  \tj{y}{[1]\nat}\tr\tj{\{1\mapsto add((\comodR)y,y)\}}{[1]\nat}
  $}
  \DisplayProof
  \begin{flushleft}
   \textsf{Part B}
  \end{flushleft}
  \AxiomC{}
  \LL{Ax}
  \UnaryInfC{$\tj{y}{[1]\nat}\tr\tj{y}{[1]\nat}$}
  \AxiomC{$\vdots$}
  \LL{$\wedge\intro$}
  \BinaryInfC{$
  \tj{x}{[0]\nat}\tr\tj{\{0\mapsto
  {add((\comodL)x,x)},
  1\mapsto{y}
  \}}{\{0\mapsto \nat, 1\mapsto \nat\}}\hmid
  $}
  \noLine
  \UnaryInfC{$
  \tj{y}{[1]\nat}\tr\tj{\{1\mapsto {add((\comodR)y,y)}\}}
  {[1]\nat}
  $}
  \AxiomC{}
  \LL{Ax}
  \UnaryInfC{$\tj{x}{[0]\nat}\tr\tj{x}{[0]\nat}$}
  \LL{$\wedge\intro$}
  \BinaryInfC{$
  \tj{x}{[0]\nat}, \tj{y}{[1]\nat}\tr
  \tj{\{
  0\mapsto {add((\comodL)x,x)}, 1\mapsto {y}
  \}}
  {\{0\mapsto \nat, 1\mapsto \nat\}}
  \hmid
  $}
  \noLine
  \UnaryInfC{
  $
  \tj{x}{[0]\nat}, \tj{y}{[1]\nat}\tr
  \tj
  {\{
  0\mapsto {x},
  1\mapsto {add((\comodR)y, y)}
  \}}
  {\{0\mapsto\nat
  , 1\mapsto \nat
  \}}
  \phantom{\hmid}$
  }
  \DisplayProof
  \begin{flushleft}
    \textsf{Whole Derivation}
  \end{flushleft}
  \AxiomC{}
  \LL{Ax}
 \UnaryInfC{$\tj{x}{[0]\nat}\tr\tj{\{0\mapsto x\}}{[0]\nat}$}
  \AxiomC{}
  \LL{Ax}
 \UnaryInfC{$\tj{y}{[1]\nat}\tr \tj{\{1\mapsto y\}}{[1]\nat}$}
 \LL{01-com}
 \BinaryInfC{
 $
  \tj{x}{[0]\nat}\tr\tj{\{0\mapsto (\comodL)x\}}{[0]\nat} \hmid
  \tj{y}{[1]\nat}\tr\tj{\{1\mapsto (\comodR)y\}}{[1]\nat}$
 }
  \LL{\textsf{Part A}}
 \doubleLine
  \UnaryInfC{$
  \tj{x}{[0]\nat}\tr\tj{\{0\mapsto{add((\comodL)x,x)}\}}
  {[0]\nat}
  \hmid
  \tj{y}{[1]\nat}\tr\tj{\{1\mapsto{add((\comodR)y,y)}\}}{[1]\nat}
  $}
  \LL{\textsf{Part B}}
  \doubleLine
 \UnaryInfC{
 $
 \tj{x}{[0]\nat}, \tj{y}{[1]\nat}\tr
 \tj{\{
  0\mapsto {add((\comodL)x,x)}, 1\mapsto {y}
  \}}
  {\{0\mapsto \nat, 1\mapsto \nat\}}
  \hmid
 $
 }
  \noLine
  \UnaryInfC{
  $
  \tj{x}{[0]\nat}, \tj{y}{[1]\nat}\tr
  \tj
  {\{
  0\mapsto {x},
  1\mapsto {add((\comodR)y, y)}
  \}}
  {\{0\mapsto
  \nat
  , 1\mapsto
  \nat
  \}}
  \phantom{\hmid}$
  }
  \LL{EC}
  \UnaryInfC{$
  \tj{x}{[0]\nat}, \tj{y}{[1]\nat}\tr\tj
  {\{
  0\mapsto \cotuple{{add((\comodL)x,x)},x},
  1\mapsto \cotuple{{add((\comodR)y,y)},y}
  \}}
  {\{
  0\mapsto \nat,
  1\mapsto \nat
  \}
  }
  $
  }
 \DisplayProof
  \ruleskip
  \caption[A typed global term that solves the exclusive-or
  problem.]
  {A typed global term that solves the exclusive-or
  problem~(Example~\ref{ex:xor}).}
  \label{fig:solving}
 \end{sidewaysfigure}

 Now we can state the most important results in this chapter.
\begin{theorem}[Soundness of \lgd\, with regard to waitfreedom]
 \label{th:soundness}
 If a typed input-output problem is solvable by a global term,
 there exists a typed protocol that solves the problem.
\end{theorem}

In order to prove this theorem,
we are going to translate a typed hyperterm into a typed protocol inductively
on the type derivations.
To make induction work, we use the following auxiliary notion.
An \textit{investigator}\index{investigator} is a partial map from processes
to program variables.
% A system snapshot satisfies a global formula%
% \index{satisfy!system snapshot ---s a global formula}~$\m\varphi$
% iff \fix{fill}.
% A system snapshot satisfies a context%
% \index{satisfy!system snapshot ---s a context} iff it
% satisfies every global formula in the context.
% A protocol\index{protocol} $p$ \textit{realizes a hypersequent}~$
% \left(\Gamma_0\vdash
% \m\varphi_0 \hmid \cdots\hmid\Gamma_{k}\vdash \m\varphi_{k}\right)$
% iff
% for any initial system snapshot satisfying
% every~$\Gamma_{k'}$,
% there exists a family of investigator sets
% $(I_{k'})_{k'\in\{0,\ldots,k\}}$ and,
% when $p$ is executed with any schedule,
% the resulting system snapshots eventually satisfy at least one of
% $\varphi_{k'}^+$.

For a typed
hyperterm~$\hypert$,
we will give $\semo{\hypert}$, which is a tuple of programs indexed
by~$\processes$.
Also, we define $\semoi{\hypert}$ at the same time as
$\semo{\hypert}$, where
$\semoi{\hypert}$ is a sequence of investigators.  The length of
$\semoi{\hypert}$ is the same as that of $\hypert$.
We refer to the last element of $\semoi{\hypert\hmid M}$ as
$\semoi{\hypert\hmid \overline{M}}$, the second to last element of
$\semoi{\hypert\hmid M\hmid N}$ as
$\semoi{\hypert\hmid \overline M\hmid N}$ and so on.
 \begin{example}[Specifying elements of a sequence]
Suppose $\semoi{\m{M}\hmid \m{N}} = \{0\mapsto \p x, 1\mapsto \p
  y\}\hmid \{0\mapsto \p z\}$.
  Then,
  $\semoi{\m{M}\hmid \overline{\m{N}}} = \{0\mapsto\p z\}$ and thus
  $\semoi{\m{M}\hmid \overline{\m{N}}}(0) = \p z$.
 \end{example}

We let $\epsilon$ denote $(p_i = \epsilon)_{i\in\processes}$.
Also, $(p_i)_{i\in\processes}; (q_i)_{i\in\processes}$ denotes
$(p_i; q_i)_{i\in\processes}$ where the
same program variable does not have multiple substitutions
(we can rename variables in the original typing derivation to satisfy
this).
And $(p)_j$ denotes $(q_i)_{i\in\processes}$ where $q_j = p$ and $q_i =
\epsilon$ for all $i\neq j$.
The definition is inductive over the type derivations. What we do below is
essentially compilation from lambda terms to imperative programs.
After three pages, there is an example showing compilation of a concrete
\lgd\,global term.
\begin{description}
 \item[$ij$-com]
      \begin{align*}
       &\semo{\hypert_0\hmid\hypert_1\hmid \imapsto{(\comodL) M}\hmid
       \jmapsto{(\comodR) N}} \\
       =& \semo{\hypert_0\hmid \imapsto{M}};
       \semo{\hypert_1\hmid \jmapsto{N}};\\
       &(d\leftarrow \semoi{\hypert_0\hmid\overline{\imapsto{M}}}(i); \p
       x\leftarrow c)_i; \\
       &(c\leftarrow \semoi{\hypert_1\hmid\overline{\jmapsto{N}}}(j); \p
       y\leftarrow d)_j\enspace,\\ \\
       &\semoi{\hypert_0\hmid\hypert_1\hmid \imapsto{(\comodL) M}\hmid
       \jmapsto{(\comodR) N}} \\=&
       \semoi{\overline{\hypert_0}\hmid \imapsto{M}} \hmid
       \semoi{\overline{\hypert_1}\hmid \jmapsto{N}}
       \hmid\\& \{j\mapsto\p y\}\hmid \{i\mapsto \p x\}
      \end{align*}
      where $\p x$ and $\p y$ are new variables not used in induction
      hypotheses (we omit writing this restriction on each case below),
 \item[EW] \begin{align*}
 \semo{\hypert\hmid \abort}=\semo{\hypert}\enspace,\quad
 \semoi{\hypert\hmid\abort}=&\semoi{\hypert}\hmid \emptyset\enspace,\quad
	   \end{align*}
 \item[EC] 
      \begin{align*}
         &\semo{ \hypert \hmid \left(\cotuple{M_i,N_i}\right)_{i\in I}
       } \\
       =& \semo{\hypert\hmid \left(M_i\right) \hmid
       \left(N_i\right)}; \\
       &\left(\p k_i\leftarrow
       \semoi{\hypert\hmid \overline{(M_i)}\hmid
       (N_i)}(i)
       ; \p k_i \leftarrow \semoi{\hypert\hmid {(M_i)}\hmid
       \overline{(N_i)}}(i)\right)_{i\in I},\\ \\
       &\semoi{ \hypert \hmid \left(\cotuple{M_i,N_i}\right)_{i\in I}
       }
       =
       \semoi{\overline{\hypert}\hmid \left(\cotuple{M_i,N_i}\right)_{i \in I}}
       \hmid \{i\mapsto \p k_i\}_{i\in I}
      \end{align*}
 \item[EE]
      \begin{align*}
       \semo{\hypert \hmid \m{N} \hmid \m{M} \hmid \hypert'}
       =&
       \semo{\overline{\hypert}\hmid \m{N}\hmid \m{M}\hmid \hypert'}
       \hmid \\
       &
       \semo{{\hypert}\hmid \m{N}\hmid \overline{\m{M}}\hmid \hypert'}
       \hmid \\
       &
       \semo{{\hypert}\hmid \overline{\m{N}}\hmid \m{M}\hmid \hypert'}
       \hmid \\
       &
       \semo{{\hypert}\hmid \m{N}\hmid \m{M}\hmid
       \overline{\hypert'}}\enspace,\\
       \semoi{\hypert \hmid \m{N} \hmid \m{M} \hmid \hypert'}
       =&
       \semoi{\overline{\hypert}\hmid \m{N}\hmid \m{M}\hmid \hypert'}
       \hmid \\
       &
       \semoi{{\hypert}\hmid \m{N}\hmid \overline{\m{M}}\hmid \hypert'}
       \hmid \\
       &
       \semoi{{\hypert}\hmid \overline{\m{N}}\hmid \m{M}\hmid \hypert'}
       \hmid \\
       &
       \semoi{{\hypert}\hmid \m{N}\hmid \m{M}\hmid
       \overline{\hypert'}}\enspace,
      \end{align*}
 \item[IC]
      \begin{align*}
       \semo{\hypert\hmid \m{M}[x/y]}&=
       \semo{\overline{\hypert}\hmid \m{M}} \hmid
       \semo{{\hypert}\hmid \overline{\m{M}}}[\p x_x/ \p x_y]\\
       \semoi{\hypert\hmid \m{M}[x/y]}&=
       \semoi{\overline{\hypert}\hmid \m{M}} \hmid
       \semoi{{\hypert}\hmid \overline{\m{M}}}[\p x_x/ \p x_y]
      \end{align*}
 \item[$\brac i$Ax]
      \begin{align*}
       \semo{x}=& \epsilon \enspace,\\
       \semoi{x}=& \{i\mapsto \p i_x\}\enspace,
      \end{align*}
 \item[${\brac{i}}\bot\elim$]
      \begin{align*}
       \semo{\hypert\hmid\{i\mapsto\abort\}}
       =&\semo{\hypert\hmid\{i\mapsto M\}} ; (\p x\leftarrow \epsilon)_i\enspace,\\
       \semoi{\hypert\hmid\{i\mapsto\abort\}}
       =&\semoi{\overline{\hypert}\hmid\{i\mapsto M\}} \hmid \{i\mapsto
       \p x\}\enspace,
      \end{align*}
 \item[$\brac i\supset\intro$]
\begin{align*}
 \semo{\hypert\hmid \{i\mapsto \lambda x.M\}}=
 & \semo{\hypert\hmid \imapsto{M}}; \left(\p z\leftarrow
 \lambda x. \semoi{\hypert\hmid\overline{\imapsto{M}}}(i)\right)_i \enspace,\\
 \semoi{\hypert\hmid \imapsto{\lambda x.M}} =& \semoi{\overline\hypert\hmid
 \imapsto{M}} \hmid \{i\mapsto \p z\}\enspace,
\end{align*}
 \item[$\brac i\supset\elim$]
\begin{align*}
 \semo{\hypert_0\hmid\hypert_1\hmid \imapsto{MN}}=&
 \semo{\hypert_0\hmid \imapsto{M}};
 \semo{\hypert_1\hmid \imapsto{N}};\\&
 \left(\p z\leftarrow \semoi{\hypert_0\hmid \overline{
 M}}(i)\,\,\semoi{\hypert_1\hmid \overline N}(i)\right)_i\enspace,\\
 \semoi{\hypert_0\hmid\hypert_1\hmid \imapsto{MN}} =&
 \semoi{\overline{\hypert_0}\hmid \imapsto{M}} \hmid
 \semoi{\overline{\hypert_1}\hmid \imapsto{N}}
 \hmid \{i\mapsto \p z\}\enspace,
\end{align*}
 \item[$\brac i\wedge\elim_0$]
\begin{align*}
 \semo{\hypert\hmid \imapsto{\lpil M}} =& \semo{\hypert\hmid \imapsto{M}};
 \left(\p z \leftarrow
 \lpil {\semoi{\hypert\hmid\overline{\imapsto{M}}}(i)}\right)_i\enspace, \\
 \semoi{\hypert\hmid \imapsto{\lpil M}}=& \semoi{\overline \hypert\hmid
 \imapsto{M}}\hmid \{{i\mapsto \p z}\}\enspace,
\end{align*}
 \item[$\brac i\wedge\elim_1$]
\begin{align*}
 \semo{\hypert\hmid \imapsto{\lpir M}} =& \semo{\hypert\hmid \imapsto{M}};
 \left(\p z \leftarrow
 \lpir{ \semoi{\hypert\hmid\overline{\imapsto{M}}}(i) }\right)_i\enspace, \\
 \semoi{\hypert\hmid \imapsto{\lpir{M}}}=& \semoi{\overline \hypert\hmid
 \imapsto{M}}\hmid
 \{{i\mapsto \p z}\}\enspace,
\end{align*}
 \item[$\brac i\vee\intro_0$]
\begin{align*}
 \semo{\hypert\hmid \imapsto{\linl{M}}} =
 & \semo{\hypert\hmid \imapsto{M}}; \left(\p z \leftarrow
 \linl{ \semoi{\hypert\hmid\overline{\imapsto{M}}}(i)}\right)_i\enspace, \\
 \semoi{\hypert\hmid \imapsto{\linl M}}=& \semoi{\overline \hypert\hmid
 \imapsto{M}}
 \hmid
 \{{i\mapsto \p z}\}\enspace,
\end{align*}
 \item[$\brac i\vee\intro_1$]
\begin{align*}
 \semo{\hypert\hmid \imapsto{\linr M}} =& \semo{\hypert\hmid \imapsto{M}};
 \left(\p z \leftarrow
 \linr{\semoi{\hypert\hmid\overline{\imapsto{M}}}(i)}\right)_i\enspace, \\
 \semoi{\hypert\hmid \imapsto{\linr{M}}}=& \semoi{\overline \hypert\hmid
 \imapsto{M}}\hmid
 \{{i\mapsto \p z}\}\enspace,
\end{align*}
 \item[$\brac{i}\vee\elim$]
\begin{align*}
 &\semo{\hypert_0\hmid \hypert_1\hmid \hypert_2\hmid \{i\mapsto
 \mat M x{N_0}y{N_1}\}}
 \\
 =&\semo{\hypert_0\hmid\imapsto{M}};\\&
 \left(\p x_x\leftarrow
 \mat{\semoi{\hypert_0\hmid\overline{\imapsto{M}}}(i)}{z}{z}{w}{\epsilon}\right)_i;
 \semo{\hypert_1\hmid\imapsto{N_0}};\\&
 \left(\p x_y\leftarrow
 \mat{\semoi{\hypert_0\hmid\overline{\imapsto{M}}}(i)}{z}{\epsilon}{w}{w}\right)_i;
 \semo{\hypert_2\hmid\imapsto{N_1}};\\&
 \Big(\p k \leftarrow
 \mathsf{match}
 {\semoi{\hypert_0\hmid\overline{\imapsto{M}}}(i)}
 \mathsf{of} \\
 &\phantom{k\leftarrow}\inl{z}. {\semoi{\hypert_1\hmid\overline{\imapsto{N_0}}}(i)}/\inr{w}. {\semoi{\hypert_2\hmid\overline{\imapsto{N_1}}}(i)}\Big)_i\enspace,
 \\
 \\
 &\semoi{\hypert_0\hmid \hypert_1\hmid \hypert_2\hmid \{i\mapsto
 \mat M x{N_0}y{N_1}\}}\\
 =&
 \semoi{\overline{\hypert_0}\hmid \imapsto{M}}\hmid
 \semoi{\overline{\hypert_1}\hmid \imapsto{N_0}}\hmid
 \semoi{\overline{\hypert_2}\hmid \imapsto{N_1}}\hmid \imapsto{\p k}\enspace.
\end{align*}
\end{description}
The rules IE and IW do not appear above because these rules do not
change the form of global terms.
When $(\tj{x_i}{[i]\iota_i})_{i\in\processes}
\tr\tj{M}(\wwedge_{i\in \processes}[i]o_i)$ is
derivable,
we can define a typed protocol using the above translation.
We set $\mathtt i_i$ to be ${\p x}_{x_i}$, ${\p o}_i$ to be arbitrarily
chosen fresh program variables, $L$ to be the set of locations
occurring in the derivation, we set the family of programs to be
$\semo{M}; ({\p o}_i\leftarrow \pi_i(\semoi{\overline M}(i)))_{i\in\processes}$,
where $\pi_i$ is obtained by composing $i$~times $\pi_{\mathrm r}$ to
$\pi_{\mathrm l}$.
We set $g,d,t_i$ accordingly so that the program is typed.
This concludes the translation.
 \begin{example}[Translation of a typed term into a typed protocol]
  The typing derivation in Figure~\ref{fig:solving} can be translated
  as follows.  We follow the derivation from top to bottom.  First we
  look at the top sequents and translate the typed terms:
  \begin{align*}
   \semo{{\{0\mapsto x\}}}&= \epsilon\\
   \semoi{{\{0\mapsto x\}}} &=
   \{0\mapsto \p i_x\} \\
   \semo{{\{1\mapsto y\}}} &=
   \epsilon\\
   \semoi{{\{1\mapsto y\}}} &=
   \{1\mapsto \p i_y\}\enspace.
  \end{align*}
  Next we look one step below:
  \begin{align*}
   \semo{{\{0\mapsto (\comodL)x\}} \hmid
   {\{1\mapsto (\comodR)y\}}}
   =&
   \left(d\leftarrow\p i_x; \p y \leftarrow c\right)_0;
   \left(c\leftarrow\p i_y; \p x \leftarrow d\right)_1\\
   \semoi{{\{0\mapsto (\comodL)x\}} \hmid
   {\{1\mapsto (\comodR)y\}}}
   =& \{0\mapsto \p y\}\hmid \{1\mapsto \p x\}\enspace
  \end{align*}
  And so on:
\begin{align*}
 &\semo{{\{0\mapsto add((\comodL)x,x)\}}\hmid
  {\{1\mapsto add((\comodR)y,y)\}}}\\
&= \left(d\leftarrow \p i_x; \p y\leftarrow c\right)_0;
 \left(c\leftarrow \p i_y; \p x\leftarrow d\right)_1;
 \left(\p z\leftarrow add(\p y,\p i_x)\right)_0;
 \left(\p w\leftarrow add(\p x,\p i_y)\right)_1
 \\
 &\semoi{{\{0\mapsto add((\comodL)x,x)\}}\hmid
  \{1\mapsto add((\comodR)y,y)\}} \\
 &= \{0\mapsto \p z\} \hmid \{1\mapsto \p x\}
\end{align*}
  \begin{align*}
&\llbracket
 {\{
  0\mapsto {add((\comodL)x,x)}, 1\mapsto {y}
  \}}
  \hmid
  {\{
  0\mapsto {x},
  1\mapsto {add((\comodR)y, y)}
  \}}
   \rrbracket\phantom{\hmid}\\
   =& \left(d\leftarrow \p i_x; \p y\leftarrow c\right)_0;
 \left(c\leftarrow \p i_y; \p x\leftarrow d\right)_1;
 \left(\p z\leftarrow add(\p y,\p i_x)\right)_0;
 \left(\p w\leftarrow add(\p x,\p i_y)\right)_1; \\
   & \left(\p{x'}\leftarrow \p i_x\right)_0;
     \left(\p{y'}\leftarrow \p i_y\right)_1 \\
&\llparenthesis
 {\{
  0\mapsto {add((\comodL)x,x)}, 1\mapsto {y}
  \}}
  \hmid
  {\{
  0\mapsto {x},
  1\mapsto {add((\comodR)y, y)}
  \}}
  \rrparenthesis\phantom{\hmid}\\
   =&
   \{0\mapsto \p z, 1\mapsto \p{y'}\} \hmid \{0\mapsto\p{x'}, 1\mapsto
   \p w\}
  \end{align*}
  \begin{align*}
   &\semo{
   \{
   0\mapsto \cotuple{{add((\comodL)x,x)},x},
   1\mapsto \cotuple{{add((\comodR)y,y)},y}
   \}}
   \\
   =&\left(d\leftarrow \p i_x; \p y\leftarrow c\right)_0;
   \left(c\leftarrow \p i_y; \p x\leftarrow d\right)_1;
   \left(\p z\leftarrow add(\p y,\p i_x)\right)_0;
   \left(\p w\leftarrow add(\p x,\p i_y)\right)_1; \\
   & \left(\p{x'}\leftarrow \p i_x\right)_0;
     \left(\p{y'}\leftarrow \p i_y\right)_1;
   \left(\p u \leftarrow \p z; \p u \leftarrow \p{x'}\right)_0 ;
   \left(\p v\leftarrow \p w; \p v \leftarrow \p{y'}\right)_1
   \\
   &\semoi{
   \{
   0\mapsto \cotuple{{add((\comodL)x,x)},x},
   1\mapsto \cotuple{{add((\comodR)y,y)},y}
   \}}
   \\
   =&\{0\mapsto\p u,1\mapsto \p v\}\enspace.
  \end{align*}
  The last two equations result in a typed protocol that solves the
  exclusive-or problem (Example~\ref{ex:xor}) for the same reason as the
  typed protocol in Example~\ref{ex:solv}.
 \end{example}

 Given the translation solves a typed input-output problem, we have to
 make sure that the original global term solves the same problem.
 Otherwise, the translation incorrectly produced a working typed protocol from
 not-working a global term.
 We have to show that the translation is correct in the following sense.
  \begin{proposition}
   \label{general-sound}
   For a derivable typed hypersequent~$\hypert$, let $\semoi{\hypert} =
   f_0\hmid
   f_1\hmid\cdots \hmid f_n$ so that each $f_j$ is a partial map
   from processes in $\processes$ to program variables.
   Assume that there is an execution of $\semo{\hypert}$ whose
   final system snapshot~$\tuple{\vec s,\vec v}$ satisfies
   $s_{f_j(i)} = V_{ji}$ for each $i \in \dom(f_j)$.
   Then, there exists a reduction relation
   \[
   \concreteconf{\{\}}{\hypert}\reduction
   \concreteconf{S}{
   \{i\mapsto V_{0i}\}_{i\in\dom(f_0)}\hmid
   \cdots\hmid
   \{i\mapsto V_{ni}\}_{i\in\dom(f_n)}
   }
   \]
   for some store~$S$.
  \end{proposition}
   \begin{proof}
    By induction on the typing derivation for $\hypert$.
    All cases are more or less straightforward, of which the most
    complicated cases are $ij$-com rule and EC rule.
    \begin{description}
     \item[$ij$-com]
	  Assume that there is an execution of
	  \begin{align*}
	   &\semo{\hypert_0\hmid \imapsto{M}};
	   \semo{\hypert_1\hmid \jmapsto{N}};\\
	   &(d\leftarrow \semoi{\hypert_0\hmid\overline{\imapsto M}}(i); \p
	   x\leftarrow c)_i; \\
	   &(c\leftarrow \semoi{\hypert_1\hmid\overline{\jmapsto N}}(j); \p
	   y\leftarrow d)_j
	  \end{align*}
	  whose final system snapshot contains process snapshots~$s_l$
	  for each process~$l\in\processes$ that map program variables as:
	  \begin{align*}
	   \semoi{\overline{\hypert_0}\hmid \imapsto{M}}&\mapsto
	   (V_{kl})_{0\le k < |\hypert_0|}\\
	   \semoi{\overline{\hypert_1}\hmid \jmapsto{N}}&\mapsto
	   (V_{kl})_{|\hypert_0|\le k < |\hypert_0| + |\hypert_1|}\enspace.
	  \end{align*}
	  Moreover, we assume $s_i(\p x) = V_{|\hypert_0|+|\hypert_1|+1,i}$
	  and $s_j(\p y) = V_{|\hypert_0| + |\hypert_1|,j}$.
	  In order to use the induction hypotheses, we have to transform
	  our assumptions to the assumptions needed by the induction
	  hypotheses on the branches of $ij$-com rule.

	  By the form of the programs,
	  there exists an execution of $\semo{\hypert_0\hmid
	  \imapsto{M}}$
	  whose final system snapshot contains a process snapshot
	  $s'_p$ for each process~$p\in \processes$
	  that maps program variables as:
	  \begin{align*}
	   \semoi{\overline{\hypert_0}\hmid \imapsto{M}}&\mapsto
	   (V_{kp})_{0\le k < |\hypert_0|}
	  \end{align*}
	  and moreover $s'_i$ maps $\semoi{\hypert_0\hmid
	  \overline{\imapsto{M}}}$ to $V$ where $V$ is equal to
	  $V_{|\hypert_0|+|\hypert_1|+1,i}$ unless
	  $V_{|\hypert_0|+|\hypert_1|+1,i}$ is $\epsilon$.
	  Similarly,
	  there exists an execution of $\semo{\hypert_1\hmid
	  \jmapsto{N}}$
	  whose final system snapshot contains a process snapshot
	  $s''_p$ for each $p\in\processes$
	  that maps program variables as:
	  \begin{align*}
	   \semoi{\overline{\hypert_1}\hmid \jmapsto{N}}&\mapsto
	   (V_{kp})_{|\hypert_0|\le k < |\hypert_0| + |\hypert_1|}
	  \end{align*}
	  and moreover $s''_j$ maps $\semoi{\hypert_1\hmid
	  \overline{\jmapsto{N}}}$ to $W$ where $W$ is
	  equal to $V_{|\hypert_0|+|\hypert_1|,j}$ unless
	  $V_{|\hypert_0|+|\hypert_1|,j}$ is $\epsilon$.

	  By induction hypothesis on $\hypert_0\hmid \imapsto{M}$,
	  there exists a reduction relation
	  \begin{align*}
	   &\concreteconf{\{\}}{ \hypert_0\hmid \imapsto{M} } \\
	   \reduce&
	   \concreteconf{S'}{\operatorname*{\hmid}_{0\le k<|\hypert_0|}
	   \left(\m{M}_k\right)
	   \hmid \{i\mapsto {V}\}}
	  \end{align*}
	  for some store~$S'$ and $\m{M}_k(p) = V_{kp}$ for each $p\in
	  \processes$.
	  Also,
	  by induction hypothesis on $\hypert_1\hmid \jmapsto{N}$,
	  there exists a reduction relation
	  \begin{align*}
	   &\concreteconf{\{\}}{ \hypert_1\hmid \jmapsto{N} } \\
	   \reduce&
	   \concreteconf{S''}{\operatorname*{\hmid}_{|\hypert_0|\le
	   k<|\hypert_0| + |\hypert_1|}
	   \left(\m{M}_k\right)
	   \hmid \{j\mapsto {W}\}}
	  \end{align*}
	  for some store~$S''$ and $\m{M}_k(p) = V_{kp}$ for each $p\in
	  \processes$.

	  When we combine these induction hypotheses,
	  we obtain
	  \begin{align*}
	   &\concreteconf{\{\}}{
	   \hypert_0\hmid \hypert_1\hmid \{i\mapsto (\comodL) M\}\hmid
	   \{j\mapsto (\comodR)N\}
	   }\\
	   \reduction & \concreteconf{S'\sqcup S''}{ (\m{M}_k)_{0\le k <
	   |\hypert_0|+ |\hypert_1|} \hmid
	   \{i\mapsto(\comodL)V\} \hmid \{j\mapsto (\comodR)W\}}\\
	   \reduction&
	   \concreteconf{S}{(\m{M}_k)_{0\le k <
	   |\hypert_0|+ |\hypert_1|}\hmid
	   \imapsto{V_{|\hypert_0|+|\hypert_1|+1,i}}
	   \hmid\jmapsto{V_{|\hypert_0|+|\hypert_1|,j}}
	   }\enspace.
	  \end{align*}
	  for some~$S$.
     \item[EC]
	  Assume that there exists an execution of
	  \begin{align*}
	   &\semo{\hypert\hmid \left(M_i\right)_{i\in I} \hmid
	   \left(N_i\right)_{i\in I}}; \\
	   &\left(\p k_i\leftarrow
	   \semoi{\hypert\hmid \overline{(M_i)}\hmid
	   (N_i)}(i)
	   ; \p k_i \leftarrow \semoi{\hypert\hmid {(M_i)}\hmid
	   \overline{(N_i)}}(i)\right)_{i\in I}
	  \end{align*}
	  whose final system snapshot is $\tuple{\vec s, \vec v}$
	  where for each process $p\in \processes$, $s_p$ maps
	  \[
	   \semoi{\overline{\hypert}\hmid
	  \left(\cotuple{M'_i,N'_i}\right)_{i\in I}}
	  \mapsto
	  \left(V_{kp}\right)_{0\le k < |\hypert|}
	  \]
	  and moreover $s_i(\p k_i)$ is $V_{|\hypert|,i}$ for each $i\in
	  I$.

	  By the form of the programs, there exists an execution of
	  $\semo{\hypert\hmid (M_i)_{i\in I}\hmid (N_i)_{i\in I}}$
	  whose final system snapshot $\tuple{\vec{s'}, \vec{v'}}$
	  satisfies
	  \begin{itemize}
	   \item for any $i\in I$ with $\tuple{M_i,N_i} = \tuple{M'_i,
		 N'_i}$, the process snapshot
		 $s'_i$ maps
		 $\semoi{\hypert\hmid \overline{(M_i)_{i\in I}}\hmid
		 (N_i)_{i\in I}}$ to $V_i$ and
		 $\semoi{\hypert\hmid (M_i)_{i\in I}\hmid
		 \overline{(N_i)_{i\in I}}}$ to $W_i$ where
		 $V_i$ is identical to $V_{|\hypert|,i}$ or
		 $\epsilon$ and $W_i$ is identical to
		 $V_{|\hypert|,i}$;
	   \item
		 for any $i\in I$ with $\tuple{M_i,N_i} = \tuple{N'_i,
		 M'_i}$, the process snapshot
		 $s'_i$ maps
		 $\semoi{\hypert\hmid \overline{(M_i)_{i\in I}}\hmid
		 (N_i)_{i\in I}}$ to $V_i$ and
		 $\semoi{\hypert\hmid (M_i)_{i\in I}\hmid
		 \overline{(N_i)_{i\in I}}}$ to $W_i$ where
		 $W_i$ is identical to $V_{|\hypert|,i}$ or
		 $\epsilon$ and $V_i$ is identical to
		 $V_{|\hypert|,i}$; and
	   \item for any $p\in\processes$,
		 $s'_p$ maps $\semoi{\overline{\hypert}\hmid (M_i)_{i\in
		 I}\hmid (N_i)_{i\in I}}$ to
		 $(V_{kp})_{0\le p < |\hypert|}$.
	  \end{itemize}
	  By induction hypothesis, there exists a reduction relation
	  \begin{align*}
	   &\concreteconf{\{\}}{\hypert\hmid (M_i)_{i\in I}\hmid
	   (N_i)_{i\in I}}
	   \\
	   \reduction&\concreteconf{S}{\operatorname*{\hmid}_{0\le k <
	   |\hypert|}
	   (\m{M_k})\hmid (V_i)_{i\in I}\hmid (W_i)_{i\in I}}
	  \end{align*}
	  for some store~$S$, global terms $\m{M_k}$ satisfying
	  $\m{M_k}(p) = V_{kp}$ for each $p\in \processes$.
	  Thus, there is also a reduction relation
	  \begin{align*}
	   &\concreteconf{\{\}}{\hypert\hmid (\cotuple{M'_i,N'_i})_{i\in
	   I}}
	   \\
	   \reduction&\concreteconf{S}{\operatorname*{\hmid}_{0\le k <
	   |\hypert|}(\m{M_k})\hmid (V_{|\hypert|,i})_{i\in I}}\enspace.
	  \end{align*}
    \end{description}
   \end{proof}

 \begin{proof}[of \thref{th:soundness}]
  Assume that a global term~$\m{M}$ solves a typed input-output problem~$R$.
  We claim that the typed protocol
  $\semo{\m{M}}; (\p o_i\leftarrow \semoi{\m{M}}(i))_{i\in \processes}$
  solves $R$.
  By \thref{general-sound},
  if there is an execution of $\semo{\m{M}}[N_i / \p i_i]$ that yields
  the content of $\semoi{\m{M}}(i)$ to be $V_i$ for each $i\in
  \processes$,
  the reduction relation $\concreteconf{\{\}}{\m{M}[N_i/x_i]}\reduce
  \concreteconf{S}{\{i\mapsto V_i\}_{i\in \processes}}$ holds for some
  store~$S$.
  Since the global term~$\m{M}$ solves $R$, the pair
  $\tuple{(N_i)_{i\in \processes}, (V_i)_{i\in\processes}}$ is compatible
  with $R$.
 \end{proof}

 For the other direction, we can use a universal waitfree problem called
 the participating set problem.
 Since the class of waitfreely solvable problems is generated by the
 participating set problem and problem compositions.
 We just have to solve the universal problem using \lgd.
\begin{theorem}[Completeness of \lgd\, with regard to waitfreedom]
 \label{th:completeness}
If there exists a typed protocol that solves a typed input-output
problem, the problem is solvable by a typed global term of \lgd.
\end{theorem}

\begin{proof}
\citet{Herlihy99} showed that a finite repetition
 of the participating set
 problem solves any waitfreely solvable problem.
 Also, $n$-party participating problem can be solved by a tournament of
 the two-party participating set problem%
 \footnote{To be exact, the construction for solving the $n$-party
 participating set problem using 2-party participating set problem
 is the same as a sorting network~\citep{batcher1968} for sorting $n$
 elements.}.
 It suffices to show a \lgd\, term solving the two-party participating
 set problem.

In the \textit{participating set problem}\index{participating set
 problem}~\cite{borowsky},
each process~$i$ receives an id $c_i$ and
returns a set of ids $S_i$.
The outputs must satisfy (i)~$c_i\in S_i$; (ii)~either $S_i\subseteq S_j$
or $S_j\subseteq S_i$; and (iii)~$S_i\subseteq S_j$  if $c_i\in S_j$ for any
$i,j\in\processes$.
For two processes,
$\tuple{S_0, S_1}$ can be $\tuple{\{c_0\}, \{c_0, c_1\}}$, $\tuple{\{c_0, c_1\}, \{c_1\}}$
or $\tuple{\{c_0, c_1\}, \{c_0, c_1\}}$.
 The point is that the processes do not know their own ids in advance
 but receive their own ids as inputs.
 This is why just hardcoding processes' outputs does not work.

We are going to encode the participating set problem in \lgd.
For this, we introduce a base type called $\Id$ for process id's.
Let there be an injection that maps a natural number~$i$ to a constant
$c_i\colon\Id$.
The additional typing rules involving $\Id$ are as follows, where $\nat = (\bot\supset\bot)\vee(\bot\supset\bot)$:
\begin{center}
 \UnaryRule{}{}
 {$\tr \tj{c_n}{[i]\Id}$}
 \hfill
 \BinaryRule
 {$\Gamma\tr \tj{M_0}[i]\Id$}
 {$\Gamma\tr \tj{M_1}[i]\Id$}
 {}
 {$\Gamma \tr \tj{\compare{M_0}{M_1}}{[i]\nat}$}\enspace.
\end{center}
The additional reduction is
\[
 c_m == c_n \reduce
\begin{cases}
 \linl{\lambda x.x}& (\text{if } m = n)\\
 \linr{\lambda x.x}& (\text{otherwise})\enspace.
\end{cases}
\]
Also,
${\ifte M {N_0} {N_1}}$
is an abbreviation for
${\mat M x {N_0} y {N_1}}$.

We represent a finite set of id's as a
typed lambda term, whose type is $[i](\Id\supset \bool)$.  Intuitively, a
set takes an id and decides whether it is \textit{in} or \textit{out}.
The emptyset is represented by a term $\lambda x. \linr {\bullet}$.
When a finite set~$S$ is represented by a term~$M$,
the set $S \cup \{c\}$ is represented by a term
$\lambda x.\left(\ifte{x==c}{\linl {\bullet}}{Mx}\right)$.
With the above construction, we define abbreviations
like $\{c_0, c_1, c_2\}$ although we do not equate $\{c_0, c_1, c_2\}$
 and $\{c_0, c_2, c_1\}$.

Now, we are ready to construct a hyperterm solving the two-party
participating set problem.
We can obtain a derivation of
 \begin{align*}
\tj{x}{[0]\Id}, \tj{y}{[1]\Id}\tr &
{\{0\mapsto\cotuple{\{(\comodL)x,x\},\{x\}},
1\mapsto\cotuple{\{(\comodR)y,y\},\{y\}}\}}\colon\\
&{0\mapsto \Id\imp \bool, 1\mapsto \Id\imp \bool}\enspace.
 \end{align*}

One possible reduction sequence is as follows:
\begin{align*}
 &
 \concreteconf{\{\}}{\{0\mapsto\cotuple{\{\underline{(\comodL)x},x\},\{x\}},
 1\mapsto \cotuple{\{(\comodR)y,y\},\{y\}}\}}\\
 \wreduce
 &\concreteconf{\{d\mapsto x\}}
 {\{0\mapsto\cotuple{\{\underline{\reader c},x\},\{x\}},
 1\mapsto\cotuple{\{(\comodR)y,y\},\{y\}}\}}
 \\
 \rreduce
 &
 \concreteconf{\{d\mapsto x\}}
 {\{0\mapsto \cotuple{\{\abort,x\},
 \{x\}},1\mapsto\cotuple{\{\underline{(\comodR)y},y\},\{y\}}\}}
 \\
 \wreduce
 &
 \concreteconf{\{c\mapsto y, d\mapsto x\}}
 {\{0\mapsto \cotuple{\{\abort,x\},\{x\}}, 1\mapsto
 \cotuple{\{\underline{\reader d},y\},y},\{y\}\}} \\
 \rreduce
 &
 \concreteconf{\{c\mapsto y, d\mapsto x\}}
 {\{0\mapsto \cotuple{\underline{\{\abort, x\}},\{x\}},
 1\mapsto\cotuple{\{x,y\},\{y\}}\}}
 \\
 \areduce
 &
 \concreteconf{\{c\mapsto y,d\mapsto
 x\}}{\{0\mapsto\underline{\cotuple{\abort,\{x\}}}, 1\mapsto\cotuple{\{x,y\},\{y\}}\}}
 \\
 \areduce
 &
 \concreteconf{\{c\mapsto y,d\mapsto
 x\}}{\{0\mapsto\{x\}, 1\mapsto\underline{\cotuple{\{x,y\},\{y\}}}\}}
 \\
 \areduce
 &
 \concreteconf{\{c\mapsto y,d\mapsto
 x\}}{\{0\mapsto\{x\}, 1\mapsto\{x,y\}\}}
\end{align*}
Moreover, the same initial configuration can reduce to
\[
\concreteconf{\{c\mapsto y,d\mapsto
 x\}}{\{0\mapsto\{y,x\}, 1\mapsto\{y\}\}}\] and
\[
\concreteconf{\{c\mapsto y,d\mapsto
 x\}}{\{0\mapsto\{y,x\}, 1\mapsto\{x,y\}\}}\enspace.
\]
There are no other normal forms.
These three normal forms correspond to the three allowed answers of the
two-party participating set problem.
\end{proof}

\section{Related Work}
\label{related}

Sonobe~\cite{sonobe} gives sequent calculi for intermediate logics $S_i$
and proved cut-elimination theorem for them.  As a special case he gives
$S_\omega$, which coincides with G\"odel--Dummett logic.
The proof of cut-elimination is similar to that of
Gentzen~\cite{gentzen}, involving the mix rule.
No lambda calculi has been developed based on Sonobe's deduction system,
probably because the deduction system involves a rule having unlimited
number of assumptions.

Avron~\cite{avron91} formulates a
hypersequent calculus for G\"odel--Dummett logic and proves
cut-elimination theorem using a method
similar to Gentzen~\cite{gentzen}.
Also, he explains the intuition behind the communication rule as
``the inputs through the ports in $\Gamma_2'$ are transmitted to the
component with output of type $A_1.$  The inputs through $\Gamma_1'$ are
treated similarly.''  He did not mention the possibility of
any transmission failures, which we exploited
in order to characterize waitfreedom.
Ciabattoni, Galatos and Terui~\cite{alg} gives a class of logics
that have hypersequent calculi with cut-elimination.
Their cut-elimination proof is general but it does not
obviously reveal the computational content.

Baaz, Ciabattoni and Ferm\"uller~\cite{natural} propose a
hypersequent-style natural deduction for G\"odel--Dummett logic, but
did not define reductions.
Ferm\"uller~\cite{parallel} gives a game semantics for G\"odel--Dummett
logic, which is based on Lorenzen game~\cite{curryhoward} and essentially
proof searching bottom-to-up.
Of course, there is a possibility of employing waitfree communication
for proof searching. Indeed, Ferm\"uller's dialogue game is
sometimes forked and proceeds concurrently.
However, he gives no explicit mention on waitfree computation.

Among numerous typed programming languages with parallelism,
to our knowledge, none models waitfreedom.
Abramsky~\cite{abramsky1993computational}'s calculus $\mathsf{PE}_2$
for classical linear logic is
deterministic
\cite[Theorem~7.9]{abramsky1993computational} so that it is
impossible to model
waitfreedom using $\mathsf{PE}_2$.
The $\pi$-calculus~\cite{milner1999communicating},
Join calculus~\cite{join},
and even asynchronous
$\pi$-calculus \cite{hondatokoro}
have too strong synchronization abilities to model waitfreedom because
a process can wait for an input.

Hirai~\cite{hirailpar,hiraimaster} compares the temporal order of waitfree
computation and the Kripke models of a modal logic similar to
G\"odel--Dummett logic.  The current
work witnesses the constructive content of
his model theoretic comparison.

\section{Discussion}
\label{future}

As a programming language, \lgd\, allows efficient execution because it
requires no synchronization among processes.
Possibly, this calculus can be extended by synchronization primitives.
It would be interesting to compare different synchronization primitives
and different intermediate logics, generalizing waitfreedom and
G\"odel--Dummett logic.
For example, it would be tedious but straightforward to adapt the
hyper-lambda calculi here to
the logics characterized by the Kripke frames of bounded
width~\citep{Ciabattoni01042001} because \lgd\, is a special case of
width~1.  However, the author has no immediate idea on
developing a general hyper-lambda calculi encompassing
all logics with cut-eliminatable hypersequent calculi~\citep{alg}.
Some high-performance computation people suggested to study a weaker
shared memory consistency than sequential consistency; that is, to
remove the assumption that all read and write operations on shared
memory are lined up in a temporal total order.
In their realm, sequential consistency is considered too strong to
assume everywhere.  If we are to study a weaker shared memory
consistency in the same approach as here,
we have to study a weaker logic.

It will be worthwhile to develop a waitfree protocol verification mechanism in Coq
because it is valuable to
remove unnecessary synchronization while keeping the program correct
in high performance computing.

An anonymous referee of FLOPS 2012 pointed out that the introduction of
modalities [$i$] is interesting on its own.
We have not investigated the logical meaning of these modalities.
We suspect these modalities are similar to nominals in the hybrid
logic~\citep{blackburn2000}.

In \lgd, the source of nondeterminism can be explicitly expressed as the
store prophecy.
If we can find a semantic counterpart $\mathsf{Sch}$ of the store
prophecy, possibly, we
can obtain a denotation $\mathcal{D}^\mathsf{Sch}$ of terms
using a denotation $\mathcal{D}$ for normal forms%
% \fix{pursue this in the
% following chapters}
.
If that succeeds for classical logic, it will be interesting%
\footnote{Kazushige Terui suggested the potential impact for classical logic.}%
.

Nonetheless there are some more immediate future work.
It would be better if we explicitly implement $n$-party participating
set problem using \lgd.
Another remaining task is to formalize the strong normalization theorem
formally in a proof assistant like Coq or Isabelle.
\citet{ttlifting} provided a concise proof of strong normalization of
the natural deduction for
intuitionistic propositional logic, containing disjunction.
Lindley's proof was formalized in Nominal Isabelle by
\citet{Doczkal2009}.

In Chapter~\ref{ch:exchange}, we studied an axiom
$(\phi\limp\psi)\otimes(\psi\limp\phi)$.
Apart from this, we also tried developing a lambda calculus for
$(\phi\limp\psi)\oplus(\psi\limp\phi)$ on top of a second-order
formulation of intuitionistic linear logic in Chapter~\ref{ch:pole}.
After doing that, we noticed that adequacy of parametricity argument
can be carried out using induction on just two type derivations;
if we did the same for the second-order variant of \lgd,\,it would take
induction over arbitrary number of derivations, using their heights.

\section{Conclusion}
\label{conc}
We proposed \lgd, a lambda calculus
based on \citet{avron91}'s hypersequent calculus for
G\"odel--Dummett logic.
We proved normalization and non-abortfullness.
The calculus characterizes
the typed version of waitfree computation.
Our result hints broader correspondence between proof theory and distributed computation.

\renewcommand{\comodL}{\comod{c}{\co c}}
\renewcommand{\comodR}{\comod{\co c}{c}}
