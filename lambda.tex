\renewcommand{\comodL}{\comod cd}
\renewcommand{\comodR}{\comod dc}

\chapter{A Hyper $\lambda$-Calculus for G\"odel--Dummett Logic}
\label{ch:lambda}

\subsection{Summary}

We propose a typed lambda calculus based on Avron's hypersequent
calculus~\citep{avron91} for G\"odel--Dummett logic.  This calculus
turns out to model
waitfree computation~\citep{Herlihy88,Saks:1993vq}.
Besides strong normalization and non-abortfullness,
we give soundness and completeness of
the calculus against the typed version of waitfree protocols.
The calculus is not only proof theoretically interesting,
but also valuable as a basis for distributed programming languages.

The Curry--Howard isomorphism~\cite{curryhoward} is surprising because the same
method works for two different purposes: a logical purpose of
removing redundancy from proofs and a computational purpose of finding a
class of terminating programs.
We extend
this surprise to G\"odel--Dummett logic and
waitfreedom.
G\"odel--Dummett logic~\cite{dummett59}
is one of the intermediate logics
between classical and intuitionistic logics.
Waitfreedom~\cite{Herlihy88,Saks:1993vq} is a class of distributed
computation without synchronization among processes.

We connect G\"odel--Dummett logic and waitfreedom using
Avron's hypersequent calculus~\cite{avron91}.
In doing that, we respond to his suggestion:
\begin{quote}
it seems to us extremely important to determine the exact
       computational content of them~[intermediate logics] ---
       and {to develop corresponding `$\lambda$-calculi'}
       ---Avron~\cite{avron91}.
\end{quote}
Differently from intuitionistic logic, G\"odel--Dummett logic validates
all formulae of the form
 $(\varphi\supset\psi)\vee(\psi\supset\varphi)$.
Our aim is building a typed lambda calculus
with some terms witnessing those formulae.
Such a term
$\tj{M}{(\varphi\supset\psi)\vee(\psi\supset\varphi)}$ must choose
$M\reduction \linl\cdots$ or $M\reduction \linr\cdots$.
We devise a nondeterministic $\lambda$-calculus in Sect.~\ref{lgd}.

Waitfreedom is a class of distributed computation where
processes cannot wait for other processes.  When two processes try to
exchange information, the faster process can pass information to the
slower one, but not always vice versa because the slower process might
start after the faster one finishes.
So, the computation is nondeterministic.
\fix{add history of waitfree}

The contribution of this paper is capturing
this nondeterminism using the nondeterministic $\lambda$-calculus for
G\"odel--Dummett logic.  \fix{herlihyのコの字型の例}

In Sect.~\ref{comparison}, we show that the
$\lambda$-terms in the calculus can solve a typed input-output
problems if and only if it is waitfreely solvable.

\section{\lgd}
\label{lgd}

We first present a proof system for G\"odel--Dummet logic.
Then we turn the proof system into typing rules for $\lambda$-terms
of~\lgd, give a set of reductions and prove strong-normalization and
non-abortfullness.
We show the proof system using the hypersequent
style~\citep{avron91}.
In the usual sequent calculi, each reasoning step concludes a sequent
$\G\vdash\phi$ where $\G$ is a sequence of formulae.
In the hypersequent calculi, each reasoning step concludes a
hypersequent, which is a finite, non-empty sequence of sequents.
Of the hypersequent
$\G_0\vdash\phi_0\hmid\G_1\vdash\phi_1\hmid\cdots\hmid\G_n\vdash\phi_n$,
each sequent $\G_i\vdash\phi_i$ is called a \textit{component}.
Each component $\G_i\vdash\phi_i$ is interpreted as an implication: the
conjunction of $\G_i$ implies $\phi_i$.
The whole hypersequent is interpreted as disjunction of implications.
When we introduce terms, we still interpret the components
disjunctively: namely, a derivation tree concluding a hypersequent
represents a sequence of concurrent processes at least one of which is
guaranteed to succeed.

\subsection{Logic}

\newcommand{\m}[1]{{#1}^+}

Let us assume a countably infinite set of propositional variables%
\index{propositional variable|see{variable}}\index{variable!propositional}.
The set of propositional variables is written~$\pvar$.
We define local formulae \index{formula!local}
\index{local formula|see{formula}}
$\varphi, \psi$ by the following BNF,
where $I$ is a
propositional variable%
\footnote{We include $\bot$ because G\"odel--Dummett logic has it
although $\bot$ is not necessary for us to encode waitfree computation.}%
:
\[
 \varphi,\psi ::= \bot \mid I \mid (\varphi\supset\psi) \mid (\varphi\wedge\psi) \mid
 (\varphi\vee\psi)\enspace.
\]
We omit parentheses following the usual convention.
A global formula is a non-empty partial mapping from processes to local
formulae.
We use $\m\phi$ and $\m\psi$ for global formulae.
For a natural number~$i$ (representing a process),
as a notation, $[i]\phi$ is a global formula that maps $i$ to $\phi$ but
does not map any other processes to local formulae.
We call such global formulae as singleton global formulae.
The unary operators $[0], [1],\ldots$ are called modalities%
\index{modality}.
Informally, the local formulae describe datatypes used by each process.
The global formulae describe inputs or outputs of all
processes together.

A contex\index{context} (denoted by $\Gamma$ and $\Delta$ possibly
subscripted) is a potentially empty
finite sequence of singleton global formulae.
A sequent\index{sequent}~$\Gamma\vdash\m\varphi$ is a pair of a context and a
global formula.
A hypersequent\index{hypersequent} is a finite sequence of sequents.

The underlying logic has the derivation rules in Fig.~\ref{fig:logic}.  If
we omit all the modalities, these rules characterize
G\"odel--Dummett logic.
Indeed,
$[0]((\varphi\supset\psi)\vee(\psi\supset\varphi))$ is provable (Figure~\ref{fig:dummett-modal}).
\begin{sidewaysfigure}
 \footnotesize
 \centering
\AxiomC{}
\LL{[0]Ax}
\UnaryInfC{$[0]P\vdash [0]P$}
\AxiomC{}
\LL{[0]Ax}
\UnaryInfC{$[0]Q\vdash[0]Q$}
\LL{00-com}
\BinaryInfC{$[0]P\vdash[0]Q\hmid [0]Q\vdash[0]P$}
\LL{$[0]\supset$I}
\UnaryInfC{$\vdash[0](P\supset Q)\hmid [0]Q\vdash[0]P$}
\LL{$[0]\supset$I}
\UnaryInfC{$\vdash[0](P\supset Q)\hmid \vdash[0](Q\supset P)$}
\LL{EC}
\UnaryInfC{$
\vdash
 [0]((P\supset Q)\lor (Q\supset P)) $}
 \DisplayProof

 \caption{Something like Dummett's axiom is provable.}
 \label{fig:dummett-modal}
\end{sidewaysfigure}

% \section{About the modality}

% \fix{compare with the intuitionistic epistemic logic}

% \fix{consider the Kripke model.}

% \fix{translation back and forth.}

\begin{figure}
 \small
\centering
  \textbf{External Rules}
   \vskip 2mm
%%communication
   \BinaryRule
   {$\hyper\hmid\G\vdash[i]\varphi$}
   {$\hyper\hmid\D\vdash[j]\psi$}
   {$ij$-com}
   {$\hyper\hmid\Gamma\vdash[i]\psi\hmid\Delta\vdash[j]\varphi$}
  \hfill
%% external structural
 \UnaryRule
 {$\hyper^+$}
 {EW}
 {$\hyper^+\hmid\Gamma\vdash \m\varphi$}
 \vskip 2mm
 \UnaryRule
 {$\hyper\hmid\Gamma\vdash \m\phi\hmid\Gamma\vdash \m\phi$}
 {EC}
 {$\hyper\hmid\Gamma\vdash \m\phi$}
 \hfill
 \UnaryRule
 {$\hyper\hmid\Gamma\vdash \m\varphi\hmid\Delta\vdash \m\psi\hmid \hyper'$}
 {EE}
 {$\hyper\hmid\Delta\vdash \m\psi   \hmid\Gamma\vdash \m\varphi\hmid
   \hyper'$}
 \vskip 2mm
\textbf{Inner Global Rules}
\vskip 2mm
%% structural
   \UnaryRule
   {$\hyper\hmid\Gamma,[i]\phi,[j]\psi,\Delta\tr\m\theta$}
   {IE}
   {$\hyper\hmid\Gamma,[j]\psi,[i]\phi,\Delta\tr\m\theta$}
   \hfill
   \UnaryRule{$\hyper\hmid\Gamma\vdash\m\varphi$}
   {IW}
   {$\hyper\hmid[i]\psi,\Gamma\vdash\m\varphi$}
   \hfill
   \UnaryRule
   {$\hyper\hmid[i]\psi,[i]\psi,\G\vdash\m\varphi$}
   {IC}
   {$\hyper\hmid[i]\psi,        \G\vdash\m\varphi$}
   \ruleskip
%% global conj intro
 \BinaryRule
 {$\hyper\hmid\G\tr(\phi_i)_{i\in I}$}
 {$\hyper\hmid\G\tr(\psi_j)_{j\in J}$}
 {$\wedge\intro$}
 {$\hyper\hmid\G\tr(\phi_k\land\psi_k)_{k\in I\cap J}\sqcup
 (\phi_i)_{i\in I\setminus J}\sqcup (\psi_j)_{j\in J\setminus I}$}

 \fix{explain sqcup}
 \ruleskip
%% global conj elim
 \UnaryRule
 {$\hyper\hmid \G\tr(\phi_i)_{i\in I}$}
 {$\wedge\elim$}
 {$\hyper\hmid \G\tr(\phi_i)_{i\in J}$}
 where $J$ is a subset of $I$.
\ruleskip
\textbf{Inner Local Rules}
\ruleskip
%% axiom
  \UnaryRule{}{$[i]$Ax}
   {$[i]\varphi,\Gamma\vdash [i]\varphi$}
   \hfill
%% bot elim
 \UnaryRule{$\hyper\hmid\Gamma\vdash[i]\bot$}
   {$[i]\bot\elim$}
   {$\hyper\hmid\Gamma\vdash[i]\varphi$}
   \vskip 2mm
%% local imp intro
  \UnaryRule{$\hyper\hmid[i]\varphi,\Gamma\vdash [i]\psi$}
  {$[i]\supset\intro$}
  {$\hyper\hmid\Gamma\vdash [i](\varphi\supset \psi)$}
  \hfill
%% local imp elim
  \BinaryRule
  {$\hyper\hmid\Gamma\vdash [i](\varphi\supset\psi)$}
  {$\hyper\hmid\Gamma\vdash [i]\varphi$}
  {$[i]\supset\elim$}
  {$\hyper\hmid\Gamma\vdash [i]\psi$}
   \vskip 2mm
%% local conj intro
  \BinaryRule{$\hyper\hmid\Gamma\vdash [i]\varphi$}
   {$\hyper\hmid\Gamma\vdash [i]\psi$}
   {$[i]\wedge\intro$}
   {$\hyper\hmid\Gamma\vdash [i](\varphi\wedge\psi)$}
   \vskip 2mm
%% local conj elim
  \UnaryRule{$\hyper\hmid\Gamma\vdash [i](\varphi\wedge\psi)$}
   {$[i]\wedge\elim_0$}
   {$\hyper\hmid\Gamma\vdash[i]\varphi$}
   \hfill
  \UnaryRule{$\hyper\hmid\Gamma\vdash[i](\varphi\wedge\psi)$}
   {$[i]\wedge\elim_1$}
   {$\hyper\hmid\Gamma\vdash[i]\psi$}
\vskip 2mm
%% local disj intro
  \UnaryRule
   {$\hyper\hmid\Gamma\vdash[i]\varphi$}
   {$[i]\vee\intro_0$}
   {$\hyper\hmid\Gamma\vdash[i](\varphi\vee\psi)$}
   \hfill
  \UnaryRule{$\hyper\hmid\Gamma\vdash[i]\psi$}
   {$[i]\vee\intro_1$}
   {$\hyper\hmid\Gamma\vdash[i](\varphi\vee\psi)$}
\vskip 2mm
%% local disj elim
   \TrinaryRule
   {$\hyper\hmid\Gamma\vdash[i](\varphi\vee\psi)$}
   {$\hyper\hmid[i]\varphi, \Gamma\vdash[i]\theta$}
   {$\hyper\hmid[i]\psi,    \Gamma\vdash[i]\theta$}
   {$[i]\vee\elim$}
   {$\hyper\hmid         \Gamma\vdash[i]\theta$}
\vskip 2mm
\caption[The underlying logic \fix{of what}.]
 {The underlying logic.
 Metavariables $\m\phi$ and $\m\psi$ stand for global formulae.
 Metavariables~$i$ and $j$ stand for a process.
 $\hyper$ stands for a
 hypersequent.
 $\hyper^+$ stands for a nonempty hypersequent.
 $\Gamma$ and $\Delta$ stand for possibly empty contexts.
 In the names of rules, I at the end stands for introduction and E for
 elimination or exchange.  The I's in front stand for internal and E
 for external.  For structural rules, E stands for exchange, W for
 weakening and C for contraction.  The external contraction (EC) is
 different from standard ones but yields the same set of derivable
 sequents.
 There are no disjunction elimination in the inner global rules lest it
 is difficult (if possible) to translate the rule into
 waitfree computation.
 }
\label{fig:logic}
\end{figure}

\subsection{Term Assignment}
\label{term}

We assume distinct, countably infinite sets of variables\index{variable},
channels\index{channel}
and
processes\index{process}.
Channels are denoted by~$c,d,\ldots$; process~$i,j, \ldots$ and variables~$x,
y, \ldots$.
Later, channels will be used to specify a store
holding a term or being empty.
Like in the $\lambda$-calculus, some terms reduces to other
terms, but in this calculus, terms may interact with the store (like
a program written in Haskell or OCaml does with an i-var).
This behavior will be shown later in the definition of reductions.

We define local terms\index{term!local}~$\term$ by the BNF:
\begin{align*}
\term ::=&\,
 x\mid (\comod c c) \term \mid \reader c
 \mid
 \cotuple{\term,\term} \mid \abort \mid
  \lpil \term \mid \lpir \term \mid
 \lpair {\term,\term}\mid \\&
  \linl \term \mid  \linr \term \mid
 \lambda x.\term\mid (\term \term)
\mid \mat \term x\term y \term
\end{align*}
where $x$ is a variable and $c$ is a channel.
All variable occurrences (including those in $\Gamma$)
except the first clause are
binding.

\fix{C}
Informally, the local terms represent parts of
programs executed by the processes.
Especially, $(\comod c c)t$ and $\reader c$ denote processes' communication.
The constructs with
$\mathtt{g}$ represent parts of programs that are used for preparing
inputs for processes and collecting outputs of the processes.

Using these terms, we annotate the hypersequent system in Fig.~\ref{fig:logic}.
We extend a sequent
to $\G\tr \tj {\m M}{\m \varphi}$\kern -3pt, where $\G$ is
a sequence like $\tj{x}{[i]\psi}\kern -3pt, \tj{y}{[j]\theta}$ and $\m M$
is a global term.
In a sequent $\Gamma\tr\tj{M}{\m\varphi}$\kern -3pt, we require the
variables in $\G$ to be distinct from each other.
A contexed type\index{contexted type}
 $\Gamma\tr\m\varphi$ is a sequent without a term but with variables in
 $\Gamma$.
A hypersequent\index{hypersequent} is a finite sequence of sequents (each called
a component\index{component})
where the same
variable has the same type even if it appears in different components.
The typing rules for the terms are given in Fig.~\ref{termassign}.
For example, the proof in Figure~\ref{fig:dummett-modal} can be
annotated as in Figure~\ref{fig:typed-term}.
\begin{sidewaysfigure}
 \centering
\AxiomC{}
\LL{[0]Ax}
\UnaryInfC{$\tj{x}{[0]P}\tr \tj{x}{[0]P}$}

\AxiomC{}
\LL{[0]Ax}
\UnaryInfC{$\tj{y}{[0]Q}\tr\tj{y}{[0]Q}$}
\LL{$00$-com}
\BinaryInfC{$\tj{x}{[0]P}\tr\tj{(\comodL)x}{[0]Q}\hmid
 \tj{y}{[0]Q}\tr\tj{(\comodR)y}{[0]P}$}
\LL{$[0]\supset\intro$}
\UnaryInfC{$\tr\tj{\lambda x. (\comodL)x}{[0](P\supset Q)}
 \hmid \tj{y}{[0]Q}\tr\tj{(\comodR)y}{[0]P}$}
\LL{$[0]\supset\intro$}
\UnaryInfC{$\tr\tj{\lambda x. (\comodL)x}{[0](P\supset Q)}\hmid \tr
 \tj{\lambda y.(\comodR)y}{[0](Q\supset P)}$}
\LL{EC}
\UnaryInfC{$
\tr \tj{\left[{\lambda x. (\comodL)x} ,\quad {\lambda
 y.(\comodR)y} \right]}
 {[0]((P\supset Q)\lor (Q\supset P))} $}
\DisplayProof
 \caption{An example of a typed term in \lgd. \fix{has to be changed}}
 \label{fig:typed-term}
\end{sidewaysfigure}

\fix{contexts can only contain singleton global formulae}


\begin{figure}[p]
 \small
\centering
\textbf{External Rules}
\vskip 2mm
%% communication
\BinaryRule
   {$\hypert_0\hmid\G\tr\tj{M}{[i]\varphi}$}
   {$\hypert_1\hmid\D\tr\tj{N}{[j]\psi}$}
   {}
   {$\cotuple{\hypert_0,\hypert_1}\hmid\Gamma\tr\tj{(\comodL)M}{[i]\psi}\hmid
   \Delta\tr\tj{(\comodR)N}{[j]\varphi}$}
   where $c$ and $d$ are fresh.
\vskip 2mm
%% external structural
 \UnaryRule
 {$\hypert^+$}
 {}
 {$\hypert^+\hmid\Gamma\tr \tj \abort {\m\phi}$}
\vskip 2mm
 \AxiomC{$\hypert\hmid \G\tr\tj{(M_i)_{i\in I}}{(\phi_i)_{i\in I}}\hmid
 \G\tr\tj{(N_i)_{i\in I}}{(\psi_i)_{i\in I}}$}
 \UnaryInfC{$\hypert\hmid
 \G\tr\tj{\cotuple{M_i',N_i'}}{(\phi'_i\lor\psi'_i)_{i\in I}}$}
 \DisplayProof \\where $I$ is a nonempty subset of $\processes$ and, for
 each $i\in\processes$, the pair of pairs $\tuple{(M_i',\phi'_i), (N_i',\psi'_i)}$
 is identical to either $\tuple{(M_i,\phi_i), (N_i,\psi_i)}$
 or $\tuple{(N_i,\psi_i), (M_i,\phi_i)}$.
\ruleskip
 \UnaryRule
 {$\hypert\hmid\Gamma\tr M\colon\m\varphi\hmid\Delta\tr N\colon \m\psi\hmid \hypert'$}
 {}
 {$\hypert\hmid\Delta\tr N\colon\m\psi   \hmid\Gamma\tr M\colon \m\varphi\hmid \hypert'$}
 \vskip 2mm
\textbf{Inner Global Rules}
   \vskip 2mm
 % internal contraction
   \UnaryRule
   {$\hypert\hmid \Gamma\tr\tj {\m M} {\m\varphi}$}
   {}
   {$\hypert\hmid \tj x {[i]\psi}, \Gamma\tr \tj{\m M}{\m\varphi}$}
   \hfill
   \UnaryRule
   {$\hypert\hmid \tj{x}{[i]\phi}, \tj{y}{[i]\phi}, \Gamma\tr \tj
   M{\m\psi}$}
   {}
   {$\hypert \hmid \tj{x}{[i]\phi}, \Gamma\tr \tj{\m{M}[x/y]}{\m\psi}$}
 \fix{define substitution on global terms}
\vskip 2mm
\UnaryRule
   {$\hypert\hmid\Gamma,\tj x{[i]\phi},\tj y{[j]\psi},\Delta\tr
   \tj {\m M}{\m\theta}$}{}
   {$\hypert\hmid\Gamma,\tj y{[j]\psi},\tj x{[i]\phi},\Delta\tr \tj
 {\m M}{\m\theta}$} %IE
\hfill
%% conj intro
 \fix{conj intro}
   \vskip 2mm
%% conj elim
 \fix{conj elim rule}
\ruleskip
\textbf{Inner Local Rules}
\vskip 2mm
%% axiom
  \UnaryRule{}{}{$\tj x{[i]\varphi}, \Gamma\tr \tj x{[i]\varphi}$}
                       \hfill
%% bot elim
 \UnaryRule
   {$\hypert\hmid\Gamma\tr \tj M{[i]\bot}$} {}
   {$\hypert\hmid\Gamma\tr \tj{\abort}{[i]\varphi}$}
   \vskip 2mm
%% local imp intro
  \UnaryRule
   {$\hypert\hmid\tj x{[i]\varphi},\Gamma\tr \tj M{[i]\psi}$}
   {}
   {$\hypert\hmid\Gamma\tr \tj{\lambda x.M}{[i](\varphi\supset\psi)}$}
                       \hfill
%% local imp elim
  \BinaryRule{$\hypert_0\hmid\Gamma \tr \tj M{[i](\varphi\supset \psi)}$}
  {$\hypert_1\hmid\Gamma\tr \tj N{[i]\varphi}$}
  {}
  {$\cotuple{\hypert_0,\hypert_1}\hmid\Gamma\tr \tj{MN}{[i]\psi}$}
                       \vskip 2mm
%% local conj intro
\BinaryRule{$\hypert_0\hmid\Gamma\tr \tj M{[i]\varphi}$}
   {$\hypert_1\hmid\Gamma\tr \tj N{[i]\psi}$}
   {}
   {$\cotuple{\hypert_0,\hypert_1}\hmid\Gamma\tr
     \tj{\lpair {M,N}}{[i](\varphi\wedge\psi)}$}
   \vskip 2mm
%% local conj elim
  \UnaryRule
   {$\hypert\hmid\Gamma\tr M\colon[i](\varphi\wedge\psi)$}
   {}
   {$\hypert\hmid\Gamma\tr \lpil{M}\colon[i]\varphi$}
   \hfill
  \UnaryRule
   {$\hypert\hmid\Gamma\tr M\colon[i](\varphi\wedge\psi)$}
   {}
   {$\hypert\hmid\Gamma\tr\lpir M\colon[i]\psi$}
\vskip 2mm
%% local disj intro
  \UnaryRule
   {$\hypert\hmid\Gamma\tr M\colon[i]\varphi$}
   {}
   {$\hypert\hmid\Gamma\tr\linl {M}\colon[i](\varphi\vee\psi)$}
   \hfill
  \UnaryRule
   {$\hypert\hmid\Gamma\tr M\colon[i]\psi$}
   {}
   {$\hypert\hmid\Gamma\tr \linr{M}\colon[i](\varphi\vee\psi)$}
\vskip 2mm
%% local disj elim
\TrinaryRule
   {$\hypert_0\hmid\Gamma\tr \tj M {[i](\varphi\vee\psi)}$}
   {$\hypert_1\hmid\tj x{[i]\varphi},\Gamma\tr \tj {N_0}{[i]\theta}$}
   {$\hypert_2\hmid\tj y{[i]\psi},   \Gamma\tr \tj {N_1}{[i]\theta}$}
   {}
   {$\cotuple{\cotuple{\hypert_0,\hypert_1},\hypert_2}\hmid\Gamma \tr \tj{\mat M x {N_0} y {N_1}}{[i]\theta}$}
\vskip 2mm
 \caption[Term assignment of \lgd.]
 {Term assignment.
 Metavariable $\m M$ stands for global terms.
 When we remove variables and terms, we obtain the derivation rules for
 the underlying logic (Figure~\ref{fig:logic}).
 $\hypert$ stands for
 a possibly empty hypersequent (with possible subscripts).
 $\hypert^+$ stands for a non-empty hypersequent.
 Within each rule, $\hypert_0$, $\hypert_1$ and $\hypert_2$ have the
 same length and the same type so that $\cotuple{\hypert_0,\hypert_1}$
 can be defined as
 the elementwise application of $\cotuple{\term,\term}$. \fix{ needs
 more explanation} \fix{add [i] in front of local terms}
 }
 \label{termassign}
\end{figure}


\fix{is this typeable?, then copy the reductions in C}
\[
 \gpair{\cotuple{\{(\comodL)x,x\},\{x\}},\cotuple{\{(\comodR)y,y\},\{y\}}}
\]


\subsection{Reduction}

\fix{somewhere, define closed global terms}
A closed global term~$\m M$ is \textit{of} type~$\m\varphi$ iff there is
a derivation of
$\tr
\tj{\m M}{\m\varphi}$.
A pure term\index{pure term|see{term}}\index{term!pure} is a term
without $\comod c c$,
$\reader c$ or any $\g$ constructs.
A hyperterm\index{hyperterm}~$\hypert$ is a nonempty sequence of terms.
A store\index{store} maps a channel to a
pure term or $\epsilon$.
For a store~$\sigma$, the updated store $\sigma[c\mapsto x]$ maps $c$ to
$x$ and $d$ to $\sigma(d)$ if $d$ is different from~$c$.
A configuration\index{configuration} is a pair $\conf{}\hypert$ of a
store~$\lstore$ and a hyperterm~$\hypert$.
A typed configuration\index{typed configuration} is a
configuration $(\epsilon, \mathcal O)$ where $\epsilon$ is the empty
store and $\mathcal O$ is derivable.

To complete the definition of \lgd,
 we define the \textit{reductions} $\reduce_\spadesuit$ of
 configurations for $\spadesuit\in\{\mathrm B, \mathrm W, \mathrm R, \mathrm A,
 \mathrm P\}$.
 We consider terms up to $\alpha$-equivalence and implicitly
 require all instances
 of $\rightsquigarrow_\spadesuit$ to avoid free variable captures.
 \fix{define congruences to be used below}

\begin{definition}[Basic reduction]
 The basic reduction $\breduce$ is the smallest congruence containing
 the followings:
 \begin{itemize}
  \item  $\conf{}{(\lambda x.M)O}\breduce
 \conf{}{M[O/x]}$
  \item $\conf{}{\lpil{\lpair{M,N}}} \breduce
	 \conf{}{           M   }$
  \item $\conf{}{\lpir{\lpair{M,N}}} \breduce
	 \conf{}{             N }$
  \item $\conf{}{\mat{\linl M}x N y O} \breduce
	 \conf{}{              N[M/x]}$
  \item $\conf{}{\mat{\linr M}x N y O} \breduce
	 \conf{}{                  O[M/y]}$
 \end{itemize}
\end{definition}

There are two sorts of reductions that interact with the store.
In summary, $\comodL$ tries to write to $d$ and read from
$c$ of the store in the configuration.
 If a term writes to a full channel of
a store, it does not abort but the store is not updated.  In fact, the
store contents are never updated after being written.
This property will be used in the proof of \thref{first:sn}.
The formal definition of the reductions follows.
\begin{definition}[Write reduction]
 The write reduction $\wreduce$ is the smallest congruence
 containing the followings:
 \begin{itemize}
  \item $\conf{[c\mapsto \epsilon]}{(\comodR)M} \wreduce
	\conf{[c\mapsto M]}{\reader d}
	$ where $M$ is a pure term
  \item $\conf{[c\mapsto N]}{(\comodR) M} \wreduce \conf{[c\mapsto
	N]}{\reader d}$ where $M$ is a pure term
 \end{itemize}
\end{definition}
In the first clause of this definition of write reductions, we require
$M$ to be a pure
term because a store can only contain pure terms.
We require the same condition in the second clause as well because
otherwise, whether a configuration admits a write reduction or not
would depend on the contents of the store, which would make the
implementation more complicated.

After the communicating term $(\comodL)$ writes to the memory,
the term changes into a reader $\reader c$.  When the reader tries to
read when $c$ is full, the reader is replaced with the content of the
channel~$c$.
If a term tries to read from an empty location of a store,
the term changes into $\abort$.
\begin{definition}[Read reduction]
 \label{read}
 The read reduction $\rreduce$ is the smallest congruence
 containing the
 followings:
\begin{itemize}
 \item $\conf{[c\mapsto M]}{\reader c}\rreduce \conf{[c\mapsto M]}{M}$
 \item $\conf{[c\mapsto \epsilon]}{\reader c} \rreduce \conf{[c\mapsto \epsilon]}{\abort}$
\end{itemize}
\end{definition}

The special term $\abort$ means failure, so, a term containing $\abort$
also reduces to abort except $\cotuple{M,N}$.  The concurrent
construction $\cotuple{M,N}$ runs $M$ and $N$ concurrently and throws
away those subterms that reduces to $\abort$.
To be specific, the term $\cotuple{M,N}$ reduces to $\linl{M}$
 or $\linr{N}$ with $\mathsf{inl}$ and
$\mathsf{inr}$ labels showing which components failed.
The reduction rules are not symmetric with regard to the left component
and the right component of the concurrent construct $[M, M]$ because
when both components succeed, the whole construct reduces to
the left component.
\begin{definition}[Abort reduction]
 The abort propagation reduction $\areduce$ is the smallest
 congruence containing the
 followings:
\begin{itemize}
 \item  $\conf{}{\cotuple{\abort, M}}\areduce
 \conf{}{{M}}$, and
   $\conf{}{\cotuple{M,\abort}}\areduce
 \conf{}{{M}}$
 \item $\conf{}{\cotuple{M,N}}\areduce \conf{}{M}$ where
       $M$ and $N$ do not contain $\abort$, $\comodL$ or $\reader c$
       for any channels $c,d$;
 \item  $\conf{}{C[\abort]}\areduce
 \conf{}{\abort}$  where $C[\bullet]$ is defined by BNF:
\begin{align*}
  C[\bullet] ::= &\bullet \mid
C[\bullet] N \mid
{M C[\bullet]}\mid
(\comod c c)C[\bullet]\mid
\linl{C[\bullet]}\mid
\linr{C[\bullet]}\mid
\lpair {C[\bullet], N}\mid \\&
\lpair {M, C[\bullet]}\mid
\pi^\square_i{C[\bullet]}\mid
\mat M x N y {C[\bullet]}\mid\\ &
\mat  {C[\bullet]} x N y O\mid \\&
\mat  M x {C[\bullet]} y O
\end{align*}
\end{itemize}
\end{definition}
For example, $(\sigma, \cotuple{\abort,\abort})$ reduces to $(\sigma,
\abort)$.

In order to obtain the subformula property
 via proof normalization
we add yet another kind of reduction rules called permutative reductions.
\begin{definition}[Permutative reduction]
 The permutative reduction~$\preduce$ is the smallest congruence
 containing the followings:
\begin{itemize}
 \small
 \item $\conf{}{ \left(\mat  M x N y O\right) P }\preduce$ \\
       $\conf{}{ \mat M x {N P} y {O P} }$
 \item $\conf{}{ \pi^\square_d \left(\mat M x N y
       O\right)}\preduce$\\
       $\conf{}{ \mat M x
       {\pi^\square_d N} y {\pi^\square_d O} }$
 \item {
       $\conf{}{ \mat
                          {\left(\mat  M x N y O\right)}
                          u P v Q
                      }\preduce$ \\
       $(\lstore,
        \mathsf{match}^{\blacksquare}\,{M}\,\mathsf{of}\, \linl{x}. {
                          {\left(\mat N u P v Q\right)}
       } /$ \\ \phantom{mmmmmmmmmmm}$
       \linr{y}. {\left(\mat  O u P v Q\right)}
                      )
       $}
 \item $\conf{}{ \cotuple{M, N} P }\preduce
        \conf{}{ \cotuple{MP, NP} }$
 \item $\conf{}{ \pi^\square_d\cotuple{M,N} }\preduce
        \conf{}{ \cotuple{\pi^\square_d M, \pi^\square_d N} }$
 \item $\conf{}{ \mat {\cotuple{M,N}} x P y Q }\preduce$\\
       $\conf{}{ \cotuple{
                          \mat  M x P y Q,
                          \mat N x P y Q
                        } }$
\end{itemize}
\end{definition}

We define $\reduce$ to be the union of $\breduce$, $\wreduce$, $\rreduce$,
$\areduce$ and $\preduce$.
The reflexive transitive closure of $\reduce$ is
written as~$\reduction$.
A redex\index{redex} is a subterm that can be rewritten by a reduction.
A configuration~$\mathcal{C}$ is normal\index{normal} when there is no configuration
$\mathcal{D}$ with $\mathcal{C}\reduce \mathcal{D}$.
A term~$M$ is normal\index{normal} when the configuration $\conf{}{M}$ is
normal (the choice of $\lstore$ is irrelevant).

\subsection{Properties}

An important property of
\lgd\, is strong normalization:
every typed hyperterm has a finite, maximal number of reductions it can
take.
Another is {non-abortfullness}: although some reductions yield
$\abort$ terms, a typed hyperterm never reduces to a hyperterm that only
contains $\abort$'s.  We show the second property first because its
proof is simpler.

\begin{theorem}[Non-abortfullness]
 \label{nab}
 All normal forms of a typed configuration contain at least one term
 that is not $\abort$.
\end{theorem}
\begin{proof}
 When a reduction sequence is fixed, for any channels~$c$ and $d$, depending on
 whether $c$ or $d$ is filled first,
 either:
 (i)  no ${\reader c} \reduce {\abort}$ occurs, or
 (ii) no ${\reader d} \reduce {\abort}$ occurs.

If the former is the case, we can rewrite
a communication rule occurrence
\begin{center}
 \BinaryRule
 {$\hypert_0\hmid \Gamma,\Delta\tr \tj M{[i]\psi}$}
 {$\hypert_1\hmid \Gamma,\Delta\tr \tj N{[j]\tau}$}
 {}
 {$\cotuple{\hypert_0,\hypert_1}\hmid
 \Gamma\tr \tj
   {(\comodL)M}{[i]\tau}\hmid
   \Delta\tr \tj{(\comodR)N}{[j]\psi}$}
\end{center}
into a weakening occurrence (using Proposition~\ref{process-change} stated below)
\begin{center}
 \AxiomC
 {$\hypert_0\hmid  \Gamma^j, \Delta^j\tr \tj M{[j]\psi}$}
 \UnaryInfC
 {$\hypert_0\hmid \tr \tj \abort
 {[i]\tau}\hmid
   \Gamma^j,\Delta^j\tr \tj{M}{[j]\psi}$}
 \DisplayProof
\end{center}
 where $\G^j$ denotes the context obtained by replacing every modality
 in $\G$ with $[j]$.
 In the lattar case, we can do the symmetric.

After these rewritings for all appearing channels,
we obtain a derivation not containing any channels.
Moreover, the end hypersequent of the resulting derivation has a component
not containing $\abort$.
The reductions of the original hyperterm can be simulated by the
resulting hyperterm.  And, even after reductions, the resulting
hyperterm has a component not containing $\abort$.
\end{proof}

 \begin{proposition}
  \label{process-change}
  When $\mathcal O \hmid \G_0,\D_0\tr\tj{P}{[k]\psi_0}$ is derivable,
  $\mathcal O\hmid \G_0^m, \D_0^m\tr\tj{P}{[m]\psi_0}$ is also
  derivable%
  \footnote{Note that the modalities in $\mathcal O$ are not changed
  while the modalities in $\G_0$ and $\D_0$ are turned into $[k]$.}.
 \end{proposition}
  \begin{proof}
   By induction on the height of derivation.
   All rules except com and EC rules are trivial because they do not interact
   with the modalities.  For EC rule, we have to apply the induction
   hypothesis twice to change modalities in two components.  For com rule,
   let us assume the derivation ends in com rule as:
   \[
   \BinaryRule
   {$\hypert_0\hmid\G\tr\tj{M}{[i]\varphi}$}
   {$\hypert_1\hmid\D\tr\tj{N}{[j]\psi}$}
   {}
   {$\cotuple{\hypert_0,\hypert_1}\hmid\Gamma\tr\tj{(\comodL)M}{[i]\psi}\hmid
   \Delta\tr\tj{(\comodR)N}{[j]\varphi}$}\enspace.
   \]
   We have to consider three cases:  first, when
   $\G_0,\D_0\tr\tj{P}{[k]\psi_0}$ is in $[\mathcal O_0, \mathcal O_1]$;
   second, when $\G_0,\D_0\tr\tj{P}{[k]\psi_0}$ is identical to
   $ \Gamma\tr\tj{(\comodL)M}{[i]\psi} $; and third,
   when $\G_0,\D_0\tr\tj{P}{[k]\psi_0}$ is identical to
   $\Delta\tr\tj{(\comodR)N}{[j]\varphi}$.
   The second and third cases are symmetric.  In the first case, $P$ is
   actually a concurrent construct $[P_0,P_1]$. We can apply the
   induction hypothesis to $P_0$ and $P_1$ and combine them again.
   In the second case, we can use the induction hypothesis on the left branch%
   \footnote{One crucial thing is the choice of the form of the com rule.
   If we use the com' rule by Avron~\cite{avron91}, the proof does not
   proceed because the contexts $\G$ and $\D$ are duplicated as
   \[
   \BinaryRule
   {$\hypert_0\hmid\G,\D\tr\tj{M}{[i]\varphi}$}
   {$\hypert_1\hmid\G,\D\tr\tj{N}{[j]\psi}$}
   {}
   {$\cotuple{\hypert_0,\hypert_1}\hmid\G\tr\tj{(\comodL)M}{[i]\psi}\hmid
   \D\tr\tj{(\comodR)N}{[j]\varphi}$}\enspace.
   \]
   There, if we want to change the modalities in the rightmost component
   naively, we also have to change the modalities in the second
   rightmost component.
   }.
  \end{proof}

\begin{theorem}[Strong normalization]
 \label{first:sn}
 \lgd\, is strongly normalizing.
\end{theorem}
\begin{proof}
For proving this, we consider the pure fragment\index{pure fragment}
 that does not contain
$(\comodL)M$, $(\comodR)N$.
We first reduce the strong
normalization of the \lgd\, to that of the pure fragment, and
ultimately to that of de Groote's
natural deduction with permutation-conversion~\cite{Philippe2002js}%
\footnote{
To the
same effect, we might be able to use other strong normalization
 results for lambda calculi with commutative conversions, like Balat,
 Di~Cosmo
 and Fiore~\cite{bdf}.
}%
.

We assume an infinite sequence of reductions
$
\conf{_0}{\hypert_0}
\reduce
\conf{_1}{\hypert_1}
\reduce
\conf{_2}{\hypert_2}
\reduce\cdots
$.  From this, we are going to construct an infinite sequence of
reductions in the pure fragment.

For that, we first
build an infinite reduction sequence with constant stores.
Using the original infinite sequence, we define a pair of stores called the
store prophecy\index{store!--- prophecy} $\lstore_\infty$ where
$ \lstore_\infty(l)= \epsilon$ if $\lstore_k(l)=\epsilon$ for all
 $k\in\omega$ and
$ \lstore_\infty(l)=M $ if $\lstore_k(l)=M$ for some $k\in\omega$.
Since store contents are never overwritten,
$\lstore_\infty$ is well-defined.
Moreover,
$\lstore_i(l)$ and $\lstore_\infty(l)$ coincide unless
$\lstore_i(l)=\epsilon$.

We build another reduction sequence
$
\conf{_\infty}{\hypert_0}
\reduce^\ast
\conf{_\infty}{\hypert'_1}
\reduce^\ast
\conf{_\infty}{\hypert'_2}
\reduce^\ast\cdots
$
with the following invariant:
$\mathcal M'_i$ can be obtained by replacing some $\abort$ occurrences
in $\mathcal M_i$ with some terms.
More specifically, we translate each reduction as follows, keeping the
invariant inductively on the number of steps
(the base case is satisfied by $\mathcal M'_0 = \mathcal M_0$ immediately):
\begin{itemize}
 \item a read reduction $\conf{_k}{\hypc{}{\reader c}}
       \rreduce
       \conf{_{k+1}}{\hypc{}{O}}$ is translated into
       $\conf{_\infty}{\hypc'{\reader c}} \rreduce
       \conf{_{k+1}}{\hypc'{O'}}$.
       If $\lstore_i(c)$ is a term,
       $\lstore_\infty(c)$ and $O'$ are also identical to the term.
       Otherwise, $O'$ must be $\abort$.
       Thus, the invariant
       holds for $k+1$.
 \item a write reduction disappears;
 \item an $\abort$ propagation
       $\hypc{}{C[\abort]} \areduce \hypc{}{\abort}$ can be translated
       either to a similar reduction or no reduction if the $\abort$ in
       the redex is replaced by another term in the $\mathcal{M'}_k$.
       Note that even in that case, the result $\mathcal{M'}_{k+1}$ can
       be obtained by replacing some $\abort$ occurrences in
       $\mathcal{M}_{k+1}$ with other terms;
 \item any other reduction $\conf{_k}{\hypc{}{M}} \bpreduce
       \conf{_{k+1}}{\hypc{}{N}}$
       is translated into one similar reduction
       $\conf{_\infty}{\hypc{'}{M'}}\bpreduce
        \conf{_\infty}{\hypc{'}{N'}}$.
\end{itemize}
Here, we have to show that the translated sequence is infinite.
 For that, we can use the facts that
 there are only finite
number of mentioned locations each of which allows only one write, and that
an $\abort$ propagation always
strictly shortens the term under operation.

 After that, we can replace
 every ${\reader c}$ with
 $\lstore_\infty(c)$.
 Since $\reader c$ either reduces to $\lstore_\infty(c)$ or $\abort$,
 replacing it with $\lstore_\infty(l)$ will only ``shorten'' the reduction
 sequence for at most one read step.
 Replacing every such occurrences
 makes an infinite reduction sequence where every occurring term is
 in the pure fragment.
 Moreover,
 the result of the translation is also well-typed.
 A typing derivation of the resulting hyperterm can be obtained by
 replacing com rules with EW rules and changing the process number in
 types of some variables (c.f. the proof of \thref{nab}).

We are aiming at reducing the problem to the strong normalization result
by de Groote~\cite{Philippe2002js}.
Since we have eliminated $(\comodL)M$ or $(\comodR)N$ occurrences,
the remaining difference is small: some $\abort$ propagation reductions
 and some permutative reductions involving $\cotuple{\term,\term'}$.
We just have to make sure that there are no infinite reduction sequences
that consist of these two kinds of reductions only.
We can deal with the permutative reductions following de
 Groote~\cite{Philippe2002js}'s strategy for introducing~$\bot$.
 There are no infinite sequence of $\abort$ reductions keeping the
 number of $[t,t]$ constructions; and an abort reduction cannot increase
 the number of $[t,t]$ constructions in a configuration.  Combined,
 there are no infinite sequence of abort reductions.
\end{proof}

\fix{subformula property around here}

\section{Typed Waitfreedom}
\label{waitfreedom}

Waitfree protocols~\cite{Herlihy88,Saks:1993vq} are a class of protocols
that can solve
some of the input-output problems~\cite{Moran:1987ep,Biran:1988hh}.
If a waitfree protocol solves an input-output problem, then the protocol
belongs to the waitfreedom.
We define the typed version of waitfreedom.

\subsection{Typed Input-Output Problem}

Saks and Zaharoglou~\cite{Saks:1993vq} formulated waitfreedom as a class
of input-output
problems.
Given inputs for all processes and outputs of all
processes, an input-output problem decides whether the processes have
succeeded or not.
We change the standard definition and have typed terms as inputs and
outputs.
This change is necessary because according to the original definition of
waitfreedom,
a single process waitfree protocol can solve any undecidable problem
because a waitfree protocol can contain arbitrary functions.

For that, we let $\lterm(\varphi)$ denote the set of closed, pure terms of
type~$\varphi$,
and $\lval(\varphi)$ denote the set of normal terms in $\lterm(\varphi)$.
For a finite set of processes~$\processes$,
a typed input-output problem\index{typed input-output problem} consists
of each process's input type
$(\iota_i)_{i\in \processes}$, each process's output type $(o_i)_{i\in
\processes}$, and a
task $R\subseteq \prod_{i\in \processes}\left(\lterm(\iota_i)\right)\times
 \prod_{i\in \processes}\left(\lval(o_i)\right)$.

 \fix{example}

\subsection{Typed Protocol}

We assume a finite set~$\processes$
of processes and a countably infinite
set of program variables $\ProV =\{\p x, \p y, \p z, \ldots\}$.
We assume an injection from variables to program variables $x\mapsto
\p{x}_x$, whose image leaves infinitely many unused program variables.

A program\index{program} is defined by BNF:
\[
 p ::= \epsilon\mid
 \p x\leftarrow E; p \mid
 l \leftarrow E; p
\]
where an expression\index{expression} is
\begin{align*}
 E
 ::=\,\,
 &x\mid \p x \mid c \mid (EE)\mid \lambda
 x.E\mid \tuple{E,E}\mid \linl{E}\mid \linr{E}\mid \\
 &\lpil{E}\mid\lpir{E}\mid  \mat E x {E} y {E}\mid \epsilon\enspace.
\end{align*}
The expression~$\epsilon$ is used as the initial content of the shared
memory \fix{really?}.

\newcommand{\Wg}{W_{\mathrm g}}
\newcommand{\Wd}{W_{\mathrm d}}
A program is well-formed\index{well-formed program} when
a program variable (resp. channel) first appears in a $\p x\leftarrow E$
(resp. $c\leftarrow E$)
sentence, and
after that, only appears in expressions.
In other words, a well-formed program is in the single assignment form.
For a contexted type $(\Gamma\tr\m\varphi)$,
we write $\tj{M}{(\Gamma\tr\m\varphi)}$ for
$\Gamma\tr\tj{M}{\m\varphi}$.
For input types $(\iota_i)_{i\in\processes}$
and output types $(o_i)_{i\in\processes}$,
a typed protocol\index{typed protocol} has:
\begin{itemize}
 \item two program variables
      $\p i_i$ and $\p o_i$ for each process~$i$;
 \item a finite set of channels~$C$;
 \item two functions $w\colon C\rightarrow \processes$
       and $r\colon C\rightarrow
       \processes$ (specifying the writer and the reader of
       each channel);
 \item $W$: maps a channel in $C$ to a contexted type;
 \item a function $t_i$ for each $i\in \processes$;
       that maps a program variable to a contexted type
       $(\tj{x_k}{\varphi_k})_k \tr[i]\varphi$ with a special condition
       $t_i(\p i_i)= \iota_i$;
 \item a typed program~$p_i$ for each $i\in \processes$,
       where
       a typed program\index{typed program} is a well-formed program where all
       sentences are typed according to the rules below.
       A sentence $\p x \leftarrow E$ is typed  iff $\tr E\colon t(\p x)$ is derivable with
       assumptions of the form $\tr\tj{\p y}{t(\p y)}$ and $\tr\tj{c}{W(c)}$.
       A sentence $c\leftarrow E$ is typed iff
       $\tr\tj{E}{W(c)}$ is derivable
       with
       assumptions of the form $\tr\tj{\p y}{t(\p y)}$ and $\tr\tj{c}{W(c)}$.
\end{itemize}
\fix{example, for the above example problem}

\subsection{Typed Waitfree Computation}

We define when a protocol solves a typed
input-output problem.
These definitions are transferred from \citet{Saks:1993vq}.

Let $\processes$ be $\{0,\ldots, n-1\}$ and fix
a typed protocol.
A program variable content\index{program variable content} for $i\in\processes$ is a
partial
function
that maps a program variable to a term of $t_i(\p x)$.
A term~$M$ \textit{is of} a contexted type $\Gamma\tr\varphi$ when
$\Gamma\tr
\tj M\varphi$ is derivable.
A process snapshot\index{process snapshot} of $i\in\processes$ is a tuple
$\tuple{p,m}$ where $p$ is either a program or $\abort$ and $m$ is a
program variable content for $i$.
We let $S_i$ denote the set of process snapshots for~$i$.
A system snapshot\index{system snapshot}
is a pair $\tuple{\vec s, \vec v}$, where $\vec s = \tuple{s_0,
{s_1,{\ldots,s_{n-1}}}} \in
\prod_{i\in \processes}\left(S_i\right)
$
and
$\vec v =
\left(\vg{v}{l}, \vd{v}{l}\right)_{c\in C} \in \prod_{c\in C}(\val(W(c))\cup\{\epsilon\})
$.

For a nonempty subset~$J$ of $\processes$, we define an operator $\update J$ that
takes a system snapshot and produces a system snapshot.
This operator depicts a computational step where the processes in~$J$
are fired.

We define $
(\vec s, \vec v) \update J = (\vec u, \vec m)
$ by defining
$u_i$ and $m_i$
where $s_i = \tuple{p,x}$:
\fix{should not abort}
\begin{align*}
 u_i & =
 \begin{cases}
 \tuple{p',x}  & (\text{if } p = c
 \leftarrow E; p' \text{ and }\semo{E}_{x,\vec v} \neq \epsilon)
 \\
 \tuple{\epsilon,x}  & (\text{if } p = c
 \leftarrow E; p' \text{ and }\semo{E}_{x,\vec v} = \epsilon)
 \\
 \tuple{p', x[\p x \mapsto \semo{E}_{x, \vec v}]}&
                       (\text{if } p = \p x \leftarrow E; p', \quad
 x(\p x) = \epsilon  \text{ and } \semo{E}_{x, \vec v} \neq \epsilon) \\
 \tuple{\epsilon, x}&
                      (\text{if } p = \p x \leftarrow E; p',  \quad
 x(\p x) = \epsilon  \text{ and } \semo{E}_{x, \vec v} = \epsilon) \\
 \tuple{\epsilon, x} & (\text{if } p = \p x \leftarrow E; p' \text{
 and }
 x(\p x) \neq \epsilon) \\
 s_i & (\text{if } p = \epsilon)
 \end{cases}\\
 \vg m c & =
 \begin{cases}
 \semo{E}_{x, \vec v} & (\text{if } p = c \leftarrow E; p',\quad w(c)= i
  \text{\fix{is this condition necessary?}
 and } \vg v c = \epsilon) \\
 \vg v c &(\text{otherwise})
 \end{cases}\\
\end{align*}
with the following notations.
We let $i(l)$ to be $\vg v l$ if $d(l)=i$ and
$\vd v l$ if $g(l) = i$.
The term
$\semo{E}_{x, \vec v}$ is defined as the unique normal form
%{show, show, show}
of $E[x(\vec{\p y}) / \vec{\p y}][\vec{i(l)}/\vec c]$ \fix{what is this vector?}, where
every program variable~$\p y$ is replaced by $x(\p y)$ and the
uniqueness is guaranteed by the absence of $c$.
If any of the substitutes is $\epsilon$,
$\semo{E}_{x, \vec v}$ is $\epsilon$.

A schedule\index{schedule} is an infinite sequence of nonempty subsets of~$\processes$,
which looks like $\sigma = \sigma_0\sigma_1\sigma_2\cdots$.
We say $i$ is nonfaulty\index{nonfaulty} in $\sigma$
if it appears infinitely often.
% probably not used anywhere % When every process is nonfaulty, the schedule is \textit{fair}.

A run\index{run} is a triple $\tuple{\Pi, \vec x, \sigma}$,
where $\Pi$ is a typed protocol,
$\vec x \in \prod_{i\in \processes} \lterm(\iota_i)$ is the input,
and $\sigma$ is a schedule.
The execution\index{execution} associated to the run
is defined as the infinite sequence of system snapshots
$C_0C_1C_2\cdots$, where $C_0 = \tuple{\vec{s^0}, \vec{v^0}}$ is
defined by $\vec{s^0_i} = \tuple{p_i, [\p i_i\mapsto x_i]}$ and
$\vg v l  = \vd v l = \epsilon$,
and $C_{k+1} = C_{k}\update
\sigma_{i+1}$.

\fix{example}

Process~$i$'s output\index{output}~$\hat{o_k}$ at step~$k$ is
$M$ if the $i$-th process snapshot of $C_k$ is
$(p, x)$ and the $x[\p{o}_i] = M$, which can be $\epsilon$.
The decision value of $i$ on the run $\tuple{\Pi,\vec x,\sigma}$,
denoted~$d_i \in \lval(o_i)\cup\{\epsilon\}$
 is the first non-$\epsilon$ element in the sequence
 $\left(\hat{o_k}\right)_{k\in\omega}$,
 or
$\epsilon$ if such element does not exist.
The $n$-tuple~$\vec d$ is defined by $d_i$'s.

A vector $\vec b\in \prod_{i\in \processes}(\lval(o_i))$
is compatible with\index{compatible with} $\vec d \in \prod_{i\in
\processes}\left(\lval(o_i)\cup\{\epsilon\}\right)$ iff
$d_i = b_i$ or $d_i = \epsilon$ holds for any process~$i$.
An input~$\vec x\in \prod_{i\in \processes}\lterm(\iota_i)$
is \linebreak[2] $R$-permissible\index{permissible} iff there is at least one
vector $\vec d\in \prod_{i\in \processes}(\lval(o_i))$ with $(\vec x, \vec b)\in R$.
A typed protocol~$\Pi$ solves\index{solve!typed protocol --- typed
input-output problem} the typed input-output problem
  $\tuple{(\iota_i)_{i\in \processes}, (o_i)_{i\in \processes}, R}$ on
schedule~$\sigma$ iff for all $R$-permissible inputs~$\vec x$ and a
schedule~$\sigma$,
 the decision value of every nonfaulty process~$i$ is a term
       $M$ not $\epsilon$, and
 there is a vector $\vec b\in \prod_{i\in \processes}(\lval (o_i))$
 with $\tuple{\vec x, \vec b} \in R$ which is compatible with the
 decision vector~$\vec d$.
 A typed protocol is waitfree\index{waitfree} iff it solves
 the problem on every schedule~$\sigma$.
 In that case, the typed input-output problem is
 waitfreely solvable\index{waitfreely solvable}.

 \fix{show example solvable}

 \fix{show example not solvable, why? see saks or see below}


\section{Characterization of Waitfreedom and \lgd}
\label{comparison}

We show that the ability of the waitfree protocols and \lgd\, are the same.
\begin{definition}
 A typed input-output problem
 $\tuple{(\iota_i)_{i\in \processes}, (o_i)_{i\in \processes}, R}$ is
 solvable by a global term
 $\m M$ of contexted type
 $\left(\tj{x_i}{[i]\iota_i}\right)_{i\in\processes}
 \tr\left(o_i\right)_{i\in \processes}$ iff
 for any closed $(N_i)_{i\in \processes}$ of $\iota_i$,
 all normal forms of $\m{M}[\vec{N_i}/\vec{x_i}]$
 are in the form
 $\tuple{{V_0}, \tuple{{V_1},
 \cdots\tuple{{V_{n-2}},\tuple{{V_{n-1}},\bullet}}\cdots}}$
 where $\tuple{(N_i)_{i\in \processes}, (V_i)_{i\in \processes}}\in R$.
 % looks like we assume subformula property
\end{definition}

\begin{theorem}[Soundness]
If a typed input-output problem is solvable by a term,
there exists a typed protocol that solves the problem.
\end{theorem}

We are going to translate a typed hyperterm into a protocol inductively
on the type derivation.
To make induction work, we use the following auxiliary notions.
An investigator\index{investigator} $\tuple{i, \p x}$ is a pair of a process and a program
variable.
For a local formula~$\varphi$, a system snapshot $\tuple{\vec s,\vec v}$
satisfies
$\tuple{i,\p x}(\varphi)$ iff
$s_i(\p x)$ is an expression of $\varphi$.
For a set of investigators~$I$,
a system snapshot satisfies
$I([i]\varphi)$ iff it satisfies
$\tuple{i, \p x}(\varphi)$ for at least one
$\tuple{i,\p x}\in I$.
This can be extended to all global formulae, as
$I(\m\varphi\wedge\m\psi)$ iff $I(\m\varphi)$ and $I(\m\psi)$;
$I(\m\varphi\vee\m\psi)$ iff $I(\m\varphi)$ or $I(\m\psi)$.
A system snapshot satisfies a global formula%
\index{satisfy!system snapshot ---s a global formula}~$\m\varphi$
iff there exists a
finite set of
investigators~$I$ such that the system snapshot satisfies $I(\m\varphi)$.
A system snapshot satisfies a context%
\index{satisfy!system snapshot ---s a context} iff it
satisfies every global formula in the context.
A protocol\index{protocol} $p$ \textit{realizes a hypersequent}~$
\left(\Gamma_0\vdash
\m\varphi_0 \hmid \cdots\hmid\Gamma_{k}\vdash \m\varphi_{k}\right)$
iff
for any initial system snapshot satisfying
every~$\Gamma_{k'}$,
there exists a family of investigator sets
$(I_{k'})_{k'\in\{0,\ldots,k\}}$ and,
when $p$ is executed with any schedule,
the resulting system snapshots eventually satisfy at least one of
$\varphi_{k'}^+$.

For a typed
hyperterm~$\hypert$,
we will give $\semo{\hypert}$, which is a tuple of programs indexed
by~$\processes$.
Also, we define $\semoi{\hypert}$ at the same time as
$\semo{\hypert}$, where
$\semoi{\hypert}$ is a sequence of finite sets of investigators whose
length is the same as that of $\hypert$.
We refer to the last element of $\semoi{\hypert\hmid M}$ as
$\semoi{\hypert\hmid \hat{M}}$, the second to last element of
$\semoi{\hypert\hmid M\hmid N}$ as
$\semoi{\hypert\hmid \hat M\hmid N}$ and so on.
We denote the right projection of $\semoi{\hypert\hmid \hat{M}}$ as
$\semoi{\hypert\hmid \hat{M}}'$.
If two sequents of investigator sets $\semoi{\hypert}$ and $\semoi{\hypert'}$
have the same length, we define $\semoi{\hypert}\cup \semoi{\hypert'}$ to
be the elementwise union.

We let $\epsilon$ denote $(p_i)_{i\in\processes}$ where $p_i=\epsilon$
for all $i\in\processes$.
Also, $(p_i)_{i\in\processes}; (q_i)_{i\in\processes}$ denotes
$(p_i; q_i)_{i\in\processes}$ where the
same program variable does not have multiple substitutions
(we rename variables in the original typing derivation to satisfy this).
And $(p)_j$ denotes $(q_i)_{i\in\processes}$ where $q_j = p$ and $q_i =
\epsilon$ for all $i\neq j$.
Below, we always choose fresh program variables.
The definition is inductive over the type derivation:
\fix{put process numbers after the local operations}
\begin{description}
 \item[$ij$-com]
      \begin{align*}
 \semo{\cotuple{\hypert_0,\hypert_1}\hmid (\comodL) M\hmid (\comodR) N}
 =& \semo{\hypert_0\hmid M};
 \semo{\hypert_1\hmid N};\\
 &(d\leftarrow \semoi{\hypert_0\hmid\hat M}'; \p
 y\leftarrow c;)_j; \\
 &(c\leftarrow \semoi{\hypert_1\hmid\hat N}'; \p
 x\leftarrow d;)_i\enspace,\\
 \semoi{\cotuple{\hypert_0,\hypert_1}\hmid\ltor j l \Delta M\hmid \rtol i l\Gamma N} =&
 \semoi{\hat \hypert_0\hmid M} \cup \semoi{\hat \hypert_1\hmid N} \hmid\\& \tuple{\{j,\p
 y\}}\hmid \{\tuple{i,\p x}\}\enspace,
      \end{align*}
 \item[EW] \begin{align*}
 \semo{\hypert\hmid \abort}=\semo{\hypert}\enspace,\quad
 \semoi{\hypert\hmid\abort}=&\semoi{\hypert}\hmid \emptyset\enspace,\quad
	   \end{align*}
 \item[EC]
\begin{align*}
 \semo{\hypert\hmid \cotuple{M,N}}&= \semo{\hypert\hmid M \hmid N}\\
 \semoi{\hypert\hmid \cotuple{M,N}}&= \semoi{\hat\hypert\hmid M\hmid N}
 \hmid
 \left(\semoi{\hypert\hmid\hat M\hmid N} \cup \semoi{\hypert\hmid M\hmid
 \hat N}\right)\enspace.
\end{align*}
 \item[EE] 
 \item[IE] 
 \item[IW] 
 \item[IC] 
 \item[$\brac i$Ax] 
\begin{align*}
 \semo{x}=& \epsilon \enspace\\
 \semoi{x}=& \{\tuple{i,\p x_x}\} \text{ where $[i]\varphi$ is the type
 of $x$}\enspace,
\end{align*}
 \item[$\wedge\intro$] 
\begin{align*}
 \semo{\hypert\hmid \gpair{M,N}}=&
 \semo{\hypert\hmid M}; \semo{\hypert\hmid N}\enspace,\\
 \semoi{\hypert\hmid \gpair{M,N}} =&
 \semoi{\hypert\hmid M}\cup \semoi{\hypert\hmid N}\enspace,
\end{align*}
 \item[$\wedge\elim_a$] 
\begin{align*}
 \semo{\hypert\hmid \pi_a^\g(M)}=&\semo{\hypert\hmid M}\enspace,\\
 \semoi{\hypert\hmid\pi_a^\g(M)}=&\semoi{\hypert\hmid M}\enspace,
\end{align*}
 \item[${\brac{i}}\bot\elim$] 
 \item[$\brac i\supset\intro$] 
\begin{align*}
 \semo{\hypert\hmid \lambda x.M}=& \semo{\hypert\hmid M}; \left(\p z\leftarrow
 \lambda x. \semoi{\hypert\hmid\hat M}'\right)_i \enspace,\\
 \semoi{\hypert\hmid \lambda x.M} =& \semoi{\hat\hypert\hmid M} \hmid
 \{\tuple{i,\p z}\}\enspace,
\end{align*}
 \item[$\brac i\supset\elim$] 
\begin{align*}
 \semo{\cotuple{\hypert_0,\hypert_1}\hmid MN}=& \semo{\hypert_0\hmid M}; \semo{\hypert_1\hmid N}; \\&
 \left(\p z\leftarrow \semoi{\hypert_0\hmid \hat M}'\semoi{\hypert_1\hmid \hat N}'\right)_i\enspace,\\
 \semoi{\cotuple{\hypert_0,\hypert_1}\hmid MN} =& (\semoi{\hat \hypert_0 \hmid M}\cup
 \semoi{\hat\hypert_1\hmid N})\hmid \{\tuple{i,\p z}\}\enspace,
\end{align*}
 \item[$\brac i\wedge\intro$]
      \begin{align*}
       \semo{\cotuple{\hypert_0,\hypert_1}\hmid \tuple{M,N}}=&
       \semo{\hypert_0\hmid M}; \semo{\hypert_1\hmid N};\\ & \left(\p z
       \leftarrow \tuple{\semoi{\hypert_0\hmid \hat
       M}',\semo{\hypert_1\hmid\hat N}'}\right)_i\enspace,\\
       \semoi{\cotuple{\hypert_0,\hypert_1}\hmid \tuple{M,N}} =& (\semoi{\hat \hypert_0 \hmid M}\cup
       \semoi{\hat\hypert_1\hmid N})\hmid \{\tuple{i,\p z}\}\enspace,
      \end{align*}
 \item[$\brac i\wedge\elim_0$] 
\begin{align*}
 \semo{\hypert\hmid \lpil M} =& \semo{\hypert\hmid M}; \left(\p z \leftarrow
 \lpil {\semoi{\hypert\hmid\hat M}'}\right)_i\enspace, \\
 \semoi{\hypert\hmid \lpil M}=& \semoi{\hat \hypert\hmid M}\hmid
 \{\tuple{i, \p z}\}\enspace,
\end{align*}
 \item[$\brac i\wedge\elim_1$] 
\begin{align*}
 \semo{\hypert\hmid \lpir M} =& \semo{\hypert\hmid M}; \left(\p z \leftarrow
 \lpir{ \semoi{\hypert\hmid\hat M}' }\right)_i\enspace, \\
 \semoi{\hypert\hmid \lpir M}=& \semoi{\hat \hypert\hmid M}\hmid
 \{\tuple{i, \p z}\}\enspace,
\end{align*}
 \item[$\brac i\vee\intro_0$] 
\begin{align*}
 \semo{\hypert\hmid \linl{M}} =& \semo{\hypert\hmid M}; \left(\p z \leftarrow
 \linl{ \semoi{\hypert\hmid\hat M}'}\right)_i\enspace, \\
 \semoi{\hypert\hmid \linl M}=& \semoi{\hat \hypert\hmid M}\hmid
 \{\tuple{i, \p z}\}\enspace,
\end{align*}
 \item[$\brac i\vee\intro_1$] 
\begin{align*}
 \semo{\hypert\hmid \linr M} =& \semo{\hypert\hmid M}; \left(\p z \leftarrow
 \linr{\semoi{\hypert\hmid\hat M}'}\right)_i\enspace, \\
 \semoi{\hypert\hmid \linr{M}}=& \semoi{\hat \hypert\hmid M}\hmid
 \{\tuple{i, \p z}\}\enspace,
\end{align*}
 \item[$\brac{i}\vee\elim$] 
\end{description}
\fix{before finishing the above list, make an example first}
When $(\tj{x_i}{[i]\iota_i})_{i\in\processes}
\tr\tj{M}(\wwedge_{i\in \processes}[i]o_i)$ is
derivable,
we can define a protocol using the above translation.
We set $\mathtt i_i$ to be ${\p x}_{x_i}$, ${\p o}_i$ to be arbitrarily
chosen fresh program variables, $L$ to be the set of locations
occurring in the derivation, we set the family of programs to be
$\semo{M}; ({\p o}_i\leftarrow \pi_i(\semoi{\hat M}'))_{i\in\processes}$,
where $\pi_i$ is obtained by composing $i$~times $\pi_{\mathrm r}$ to
$\pi_{\mathrm l}$.
We set $g,d,t_i$ accordingly so that the program is typed.
\fix{add example}

We can simulate a reduction sequence of
the hyperterm using a fair execution of the protocol.
And, since the protocol solves a problem for any fair schedule, it
solves the problem waitfreely.
If we deny the claim, there must be an execution where a nonfaulty
process
either (a)~gives a
wrong answer or
 (b)~never gives an answer.
 Either case, there is a step~$k$ when
 such a failure is inevitable.
We can modify the schedule after step $k$ to a fair one,
keeeping the failing behavior of
the process.

\fix{add example}

\begin{theorem}[Completeness]
If there exists a typed protocol that solves a typed input-output
 problem,
the problem is solvable by a term.
\end{theorem}

Saks and Zaharoglou~\cite{Saks:1993vq} showed that a finite repetition of the participating set
problem universally solves any waitfreely solvable problem.
Also, $n$-party participating problem can be solved by a tournament of
the two-party participating set problem.
It suffices to show a \lgd\, term solving the two-party problem.


In the participating set problem\index{participating set problem}~\cite{borowsky},
each process~$i$ receives an id $c_i$ and
returns a set of id's $S_i$.
The outputs must satisfy (i)~$i\in S_i$; (ii)~either $S_i\subseteq S_j$
or $S_j\subseteq S_i$; and (iii)~$S_i\subseteq S_j$  if $i\in S_j$ for any
$i,j\in\processes$.
For two processes,
$\tuple{S_0, S_1}$ can be $\tuple{\{c_0\}, \{c_0, c_1\}}$, $\tuple{\{c_0, c_1\}, \{c_1\}}$
or
$\tuple{\{c_0, c_1\}, \{c_0, c_1\}}$.

We are going to encode the participating set problem in \lgd.
For this, we introduce a base type called $\Id$ for process id's.
Let there be an injection that maps a natural number~$i$ to a constant
$C_i\colon\Id$.
The additional typing rules involving $\Id$ are as follows, where $2 = (\bot\supset\bot)\vee(\bot\supset\bot)$:
\begin{center}
 \UnaryRule{}{}
 {$\tr \tj{c_n}{[i]\Id}$}
 \hfill
 \BinaryRule
 {$\Gamma\tr \tj{M_0}[i]\Id$}
 {$\Gamma\tr \tj{M_1}[i]\Id$}
 {}
 {$\Gamma \tr \tj{\compare{M_0}{M_1}}{[i]2}$}\enspace.
\end{center}
The additional reduction is
\[
 c_m == c_n \reduce
\begin{cases}
 \linl{\lambda x.x}& (\text{if } m = n)\\
 \linr{\lambda x.x}& (\text{otherwise})\enspace.
\end{cases}
\]
Also,
${\ifte M {N_0} {N_1}}$
is an abbreviation for
${\mat M x {N_0} y {N_1}}$.

We represent a finite set of id's as a
typed lambda term, whose type is $[i](\Id\supset 2)$.  Intuitively, a
set takes an id and decides whether it is \textit{in} or \textit{out}.
The emptyset is represented by a term $\lambda x. \linr {\bullet}$.
When a finite set~$S$ is represented by a term~$M$,
the set $S \cup \{c\}$ is represented by a term
$\lambda x.\left(\ifte{x==c}{\linl {\bullet}}{Mx}\right)$.
With the above construction, we define abbreviations
like $\{c_0, c_1, c_2\}$.

Now, we are ready to construct a hyperterm solving the two-party
participating set problem.
We can obtain a derivation of \fix{something else}:

One possible reduction sequence is as follows: \fix{according to the new
rule?}

Moreover, the same initial configuration can reduce to
\[
 \concreteconf{[d\mapsto c_0,c\mapsto c_1]}{\gpair{\{c_1,c_0\},
 \{c_1\}}}\text{ and }
 \concreteconf{[d\mapsto c_0,c\mapsto c_1]}{\gpair{\{c_1,c_0\},
 \{c_0, c_1\}}}\enspace.
\]
There are no other normal forms.
These three normal forms correspond to the three answers for the
two-party participating set problem.

\section{Related Work}
\label{related}
Sonobe~\cite{sonobe} gives sequent calculi for intermediate logics $S_i$
and proved cut-elimination theorem for them.  As a special case he gives
$S_\omega$, which coincides with G\"odel--Dummett logic.
The proof of cut-elimination is similar to that of
Gentzen~\cite{gentzen}, involving the mix rule.
No lambda calculi has been developed based on Sonobe's deduction system.

Avron~\cite{avron91} formulates a
hypersequent calculus for G\"odel--Dummett logic and proves
cut-elimination theorem using a method
similar to Gentzen~\cite{gentzen}.
Also, he explains the intuition behind the communication rule as
``the inputs through the ports in $\Gamma_2'$ are transmitted to the
component with output of type $A_1.$  The inputs through $\Gamma_1'$ are
treated similarly.''  He did not mention the possibility of
any transmission failures, which we exploited
in order to characterize waitfreedom.
Ciabattoni, Galatos and Terui~\cite{alg} gives a class of logics
that have
hypersequent calculi with
cut-elimination.
Their cut-elimination proof is general but it does not
obviously reveal the computational content.

Baaz, Ciabattoni and Ferm\"uller~\cite{natural} propose a
hypersequent-style natural deduction for G\"odel--Dummett logic, but
did not define reduction.
Ferm\"uller~\cite{parallel} gives a game semantics for G\"odel--Dummett
logic, which is based on Lorenzen game~\cite{curryhoward} and essentially
proof searching bottom-to-up.

Among numerous typed programming languages with parallelism,
to our knowledge, none exhibits
the connection of G\"odel--Dummett logic and waitfreedom.
Abramsky~\cite{abramsky1993computational}'s calculus $\mathsf{PE}_2$
for classical linear logic is
deterministic
\cite[Theorem~7.9]{abramsky1993computational} so that it is
impossible to model
waitfreedom using $\mathsf{PE}_2$.
The $\pi$-calculus~\cite{milner1999communicating},
Join calculus~\cite{join},
and even asynchronous
$\pi$-calculus \cite{hondatokoro}
have too strong synchronization abilities to model waitfreedom because
a process can wait for an input.

Hirai~\cite{hirailpar} compares the temporal order of waitfree
computation and the Kripke models of a modal logic similar to
G\"odel--Dummett logic.  The current
work witnesses the constructive content of
his model theoretic comparison.

\section{Future Work}
\label{future}

As a programming language, \lgd\, allows efficient execution because it
requires no synchronization among processes.
We implemented a calculus similar to \lgd\, in a programming language
Haskell%
\footnote{Given Haskell Platform, a command \texttt{cabal
waitfree} installs the implementation.}.
A possible extension is adding synchronization primitives.
It would be interesting to compare different synchronization primitives
and different intermediate logics, generalizing waitfreedom and
G\"odel--Dummett logic.
For example, it would be tedious but straightforward to adapt the
hyper-lambda calculi here to
the logics characterized by the Kripke frames of bounded
width~\citet{Ciabattoni01042001} because \lgd\, is a special case of
width~1.  However, the author has no immediate idea on
developing a general hyper-lambda calculi encompassing
all logics with cut-eliminatable hypersequent calculi.

We are also planning to develop a waitfree protocol verification mechanism in Coq
because it is valuable to
remove unnecessary synchronization while keeping the program correct
in high performance computing.

An anonymous refree pointed out that the introduction of
modalities is interesting on its own.
We have not investigated the semantics of these modalities.

In \lgd, the source of nondeterminism can be explicitly expressed as the
store prophecy.
If we can find a semantic counterpart $\mathsf{Sch}$ of the store
prophecy, possibly, we
can obtain a denotation $\mathcal{D}^\mathsf{Sch}$ of terms
using a denotation $\mathcal{D}$ for normal forms\fix{pursue this in the
following chapters}.
If that succeeds for classical logic, it will be interesting%
\footnote{Kazushige Terui suggested the potential impact for classical logic.}%
.

\fix{external contraction is not general.}
\fix{no problem with regard to provability}

\section{Conclusion}
\label{conc}
We proposed \lgd, a lambda calculus
based on hypersequent calculus of
G\"odel--Dummett logic.
We proved normalization and non-abortfullness.
The calculus characterizes
the typed version of waitfree computation.
Our result
hints broader correspondence between
proof theory and distributed computation.

\renewcommand{\comodL}{\comod{c}{\co c}}
\renewcommand{\comodR}{\comod{\co c}{c}}
